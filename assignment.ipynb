{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sE7W8BhacL9",
        "outputId": "3ae784c4-41ec-476e-a1e2-ebb3082230c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deep-sort-realtime in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.2.90)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deep-sort-realtime) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from deep-sort-realtime) (1.13.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from deep-sort-realtime) (4.10.0.84)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.19.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# First, install the necessary libraries\n",
        "!pip install deep-sort-realtime ultralytics opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision opencv-python tqdm\n",
        "!pip install ultralytics  # YOLOv8\n",
        "!pip install filterpy  # Kalman filtering (for DeepSORT)\n",
        "!pip install moviepy  # For video processing and output\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dM8ckFTzagCV",
        "outputId": "9fc5a7ee-45d4-4fbb-e9d1-878a3f8247ad"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0+cu121)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.2.90)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.19.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: filterpy in /usr/local/lib/python3.10/dist-packages (1.4.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from filterpy) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from filterpy) (1.13.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from filterpy) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->filterpy) (1.16.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.26.4)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.34.2)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (71.0.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yt_dlp\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Etd4LIX5a1kL",
        "outputId": "53e5b7cb-f0f4-4692-abc2-ecdf03d14879"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yt_dlp in /usr/local/lib/python3.10/dist-packages (2024.8.6)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.10/dist-packages (from yt_dlp) (1.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt_dlp) (2024.8.30)\n",
            "Requirement already satisfied: mutagen in /usr/local/lib/python3.10/dist-packages (from yt_dlp) (1.47.0)\n",
            "Requirement already satisfied: pycryptodomex in /usr/local/lib/python3.10/dist-packages (from yt_dlp) (3.20.0)\n",
            "Requirement already satisfied: requests<3,>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from yt_dlp) (2.32.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.17 in /usr/local/lib/python3.10/dist-packages (from yt_dlp) (2.0.7)\n",
            "Requirement already satisfied: websockets>=12.0 in /usr/local/lib/python3.10/dist-packages (from yt_dlp) (13.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.32.2->yt_dlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.32.2->yt_dlp) (3.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yt_dlp\n",
        "\n",
        "video_urls = [\n",
        "    \"https://www.youtube.com/watch?v=aWV7UUMddCU\",\n",
        "    \"https://www.youtube.com/watch?v=f6wqlpG9rd0\",\n",
        "    \"https://www.youtube.com/watch?v=GNVTuLHdeSo\",\n",
        "    \"https://www.youtube.com/watch?v=SWtmkjd45so\",\n",
        "    \"https://www.youtube.com/watch?v=RzI6Ar5mu2Q\",\n",
        "    \"https://www.youtube.com/watch?v=aulLej6Z6W8\",\n",
        "    \"https://www.youtube.com/watch?v=7pN6ydLE4EQ\",\n",
        "    \"https://www.youtube.com/watch?v=fEEelCgBkWA\",\n",
        "    \"https://www.youtube.com/watch?v=ckZQbQwM3oU\",\n",
        "    \"https://www.youtube.com/watch?v=E8Wgwg3F4X0\",\n",
        "    \"https://www.youtube.com/watch?v=rvIPH4ccfpI\",\n",
        "    \"https://www.youtube.com/watch?v=F6iqlW6ovZc\",\n",
        "    \"https://www.youtube.com/watch?v=9qjk-Sq415s&list=PL5B0D2D5B4BFE92C1&index=6\",\n",
        "    \"https://www.youtube.com/watch?v=DI25kGJis0w\",\n",
        "    \"https://www.youtube.com/watch?v=rrLhFZG6iQY\",\n",
        "    \"https://www.youtube.com/watch?v=RKOZbT0ftL4&t=1s\",\n",
        "    \"https://www.youtube.com/watch?v=N7TBbWHB01E\",\n",
        "    \"https://www.youtube.com/watch?v=1YqVEVbXQ1c\",\n",
        "\n",
        "]\n",
        "\n",
        "def download_videos(urls):\n",
        "    ydl_opts = {\n",
        "        'format': 'mp4',\n",
        "        'outtmpl': '%(id)s.%(ext)s',\n",
        "    }\n",
        "\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download(urls)\n",
        "\n",
        "download_videos(video_urls)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYPGWOUdbhWH",
        "outputId": "dd9ad21f-7f17-4e1e-d511-737c71fc520a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=aWV7UUMddCU\n",
            "[youtube] aWV7UUMddCU: Downloading webpage\n",
            "[youtube] aWV7UUMddCU: Downloading ios player API JSON\n",
            "[youtube] aWV7UUMddCU: Downloading web creator player API JSON\n",
            "[youtube] aWV7UUMddCU: Downloading m3u8 information\n",
            "[info] aWV7UUMddCU: Downloading 1 format(s): 18\n",
            "[download] aWV7UUMddCU.mp4 has already been downloaded\n",
            "[download] 100% of   22.69MiB\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=f6wqlpG9rd0\n",
            "[youtube] f6wqlpG9rd0: Downloading webpage\n",
            "[youtube] f6wqlpG9rd0: Downloading ios player API JSON\n",
            "[youtube] f6wqlpG9rd0: Downloading web creator player API JSON\n",
            "[youtube] f6wqlpG9rd0: Downloading m3u8 information\n",
            "[info] f6wqlpG9rd0: Downloading 1 format(s): 18\n",
            "[download] f6wqlpG9rd0.mp4 has already been downloaded\n",
            "[download] 100% of   23.56MiB\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=GNVTuLHdeSo\n",
            "[youtube] GNVTuLHdeSo: Downloading webpage\n",
            "[youtube] GNVTuLHdeSo: Downloading ios player API JSON\n",
            "[youtube] GNVTuLHdeSo: Downloading web creator player API JSON\n",
            "[youtube] GNVTuLHdeSo: Downloading m3u8 information\n",
            "[info] GNVTuLHdeSo: Downloading 1 format(s): 18\n",
            "[download] GNVTuLHdeSo.mp4 has already been downloaded\n",
            "[download] 100% of   10.77MiB\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=SWtmkjd45so\n",
            "[youtube] SWtmkjd45so: Downloading webpage\n",
            "[youtube] SWtmkjd45so: Downloading ios player API JSON\n",
            "[youtube] SWtmkjd45so: Downloading web creator player API JSON\n",
            "[youtube] SWtmkjd45so: Downloading m3u8 information\n",
            "[info] SWtmkjd45so: Downloading 1 format(s): 18\n",
            "[download] SWtmkjd45so.mp4 has already been downloaded\n",
            "[download] 100% of   13.43MiB\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=RzI6Ar5mu2Q\n",
            "[youtube] RzI6Ar5mu2Q: Downloading webpage\n",
            "[youtube] RzI6Ar5mu2Q: Downloading ios player API JSON\n",
            "[youtube] RzI6Ar5mu2Q: Downloading web creator player API JSON\n",
            "[youtube] RzI6Ar5mu2Q: Downloading m3u8 information\n",
            "[info] RzI6Ar5mu2Q: Downloading 1 format(s): 18\n",
            "[download] RzI6Ar5mu2Q.mp4 has already been downloaded\n",
            "[download] 100% of   13.86MiB\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=aulLej6Z6W8\n",
            "[youtube] aulLej6Z6W8: Downloading webpage\n",
            "[youtube] aulLej6Z6W8: Downloading ios player API JSON\n",
            "[youtube] aulLej6Z6W8: Downloading web creator player API JSON\n",
            "[youtube] aulLej6Z6W8: Downloading m3u8 information\n",
            "[info] aulLej6Z6W8: Downloading 1 format(s): 18\n",
            "[download] aulLej6Z6W8.mp4 has already been downloaded\n",
            "[download] 100% of    1.56MiB\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=7pN6ydLE4EQ\n",
            "[youtube] 7pN6ydLE4EQ: Downloading webpage\n",
            "[youtube] 7pN6ydLE4EQ: Downloading ios player API JSON\n",
            "[youtube] 7pN6ydLE4EQ: Downloading web creator player API JSON\n",
            "[youtube] 7pN6ydLE4EQ: Downloading m3u8 information\n",
            "[info] 7pN6ydLE4EQ: Downloading 1 format(s): 18\n",
            "[download] 7pN6ydLE4EQ.mp4 has already been downloaded\n",
            "[download] 100% of   33.97MiB\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=fEEelCgBkWA\n",
            "[youtube] fEEelCgBkWA: Downloading webpage\n",
            "[youtube] fEEelCgBkWA: Downloading ios player API JSON\n",
            "[youtube] fEEelCgBkWA: Downloading web creator player API JSON\n",
            "[youtube] fEEelCgBkWA: Downloading m3u8 information\n",
            "[info] fEEelCgBkWA: Downloading 1 format(s): 18\n",
            "[download] fEEelCgBkWA.mp4 has already been downloaded\n",
            "[download] 100% of    8.75MiB\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=ckZQbQwM3oU\n",
            "[youtube] ckZQbQwM3oU: Downloading webpage\n",
            "[youtube] ckZQbQwM3oU: Downloading ios player API JSON\n",
            "[youtube] ckZQbQwM3oU: Downloading web creator player API JSON\n",
            "[youtube] ckZQbQwM3oU: Downloading m3u8 information\n",
            "[info] ckZQbQwM3oU: Downloading 1 format(s): 18\n",
            "[download] ckZQbQwM3oU.mp4 has already been downloaded\n",
            "[download] 100% of   14.21MiB\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=E8Wgwg3F4X0\n",
            "[youtube] E8Wgwg3F4X0: Downloading webpage\n",
            "[youtube] E8Wgwg3F4X0: Downloading ios player API JSON\n",
            "[youtube] E8Wgwg3F4X0: Downloading web creator player API JSON\n",
            "[youtube] E8Wgwg3F4X0: Downloading m3u8 information\n",
            "[info] E8Wgwg3F4X0: Downloading 1 format(s): 18\n",
            "[download] E8Wgwg3F4X0.mp4 has already been downloaded\n",
            "[download] 100% of    4.55MiB\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=rvIPH4ccfpI\n",
            "[youtube] rvIPH4ccfpI: Downloading webpage\n",
            "[youtube] rvIPH4ccfpI: Downloading ios player API JSON\n",
            "[youtube] rvIPH4ccfpI: Downloading web creator player API JSON\n",
            "[youtube] rvIPH4ccfpI: Downloading m3u8 information\n",
            "[info] rvIPH4ccfpI: Downloading 1 format(s): 18\n",
            "[download] rvIPH4ccfpI.mp4 has already been downloaded\n",
            "[download] 100% of    1.74MiB\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=F6iqlW6ovZc\n",
            "[youtube] F6iqlW6ovZc: Downloading webpage\n",
            "[youtube] F6iqlW6ovZc: Downloading ios player API JSON\n",
            "[youtube] F6iqlW6ovZc: Downloading web creator player API JSON\n",
            "[youtube] F6iqlW6ovZc: Downloading m3u8 information\n",
            "[info] F6iqlW6ovZc: Downloading 1 format(s): 18\n",
            "[download] F6iqlW6ovZc.mp4 has already been downloaded\n",
            "[download] 100% of    4.60MiB\n",
            "[youtube:tab] Extracting URL: https://www.youtube.com/watch?v=9qjk-Sq415s&list=PL5B0D2D5B4BFE92C1&index=6\n",
            "[youtube:tab] Downloading playlist PL5B0D2D5B4BFE92C1 - add --no-playlist to download just the video 9qjk-Sq415s\n",
            "[youtube:tab] PL5B0D2D5B4BFE92C1: Downloading webpage\n",
            "[youtube:tab] Extracting URL: https://www.youtube.com/playlist?list=PL5B0D2D5B4BFE92C1\n",
            "[youtube:tab] PL5B0D2D5B4BFE92C1: Downloading webpage\n",
            "[youtube:tab] PL5B0D2D5B4BFE92C1: Redownloading playlist API JSON with unavailable videos\n",
            "[download] Downloading playlist: In The Son-Rise Program® Playroom for Autism\n",
            "[youtube:tab] PL5B0D2D5B4BFE92C1 page 1: Downloading API JSON\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube:tab] Incomplete data received. Retrying (1/3)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube:tab] PL5B0D2D5B4BFE92C1 page 1: Downloading API JSON\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube:tab] Incomplete data received. Retrying (2/3)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube:tab] PL5B0D2D5B4BFE92C1 page 1: Downloading API JSON\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube:tab] Incomplete data received. Retrying (3/3)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube:tab] PL5B0D2D5B4BFE92C1 page 1: Downloading API JSON\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube:tab] Incomplete data received. Giving up after 3 retries\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube:tab] Playlist In The Son-Rise Program® Playroom for Autism: Downloading 6 items of 6\n",
            "[download] Downloading item 1 of 6\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=Hd9marUY5GQ\n",
            "[youtube] Hd9marUY5GQ: Downloading webpage\n",
            "[youtube] Hd9marUY5GQ: Downloading ios player API JSON\n",
            "[youtube] Hd9marUY5GQ: Downloading web creator player API JSON\n",
            "[youtube] Hd9marUY5GQ: Downloading m3u8 information\n",
            "[info] Hd9marUY5GQ: Downloading 1 format(s): 18\n",
            "[download] Hd9marUY5GQ.mp4 has already been downloaded\n",
            "[download] 100% of   21.01MiB\n",
            "[download] Downloading item 2 of 6\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=81fShK4roew\n",
            "[youtube] 81fShK4roew: Downloading webpage\n",
            "[youtube] 81fShK4roew: Downloading ios player API JSON\n",
            "[youtube] 81fShK4roew: Downloading web creator player API JSON\n",
            "[youtube] 81fShK4roew: Downloading m3u8 information\n",
            "[info] 81fShK4roew: Downloading 1 format(s): 18\n",
            "[download] 81fShK4roew.mp4 has already been downloaded\n",
            "[download] 100% of   21.64MiB\n",
            "[download] Downloading item 3 of 6\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=Wd3X_3C0et8\n",
            "[youtube] Wd3X_3C0et8: Downloading webpage\n",
            "[youtube] Wd3X_3C0et8: Downloading ios player API JSON\n",
            "[youtube] Wd3X_3C0et8: Downloading web creator player API JSON\n",
            "[youtube] Wd3X_3C0et8: Downloading m3u8 information\n",
            "[info] Wd3X_3C0et8: Downloading 1 format(s): 18\n",
            "[download] Wd3X_3C0et8.mp4 has already been downloaded\n",
            "[download] 100% of   12.08MiB\n",
            "[download] Downloading item 4 of 6\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=HGz2M8kvWqM\n",
            "[youtube] HGz2M8kvWqM: Downloading webpage\n",
            "[youtube] HGz2M8kvWqM: Downloading ios player API JSON\n",
            "[youtube] HGz2M8kvWqM: Downloading web creator player API JSON\n",
            "[youtube] HGz2M8kvWqM: Downloading m3u8 information\n",
            "[info] HGz2M8kvWqM: Downloading 1 format(s): 18\n",
            "[download] HGz2M8kvWqM.mp4 has already been downloaded\n",
            "[download] 100% of   25.05MiB\n",
            "[download] Downloading item 5 of 6\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=9qjk-Sq415s\n",
            "[youtube] 9qjk-Sq415s: Downloading webpage\n",
            "[youtube] 9qjk-Sq415s: Downloading ios player API JSON\n",
            "[youtube] 9qjk-Sq415s: Downloading web creator player API JSON\n",
            "[youtube] 9qjk-Sq415s: Downloading m3u8 information\n",
            "[info] 9qjk-Sq415s: Downloading 1 format(s): 18\n",
            "[download] 9qjk-Sq415s.mp4 has already been downloaded\n",
            "[download] 100% of   21.58MiB\n",
            "[download] Downloading item 6 of 6\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=-9ePkth7TSQ\n",
            "[youtube] -9ePkth7TSQ: Downloading webpage\n",
            "[youtube] -9ePkth7TSQ: Downloading ios player API JSON\n",
            "[youtube] -9ePkth7TSQ: Downloading web creator player API JSON\n",
            "[youtube] -9ePkth7TSQ: Downloading m3u8 information\n",
            "[info] -9ePkth7TSQ: Downloading 1 format(s): 18\n",
            "[download] -9ePkth7TSQ.mp4 has already been downloaded\n",
            "[download] 100% of   13.84MiB\n",
            "[download] Finished downloading playlist: In The Son-Rise Program® Playroom for Autism\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=DI25kGJis0w\n",
            "[youtube] DI25kGJis0w: Downloading webpage\n",
            "[youtube] DI25kGJis0w: Downloading ios player API JSON\n",
            "[youtube] DI25kGJis0w: Downloading web creator player API JSON\n",
            "[youtube] DI25kGJis0w: Downloading m3u8 information\n",
            "[info] DI25kGJis0w: Downloading 1 format(s): 18\n",
            "[download] DI25kGJis0w.mp4 has already been downloaded\n",
            "[download] 100% of    5.48MiB\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=rrLhFZG6iQY\n",
            "[youtube] rrLhFZG6iQY: Downloading webpage\n",
            "[youtube] rrLhFZG6iQY: Downloading ios player API JSON\n",
            "[youtube] rrLhFZG6iQY: Downloading web creator player API JSON\n",
            "[youtube] rrLhFZG6iQY: Downloading m3u8 information\n",
            "[info] rrLhFZG6iQY: Downloading 1 format(s): 18\n",
            "[download] rrLhFZG6iQY.mp4 has already been downloaded\n",
            "[download] 100% of   23.42MiB\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=RKOZbT0ftL4&t=1s\n",
            "[youtube] RKOZbT0ftL4: Downloading webpage\n",
            "[youtube] RKOZbT0ftL4: Downloading ios player API JSON\n",
            "[youtube] RKOZbT0ftL4: Downloading web creator player API JSON\n",
            "[youtube] RKOZbT0ftL4: Downloading m3u8 information\n",
            "[info] RKOZbT0ftL4: Downloading 1 format(s): 18\n",
            "[download] RKOZbT0ftL4.mp4 has already been downloaded\n",
            "[download] 100% of   94.98MiB\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=N7TBbWHB01E\n",
            "[youtube] N7TBbWHB01E: Downloading webpage\n",
            "[youtube] N7TBbWHB01E: Downloading ios player API JSON\n",
            "[youtube] N7TBbWHB01E: Downloading web creator player API JSON\n",
            "[youtube] N7TBbWHB01E: Downloading m3u8 information\n",
            "[info] N7TBbWHB01E: Downloading 1 format(s): 18\n",
            "[download] N7TBbWHB01E.mp4 has already been downloaded\n",
            "[download] 100% of   15.79MiB\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=1YqVEVbXQ1c\n",
            "[youtube] 1YqVEVbXQ1c: Downloading webpage\n",
            "[youtube] 1YqVEVbXQ1c: Downloading ios player API JSON\n",
            "[youtube] 1YqVEVbXQ1c: Downloading web creator player API JSON\n",
            "[youtube] 1YqVEVbXQ1c: Downloading m3u8 information\n",
            "[info] 1YqVEVbXQ1c: Downloading 1 format(s): 18\n",
            "[download] 1YqVEVbXQ1c.mp4 has already been downloaded\n",
            "[download] 100% of   97.98MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "-24ZKB6Obx6A"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize YOLOv8 model (or any other model of choice)\n",
        "model = YOLO('yolov8n.pt')\n"
      ],
      "metadata": {
        "id": "AJ98XReGcbme"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize DeepSORT tracker\n",
        "deepsort = DeepSort(max_age=30, n_init=3, nms_max_overlap=1.0, max_iou_distance=0.7)"
      ],
      "metadata": {
        "id": "U-s0ARuXci2p"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def process_frame(frame):\n",
        "    # Perform detection\n",
        "    results = model(frame)\n",
        "    detections = results[0].boxes.data.cpu().numpy()\n",
        "\n",
        "    # Extract bounding boxes and confidence scores\n",
        "    bbox_xywh = []\n",
        "    confidences = []\n",
        "    for *xyxy, conf, cls in detections:\n",
        "        if int(cls) == 0:  # Class 0 is 'person' in COCO dataset\n",
        "            x1, y1, x2, y2 = map(int, xyxy)\n",
        "            w = x2 - x1\n",
        "            h = y2 - y1\n",
        "            x_center = x1 + w / 2.0\n",
        "            y_center = y1 + h / 2.0\n",
        "            bbox_xywh.append([x_center, y_center, w, h])\n",
        "            confidences.append(float(conf))\n",
        "\n",
        "    bbox_xywh = np.array(bbox_xywh, dtype=np.float32)\n",
        "    confidences = np.array(confidences)\n",
        "\n",
        "    # Debugging: Print bounding boxes and their shape\n",
        "    print(\"Bounding boxes:\", bbox_xywh)\n",
        "    print(\"Bounding box shape:\", bbox_xywh.shape)\n",
        "    print(\"Confidences:\", confidences)\n",
        "    print(\"Confidences shape:\", confidences.shape)\n",
        "\n",
        "    # Format detections for DeepSORT\n",
        "    detections = [([x, y, w, h], conf, -1) for [x, y, w, h], conf in zip(bbox_xywh, confidences)]\n",
        "\n",
        "    print(\"Formatted detections:\", detections)\n",
        "\n",
        "    # Perform tracking with DeepSORT if there are any detections\n",
        "    if len(detections) > 0:\n",
        "        try:\n",
        "            outputs = deepsort.update_tracks(detections, embeds=None, frame=frame)\n",
        "        except Exception as e:\n",
        "            print(f\"Error in DeepSORT update: {e}\")\n",
        "            outputs = []\n",
        "    else:\n",
        "        outputs = []\n",
        "\n",
        "    # Draw bounding boxes and labels\n",
        "    for track in outputs:\n",
        "        if not track.is_confirmed():\n",
        "            continue\n",
        "        bbox = track.to_tlbr()\n",
        "        track_id = track.track_id\n",
        "        cv2.rectangle(frame, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (0, 255, 0), 2)\n",
        "        cv2.putText(frame, f\"ID: {track_id}\", (int(bbox[0]), int(bbox[1]) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    return frame"
      ],
      "metadata": {
        "id": "K7ermCdTcnhF"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_video(input_video_path, output_video_path):\n",
        "    video_capture = cv2.VideoCapture(input_video_path)\n",
        "    width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "    frame_count = 0\n",
        "    while video_capture.isOpened():\n",
        "        ret, frame = video_capture.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_count += 1\n",
        "        if frame_count % 100 == 0:\n",
        "            print(f\"Processing frame {frame_count}\")\n",
        "\n",
        "        try:\n",
        "            processed_frame = process_frame(frame)\n",
        "            out.write(processed_frame)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing frame {frame_count}: {e}\")\n",
        "            break\n",
        "\n",
        "    video_capture.release()\n",
        "    out.release()\n",
        "    print(f\"Finished processing {input_video_path}\")\n"
      ],
      "metadata": {
        "id": "8UQwU5chcuMf"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of downloaded video paths (assuming they are in /content/)\n",
        "video_paths = [\n",
        "    '/content/1YqVEVbXQ1c.mp4',\n",
        "    '/content/7pN6ydLE4EQ.mp4',\n",
        "    '/content/81fShK4roew.mp4',\n",
        "    '/content/9qjk-Sq415s.mp4',\n",
        "    '/content/DI25kGJis0w.mp4',\n",
        "    '/content/E8Wgwg3F4X0.mp4',\n",
        "    '/content/F6iqlW6ovZc.mp4',\n",
        "    '/content/GNVTuLHdeSo.mp4',\n",
        "    '/content/HGz2M8kvWqM.mp4',\n",
        "    '/content/Hd9marUY5GQ.mp4',\n",
        "    '/content/N7TBbWHB01E.mp4',\n",
        "    '/content/RKOZbT0ftL4.mp4',\n",
        "    '/content/RzI6Ar5mu2Q.mp4',\n",
        "    '/content/SWtmkjd45so.mp4',\n",
        "    '/content/V9YDDpo9LWg.mp4',\n",
        "    '/content/Wd3X_3C0et8.mp4',\n",
        "    '/content/aWV7UUMddCU.mp4',\n",
        "    '/content/aulLej6Z6W8.mp4',\n",
        "    '/content/ckZQbQwM3oU.mp4',\n",
        "    '/content/f6wqlpG9rd0.mp4',\n",
        "    '/content/rrLhFZG6iQY.mp4',\n",
        "    '/content/rvIPH4ccfpI.mp4',\n",
        "]\n"
      ],
      "metadata": {
        "id": "664j5HjLc2i6"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for video_path in video_paths:\n",
        "    output_video_path = video_path.replace('.webm', '_output.mp4').replace('.mkv', '_output.mp4').replace('.mp4', '_output.mp4')\n",
        "    try:\n",
        "        process_video(video_path, output_video_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing video {video_path}: {e}\")\n",
        "\n",
        "print(\"All videos processed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9Jhd810d-k0",
        "outputId": "14d34285-d051-492f-8ebe-32f2dbdda7d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Confidences: [    0.85012     0.83595]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([232.0, 184.5, 150.0, 271.0], 0.8501189351081848, -1), ([256.5, 213.0, 75.0, 218.0], 0.8359506726264954, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 1 refrigerator, 216.2ms\n",
            "Speed: 3.4ms preprocess, 216.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      231.5         184         149         270]\n",
            " [        254         213          76         220]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86041     0.83576]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([231.5, 184.0, 149.0, 270.0], 0.8604108095169067, -1), ([254.0, 213.0, 76.0, 220.0], 0.8357559442520142, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 1 refrigerator, 199.1ms\n",
            "Speed: 3.7ms preprocess, 199.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      231.5       185.5         149         271]\n",
            " [        255         212          76         220]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86189     0.83632]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([231.5, 185.5, 149.0, 271.0], 0.8618943095207214, -1), ([255.0, 212.0, 76.0, 220.0], 0.8363156318664551, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 1 refrigerator, 201.2ms\n",
            "Speed: 3.7ms preprocess, 201.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        232       185.5         150         271]\n",
            " [      250.5         206          79         214]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.8519     0.82123]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([232.0, 185.5, 150.0, 271.0], 0.8518974781036377, -1), ([250.5, 206.0, 79.0, 214.0], 0.8212293386459351, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 1 refrigerator, 223.7ms\n",
            "Speed: 3.7ms preprocess, 223.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        232         186         150         270]\n",
            " [      249.5       202.5          81         209]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86009     0.83248]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([232.0, 186.0, 150.0, 270.0], 0.8600872159004211, -1), ([249.5, 202.5, 81.0, 209.0], 0.8324810862541199, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 1 refrigerator, 203.1ms\n",
            "Speed: 6.0ms preprocess, 203.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        232         187         150         270]\n",
            " [        251       205.5          76         213]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85843     0.82517]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([232.0, 187.0, 150.0, 270.0], 0.8584338426589966, -1), ([251.0, 205.5, 76.0, 213.0], 0.8251726627349854, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 1 refrigerator, 210.1ms\n",
            "Speed: 3.7ms preprocess, 210.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        232       187.5         150         269]\n",
            " [      253.5       204.5          75         213]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86176     0.83255]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([232.0, 187.5, 150.0, 269.0], 0.8617622256278992, -1), ([253.5, 204.5, 75.0, 213.0], 0.832546591758728, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 1 car, 2 chairs, 1 refrigerator, 228.7ms\n",
            "Speed: 3.9ms preprocess, 228.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        232       187.5         150         269]\n",
            " [      254.5       201.5          75         207]\n",
            " [      247.5         200         103         222]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.87015      0.8424     0.35224]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([232.0, 187.5, 150.0, 269.0], 0.8701462745666504, -1), ([254.5, 201.5, 75.0, 207.0], 0.8423998951911926, -1), ([247.5, 200.0, 103.0, 222.0], 0.35223549604415894, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 1 refrigerator, 228.2ms\n",
            "Speed: 15.9ms preprocess, 228.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      232.5       187.5         151         269]\n",
            " [      257.5       202.5          73         207]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87191     0.83824]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([232.5, 187.5, 151.0, 269.0], 0.8719131946563721, -1), ([257.5, 202.5, 73.0, 207.0], 0.8382406830787659, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 1 car, 2 chairs, 1 refrigerator, 314.8ms\n",
            "Speed: 8.1ms preprocess, 314.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        233         187         152         268]\n",
            " [      259.5       201.5          77         205]\n",
            " [      252.5         190          99         244]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.87651     0.82869      0.3095]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([233.0, 187.0, 152.0, 268.0], 0.8765125274658203, -1), ([259.5, 201.5, 77.0, 205.0], 0.8286898732185364, -1), ([252.5, 190.0, 99.0, 244.0], 0.30949512124061584, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 1 refrigerator, 319.7ms\n",
            "Speed: 3.7ms preprocess, 319.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      232.5       187.5         151         269]\n",
            " [        262         201          76         202]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88942     0.83519]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([232.5, 187.5, 151.0, 269.0], 0.8894215822219849, -1), ([262.0, 201.0, 76.0, 202.0], 0.83519047498703, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 1 refrigerator, 279.3ms\n",
            "Speed: 4.3ms preprocess, 279.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        233         187         152         268]\n",
            " [        264       200.5          78         203]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [      0.888      0.8295]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([233.0, 187.0, 152.0, 268.0], 0.8879989385604858, -1), ([264.0, 200.5, 78.0, 203.0], 0.8295031189918518, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 1 refrigerator, 296.8ms\n",
            "Speed: 4.8ms preprocess, 296.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        233         187         154         270]\n",
            " [        265         201          78         202]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89563     0.83422]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([233.0, 187.0, 154.0, 270.0], 0.8956334590911865, -1), ([265.0, 201.0, 78.0, 202.0], 0.8342217803001404, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 1 refrigerator, 279.8ms\n",
            "Speed: 4.7ms preprocess, 279.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        234         187         156         270]\n",
            " [      266.5       200.5          79         201]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88561     0.80147]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([234.0, 187.0, 156.0, 270.0], 0.8856095671653748, -1), ([266.5, 200.5, 79.0, 201.0], 0.8014681339263916, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 1 refrigerator, 332.4ms\n",
            "Speed: 7.8ms preprocess, 332.4ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      234.5       187.5         155         269]\n",
            " [        269         202          80         204]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88882      0.7991]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([234.5, 187.5, 155.0, 269.0], 0.8888185620307922, -1), ([269.0, 202.0, 80.0, 204.0], 0.7991003394126892, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 1 refrigerator, 313.0ms\n",
            "Speed: 3.7ms preprocess, 313.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      234.5         187         159         268]\n",
            " [        272       210.5          82         221]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87496     0.80954]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([234.5, 187.0, 159.0, 268.0], 0.8749635219573975, -1), ([272.0, 210.5, 82.0, 221.0], 0.8095384836196899, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 1 refrigerator, 322.8ms\n",
            "Speed: 6.7ms preprocess, 322.8ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        234         188         160         270]\n",
            " [        274         212          84         220]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87361     0.81859]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([234.0, 188.0, 160.0, 270.0], 0.8736085891723633, -1), ([274.0, 212.0, 84.0, 220.0], 0.8185945153236389, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 304.8ms\n",
            "Speed: 10.8ms preprocess, 304.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        235         189         162         268]\n",
            " [      278.5       213.5          85         219]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87162     0.82942]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([235.0, 189.0, 162.0, 268.0], 0.8716244697570801, -1), ([278.5, 213.5, 85.0, 219.0], 0.8294242024421692, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 347.7ms\n",
            "Speed: 3.4ms preprocess, 347.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        235       189.5         164         265]\n",
            " [      281.5       213.5          83         217]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.8633     0.82827]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([235.0, 189.5, 164.0, 265.0], 0.8633008599281311, -1), ([281.5, 213.5, 83.0, 217.0], 0.8282732963562012, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 cars, 1 chair, 337.5ms\n",
            "Speed: 5.5ms preprocess, 337.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        235       189.5         166         263]\n",
            " [      284.5         212          83         208]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86329     0.84439]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([235.0, 189.5, 166.0, 263.0], 0.8632921576499939, -1), ([284.5, 212.0, 83.0, 208.0], 0.8443911671638489, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 cars, 1 chair, 1 refrigerator, 329.7ms\n",
            "Speed: 6.5ms preprocess, 329.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      234.5         191         165         262]\n",
            " [      286.5         211          83         202]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86634     0.86207]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([234.5, 191.0, 165.0, 262.0], 0.866344153881073, -1), ([286.5, 211.0, 83.0, 202.0], 0.8620724678039551, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 motorcycle, 1 chair, 1 refrigerator, 217.3ms\n",
            "Speed: 6.2ms preprocess, 217.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      235.5       191.5         169         261]\n",
            " [      287.5       215.5          89         205]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89519     0.84351]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([235.5, 191.5, 169.0, 261.0], 0.8951904773712158, -1), ([287.5, 215.5, 89.0, 205.0], 0.8435062170028687, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 chair, 1 refrigerator, 203.0ms\n",
            "Speed: 3.4ms preprocess, 203.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        236         193         170         258]\n",
            " [      287.5         217          93         198]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89382      0.8565]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([236.0, 193.0, 170.0, 258.0], 0.8938207626342773, -1), ([287.5, 217.0, 93.0, 198.0], 0.8564978241920471, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 1 refrigerator, 196.4ms\n",
            "Speed: 3.5ms preprocess, 196.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        238         194         178         256]\n",
            " [        288         214          96         186]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90502     0.86778]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([238.0, 194.0, 178.0, 256.0], 0.905017614364624, -1), ([288.0, 214.0, 96.0, 186.0], 0.8677813410758972, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 chair, 1 refrigerator, 214.1ms\n",
            "Speed: 3.4ms preprocess, 214.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        237       196.5         174         253]\n",
            " [        286         222          98         198]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89501     0.85838]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([237.0, 196.5, 174.0, 253.0], 0.895013689994812, -1), ([286.0, 222.0, 98.0, 198.0], 0.8583788871765137, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 1 refrigerator, 200.3ms\n",
            "Speed: 3.5ms preprocess, 200.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      237.5         197         175         250]\n",
            " [        286         223         100         198]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90175     0.86307]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([237.5, 197.0, 175.0, 250.0], 0.9017463326454163, -1), ([286.0, 223.0, 100.0, 198.0], 0.8630697131156921, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 1 refrigerator, 203.3ms\n",
            "Speed: 3.7ms preprocess, 203.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        237       198.5         176         249]\n",
            " [        283         224         106         196]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89775     0.87324]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([237.0, 198.5, 176.0, 249.0], 0.8977515697479248, -1), ([283.0, 224.0, 106.0, 196.0], 0.8732414245605469, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 1 refrigerator, 209.4ms\n",
            "Speed: 4.2ms preprocess, 209.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        237         199         178         248]\n",
            " [      279.5         224         115         194]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89222     0.85381]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([237.0, 199.0, 178.0, 248.0], 0.8922168016433716, -1), ([279.5, 224.0, 115.0, 194.0], 0.8538070917129517, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 1 refrigerator, 207.0ms\n",
            "Speed: 7.7ms preprocess, 207.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      237.5       199.5         179         247]\n",
            " [        279       224.5         118         193]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88837     0.86785]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([237.5, 199.5, 179.0, 247.0], 0.8883702158927917, -1), ([279.0, 224.5, 118.0, 193.0], 0.8678496479988098, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 1 refrigerator, 209.3ms\n",
            "Speed: 4.2ms preprocess, 209.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        238       199.5         180         247]\n",
            " [      278.5       224.5         123         193]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88541     0.86397]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([238.0, 199.5, 180.0, 247.0], 0.8854108452796936, -1), ([278.5, 224.5, 123.0, 193.0], 0.8639683127403259, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 1 refrigerator, 197.3ms\n",
            "Speed: 3.4ms preprocess, 197.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        238       200.5         182         247]\n",
            " [        282         225         122         190]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88535     0.85231]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([238.0, 200.5, 182.0, 247.0], 0.8853509426116943, -1), ([282.0, 225.0, 122.0, 190.0], 0.8523114919662476, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 1 refrigerator, 208.7ms\n",
            "Speed: 3.6ms preprocess, 208.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        238       201.5         182         245]\n",
            " [      282.5         225         123         188]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.8608     0.85488]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([238.0, 201.5, 182.0, 245.0], 0.8608033061027527, -1), ([282.5, 225.0, 123.0, 188.0], 0.8548769354820251, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 1 refrigerator, 217.5ms\n",
            "Speed: 3.4ms preprocess, 217.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      283.5       225.5         123         187]\n",
            " [        238       201.5         182         241]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86556     0.86535]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([283.5, 225.5, 123.0, 187.0], 0.8655550479888916, -1), ([238.0, 201.5, 182.0, 241.0], 0.8653524518013, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 1 refrigerator, 216.7ms\n",
            "Speed: 12.7ms preprocess, 216.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        285       226.5         124         187]\n",
            " [        238         202         184         242]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86759     0.84711]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([285.0, 226.5, 124.0, 187.0], 0.86758953332901, -1), ([238.0, 202.0, 184.0, 242.0], 0.8471141457557678, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 1 refrigerator, 231.4ms\n",
            "Speed: 3.4ms preprocess, 231.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      286.5         227         125         188]\n",
            " [        238         203         184         240]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88758     0.83184]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([286.5, 227.0, 125.0, 188.0], 0.8875828981399536, -1), ([238.0, 203.0, 184.0, 240.0], 0.8318402171134949, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 1 refrigerator, 236.1ms\n",
            "Speed: 3.8ms preprocess, 236.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        288       226.5         126         187]\n",
            " [      238.5       202.5         185         239]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86528     0.83748]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([288.0, 226.5, 126.0, 187.0], 0.8652752041816711, -1), ([238.5, 202.5, 185.0, 239.0], 0.837483823299408, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 1 refrigerator, 234.2ms\n",
            "Speed: 8.0ms preprocess, 234.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        289         227         128         188]\n",
            " [        241         204         188         238]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86639     0.81541]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([289.0, 227.0, 128.0, 188.0], 0.8663923144340515, -1), ([241.0, 204.0, 188.0, 238.0], 0.815414547920227, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 cars, 2 chairs, 1 refrigerator, 238.8ms\n",
            "Speed: 4.3ms preprocess, 238.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      290.5         227         131         186]\n",
            " [        241       204.5         188         237]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87259     0.83054]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([290.5, 227.0, 131.0, 186.0], 0.8725853562355042, -1), ([241.0, 204.5, 188.0, 237.0], 0.8305383324623108, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 1 refrigerator, 224.7ms\n",
            "Speed: 9.2ms preprocess, 224.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        291       226.5         132         185]\n",
            " [        241         205         188         236]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87279     0.81666]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([291.0, 226.5, 132.0, 185.0], 0.8727914690971375, -1), ([241.0, 205.0, 188.0, 236.0], 0.8166558742523193, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 3 chairs, 1 refrigerator, 227.1ms\n",
            "Speed: 4.3ms preprocess, 227.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        294         226         132         184]\n",
            " [      238.5       205.5         185         235]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.82273     0.71444]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([294.0, 226.0, 132.0, 184.0], 0.822733998298645, -1), ([238.5, 205.5, 185.0, 235.0], 0.7144439816474915, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 3 chairs, 1 refrigerator, 240.9ms\n",
            "Speed: 3.5ms preprocess, 240.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      299.5         224         125         182]\n",
            " [      238.5       205.5         185         235]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.81318     0.79005]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([299.5, 224.0, 125.0, 182.0], 0.8131828308105469, -1), ([238.5, 205.5, 185.0, 235.0], 0.79005366563797, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 3 chairs, 1 refrigerator, 223.2ms\n",
            "Speed: 10.5ms preprocess, 223.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      295.5       221.5         135         175]\n",
            " [      238.5         206         185         234]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.8252     0.82235]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([295.5, 221.5, 135.0, 175.0], 0.8252004981040955, -1), ([238.5, 206.0, 185.0, 234.0], 0.8223538398742676, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 1 refrigerator, 232.0ms\n",
            "Speed: 3.7ms preprocess, 232.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      293.5       220.5         137         173]\n",
            " [      239.5         206         187         230]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.78947     0.73426]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([293.5, 220.5, 137.0, 173.0], 0.7894662618637085, -1), ([239.5, 206.0, 187.0, 230.0], 0.7342575192451477, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 1 refrigerator, 220.2ms\n",
            "Speed: 5.2ms preprocess, 220.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        294       221.5         140         173]\n",
            " [        238         207         186         228]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.82108     0.71761]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([294.0, 221.5, 140.0, 173.0], 0.8210824131965637, -1), ([238.0, 207.0, 186.0, 228.0], 0.7176123261451721, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 1 refrigerator, 238.5ms\n",
            "Speed: 3.6ms preprocess, 238.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      292.5       221.5         143         173]\n",
            " [      237.5       206.5         185         227]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.83978     0.67589]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([292.5, 221.5, 143.0, 173.0], 0.8397813439369202, -1), ([237.5, 206.5, 185.0, 227.0], 0.6758924722671509, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 1 refrigerator, 233.2ms\n",
            "Speed: 3.6ms preprocess, 233.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        297         219         136         168]\n",
            " [      237.5       205.5         185         225]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.82168     0.65144]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([297.0, 219.0, 136.0, 168.0], 0.8216755390167236, -1), ([237.5, 205.5, 185.0, 225.0], 0.6514411568641663, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 3 chairs, 1 refrigerator, 250.8ms\n",
            "Speed: 3.6ms preprocess, 250.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        291       220.5         148         171]\n",
            " [      230.5       207.5         169         233]\n",
            " [        286       179.5          84         161]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.81974     0.55906     0.35251]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([291.0, 220.5, 148.0, 171.0], 0.819736659526825, -1), ([230.5, 207.5, 169.0, 233.0], 0.5590586066246033, -1), ([286.0, 179.5, 84.0, 161.0], 0.352511465549469, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 4 chairs, 1 refrigerator, 217.7ms\n",
            "Speed: 10.6ms preprocess, 217.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        288         221         154         176]\n",
            " [        230         207         168         232]\n",
            " [        286       177.5          84         155]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.85132     0.70459     0.34951]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([288.0, 221.0, 154.0, 176.0], 0.8513194918632507, -1), ([230.0, 207.0, 168.0, 232.0], 0.7045892477035522, -1), ([286.0, 177.5, 84.0, 155.0], 0.34950995445251465, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 4 chairs, 1 refrigerator, 221.8ms\n",
            "Speed: 8.6ms preprocess, 221.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      287.5         222         155         176]\n",
            " [      232.5       207.5         173         231]\n",
            " [      285.5         173          85         146]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.85305     0.68661     0.38523]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([287.5, 222.0, 155.0, 176.0], 0.8530520796775818, -1), ([232.5, 207.5, 173.0, 231.0], 0.6866074800491333, -1), ([285.5, 173.0, 85.0, 146.0], 0.3852253556251526, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 1 refrigerator, 229.8ms\n",
            "Speed: 3.4ms preprocess, 229.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      288.5       220.5         153         179]\n",
            " [        237         207         182         228]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85991     0.72017]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([288.5, 220.5, 153.0, 179.0], 0.8599053621292114, -1), ([237.0, 207.0, 182.0, 228.0], 0.7201681733131409, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 1 refrigerator, 316.7ms\n",
            "Speed: 5.1ms preprocess, 316.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        294       219.5         142         177]\n",
            " [        238         207         184         230]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85016     0.81929]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([294.0, 219.5, 142.0, 177.0], 0.8501573801040649, -1), ([238.0, 207.0, 184.0, 230.0], 0.8192880153656006, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 1 refrigerator, 312.4ms\n",
            "Speed: 11.9ms preprocess, 312.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        298         218         136         176]\n",
            " [        238       207.5         184         229]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.82584     0.82176]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([298.0, 218.0, 136.0, 176.0], 0.8258411884307861, -1), ([238.0, 207.5, 184.0, 229.0], 0.8217628598213196, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 1 refrigerator, 292.4ms\n",
            "Speed: 3.5ms preprocess, 292.4ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      237.5         208         183         228]\n",
            " [      297.5       221.5         135         183]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.8424      0.8345]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([237.5, 208.0, 183.0, 228.0], 0.8424015641212463, -1), ([297.5, 221.5, 135.0, 183.0], 0.8345028758049011, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 1 refrigerator, 341.5ms\n",
            "Speed: 7.1ms preprocess, 341.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      237.5         208         183         228]\n",
            " [      298.5         224         133         188]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85253     0.81507]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([237.5, 208.0, 183.0, 228.0], 0.8525307774543762, -1), ([298.5, 224.0, 133.0, 188.0], 0.8150702118873596, -1)]\n",
            "Processing frame 1500\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 1 refrigerator, 320.9ms\n",
            "Speed: 8.0ms preprocess, 320.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      297.5         223         133         184]\n",
            " [        238       208.5         184         229]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.83344     0.82075]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([297.5, 223.0, 133.0, 184.0], 0.833439290523529, -1), ([238.0, 208.5, 184.0, 229.0], 0.8207513093948364, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 1 refrigerator, 346.5ms\n",
            "Speed: 10.2ms preprocess, 346.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      301.5       220.5         123         179]\n",
            " [      238.5         209         185         228]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85499     0.83506]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([301.5, 220.5, 123.0, 179.0], 0.8549932241439819, -1), ([238.5, 209.0, 185.0, 228.0], 0.8350620865821838, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 1 refrigerator, 315.4ms\n",
            "Speed: 13.9ms preprocess, 315.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        238       207.5         184         227]\n",
            " [      302.5       220.5         121         179]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85825     0.83934]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([238.0, 207.5, 184.0, 227.0], 0.858251690864563, -1), ([302.5, 220.5, 121.0, 179.0], 0.839344322681427, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 1 refrigerator, 322.3ms\n",
            "Speed: 14.8ms preprocess, 322.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        238       207.5         184         227]\n",
            " [      303.5       222.5         119         183]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86543     0.84263]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([238.0, 207.5, 184.0, 227.0], 0.8654319643974304, -1), ([303.5, 222.5, 119.0, 183.0], 0.8426291942596436, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 1 refrigerator, 311.2ms\n",
            "Speed: 10.8ms preprocess, 311.2ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        238       208.5         182         227]\n",
            " [        303         225         120         188]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87534     0.84915]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([238.0, 208.5, 182.0, 227.0], 0.8753411769866943, -1), ([303.0, 225.0, 120.0, 188.0], 0.849147379398346, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 1 car, 2 chairs, 1 refrigerator, 341.0ms\n",
            "Speed: 8.7ms preprocess, 341.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        236       208.5         178         229]\n",
            " [        305         225         116         188]\n",
            " [        316         190          94         116]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.90161     0.76043     0.35881]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([236.0, 208.5, 178.0, 229.0], 0.9016072750091553, -1), ([305.0, 225.0, 116.0, 188.0], 0.7604308724403381, -1), ([316.0, 190.0, 94.0, 116.0], 0.3588126003742218, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 1 car, 2 chairs, 1 refrigerator, 333.6ms\n",
            "Speed: 9.3ms preprocess, 333.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      235.5         208         177         230]\n",
            " [      303.5       225.5         113         187]\n",
            " [      317.5       191.5          91         117]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [     0.9164     0.72691     0.37927]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([235.5, 208.0, 177.0, 230.0], 0.9163973927497864, -1), ([303.5, 225.5, 113.0, 187.0], 0.7269087433815002, -1), ([317.5, 191.5, 91.0, 117.0], 0.37927308678627014, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 3 chairs, 1 refrigerator, 306.1ms\n",
            "Speed: 3.8ms preprocess, 306.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      234.5       207.5         175         231]\n",
            " [      302.5       226.5         115         187]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91524     0.79597]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([234.5, 207.5, 175.0, 231.0], 0.9152445197105408, -1), ([302.5, 226.5, 115.0, 187.0], 0.7959727048873901, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 1 refrigerator, 234.0ms\n",
            "Speed: 9.5ms preprocess, 234.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      233.5       206.5         171         231]\n",
            " [      302.5         224         119         186]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91914     0.81273]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([233.5, 206.5, 171.0, 231.0], 0.9191376566886902, -1), ([302.5, 224.0, 119.0, 186.0], 0.8127256631851196, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 cars, 2 chairs, 1 refrigerator, 203.5ms\n",
            "Speed: 3.7ms preprocess, 203.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      233.5       205.5         169         233]\n",
            " [        302         223         122         186]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.93131     0.79589]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([233.5, 205.5, 169.0, 233.0], 0.9313077926635742, -1), ([302.0, 223.0, 122.0, 186.0], 0.7958942651748657, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 1 refrigerator, 226.8ms\n",
            "Speed: 18.4ms preprocess, 226.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      233.5         205         169         234]\n",
            " [        298       225.5         130         189]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.92922     0.87329]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([233.5, 205.0, 169.0, 234.0], 0.9292199015617371, -1), ([298.0, 225.5, 130.0, 189.0], 0.8732854723930359, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 1 refrigerator, 205.7ms\n",
            "Speed: 3.7ms preprocess, 205.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        234       204.5         166         235]\n",
            " [        293         226         138         188]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91247     0.84983]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([234.0, 204.5, 166.0, 235.0], 0.9124715328216553, -1), ([293.0, 226.0, 138.0, 188.0], 0.8498262166976929, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 1 refrigerator, 227.8ms\n",
            "Speed: 3.6ms preprocess, 227.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        230       204.5         160         235]\n",
            " [        294         227         136         190]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.93033     0.88372]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([230.0, 204.5, 160.0, 235.0], 0.9303334951400757, -1), ([294.0, 227.0, 136.0, 190.0], 0.8837192058563232, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 1 refrigerator, 225.5ms\n",
            "Speed: 3.8ms preprocess, 225.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        229         204         156         234]\n",
            " [      293.5       226.5         137         189]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.92748      0.8848]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([229.0, 204.0, 156.0, 234.0], 0.9274804592132568, -1), ([293.5, 226.5, 137.0, 189.0], 0.8847951292991638, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 1 refrigerator, 240.7ms\n",
            "Speed: 3.5ms preprocess, 240.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        228       204.5         156         235]\n",
            " [      292.5       227.5         137         189]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.92486     0.88044]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([228.0, 204.5, 156.0, 235.0], 0.9248631000518799, -1), ([292.5, 227.5, 137.0, 189.0], 0.8804370760917664, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 1 refrigerator, 230.7ms\n",
            "Speed: 3.7ms preprocess, 230.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        227       205.5         154         233]\n",
            " [        293       227.5         138         189]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.9231     0.88513]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([227.0, 205.5, 154.0, 233.0], 0.9231017827987671, -1), ([293.0, 227.5, 138.0, 189.0], 0.8851314187049866, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 1 refrigerator, 205.5ms\n",
            "Speed: 4.0ms preprocess, 205.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        227         206         152         232]\n",
            " [      292.5         228         139         188]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90639     0.88951]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([227.0, 206.0, 152.0, 232.0], 0.906387984752655, -1), ([292.5, 228.0, 139.0, 188.0], 0.8895132541656494, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 1 refrigerator, 240.3ms\n",
            "Speed: 6.6ms preprocess, 240.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        226       206.5         152         229]\n",
            " [      294.5         228         135         190]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91024     0.88941]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([226.0, 206.5, 152.0, 229.0], 0.910239577293396, -1), ([294.5, 228.0, 135.0, 190.0], 0.8894129991531372, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 1 refrigerator, 250.2ms\n",
            "Speed: 8.1ms preprocess, 250.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      225.5       207.5         151         227]\n",
            " [        295         229         134         190]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.9004     0.89037]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([225.5, 207.5, 151.0, 227.0], 0.9004027843475342, -1), ([295.0, 229.0, 134.0, 190.0], 0.8903726935386658, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 1 refrigerator, 203.9ms\n",
            "Speed: 3.9ms preprocess, 203.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      223.5         209         147         224]\n",
            " [        296         229         130         188]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.9148     0.88761]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([223.5, 209.0, 147.0, 224.0], 0.9148001670837402, -1), ([296.0, 229.0, 130.0, 188.0], 0.8876097202301025, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 1 refrigerator, 233.5ms\n",
            "Speed: 8.6ms preprocess, 233.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      221.5         211         147         222]\n",
            " [        300         229         122         188]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.92192     0.88629]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([221.5, 211.0, 147.0, 222.0], 0.9219223856925964, -1), ([300.0, 229.0, 122.0, 188.0], 0.8862863183021545, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 1 refrigerator, 220.8ms\n",
            "Speed: 5.7ms preprocess, 220.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        220       211.5         146         221]\n",
            " [        301       227.5         122         189]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.9312     0.87851]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([220.0, 211.5, 146.0, 221.0], 0.9312030076980591, -1), ([301.0, 227.5, 122.0, 189.0], 0.8785067796707153, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 3 chairs, 1 refrigerator, 223.4ms\n",
            "Speed: 7.7ms preprocess, 223.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      219.5         213         145         218]\n",
            " [      303.5         227         117         188]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.92816     0.85753]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([219.5, 213.0, 145.0, 218.0], 0.9281604290008545, -1), ([303.5, 227.0, 117.0, 188.0], 0.8575262427330017, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 1 refrigerator, 221.3ms\n",
            "Speed: 7.8ms preprocess, 221.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        218         215         146         214]\n",
            " [      303.5       227.5         117         187]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.9234     0.85588]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([218.0, 215.0, 146.0, 214.0], 0.923399806022644, -1), ([303.5, 227.5, 117.0, 187.0], 0.8558771014213562, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 1 refrigerator, 219.0ms\n",
            "Speed: 6.3ms preprocess, 219.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        216       216.5         144         211]\n",
            " [      303.5         226         117         186]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.92068     0.85331]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([216.0, 216.5, 144.0, 211.0], 0.9206796884536743, -1), ([303.5, 226.0, 117.0, 186.0], 0.8533111214637756, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 1 refrigerator, 234.6ms\n",
            "Speed: 10.6ms preprocess, 234.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        214         218         142         208]\n",
            " [      304.5         226         115         184]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91194      0.8769]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([214.0, 218.0, 142.0, 208.0], 0.9119367599487305, -1), ([304.5, 226.0, 115.0, 184.0], 0.876899003982544, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 1 refrigerator, 230.3ms\n",
            "Speed: 3.5ms preprocess, 230.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      212.5         220         143         206]\n",
            " [      304.5         226         113         184]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89562     0.86628]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([212.5, 220.0, 143.0, 206.0], 0.8956193327903748, -1), ([304.5, 226.0, 113.0, 184.0], 0.8662803769111633, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 3 chairs, 1 refrigerator, 237.0ms\n",
            "Speed: 8.3ms preprocess, 237.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        211         221         142         204]\n",
            " [      304.5       226.5         113         185]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91444     0.85904]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([211.0, 221.0, 142.0, 204.0], 0.9144423604011536, -1), ([304.5, 226.5, 113.0, 185.0], 0.8590351343154907, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 3 chairs, 1 refrigerator, 209.0ms\n",
            "Speed: 4.1ms preprocess, 209.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        209         223         142         200]\n",
            " [      304.5         227         113         186]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91621     0.86736]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([209.0, 223.0, 142.0, 200.0], 0.9162082672119141, -1), ([304.5, 227.0, 113.0, 186.0], 0.8673616051673889, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 3 chairs, 1 refrigerator, 237.7ms\n",
            "Speed: 6.9ms preprocess, 237.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        208         224         138         198]\n",
            " [        305       226.5         112         185]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91049     0.84187]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([208.0, 224.0, 138.0, 198.0], 0.9104903340339661, -1), ([305.0, 226.5, 112.0, 185.0], 0.8418667912483215, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 4 chairs, 1 refrigerator, 206.8ms\n",
            "Speed: 3.5ms preprocess, 206.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      206.5       224.5         137         197]\n",
            " [        305         227         112         186]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.9123      0.8235]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([206.5, 224.5, 137.0, 197.0], 0.9123044013977051, -1), ([305.0, 227.0, 112.0, 186.0], 0.823496401309967, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 4 chairs, 1 refrigerator, 224.0ms\n",
            "Speed: 3.5ms preprocess, 224.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      204.5         225         135         196]\n",
            " [      304.5       226.5         113         187]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90854     0.85134]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([204.5, 225.0, 135.0, 196.0], 0.9085424542427063, -1), ([304.5, 226.5, 113.0, 187.0], 0.8513386845588684, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 1 refrigerator, 232.6ms\n",
            "Speed: 3.9ms preprocess, 232.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      202.5         225         133         196]\n",
            " [      303.5         228         115         190]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91278     0.87414]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([202.5, 225.0, 133.0, 196.0], 0.9127811789512634, -1), ([303.5, 228.0, 115.0, 190.0], 0.8741382360458374, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 1 refrigerator, 233.4ms\n",
            "Speed: 3.5ms preprocess, 233.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        201       225.5         130         195]\n",
            " [        303       228.5         116         191]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89412      0.8734]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([201.0, 225.5, 130.0, 195.0], 0.8941197395324707, -1), ([303.0, 228.5, 116.0, 191.0], 0.873403012752533, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 3 chairs, 1 refrigerator, 250.7ms\n",
            "Speed: 16.6ms preprocess, 250.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      197.5         224         127         198]\n",
            " [        303       227.5         116         189]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90738      0.8707]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([197.5, 224.0, 127.0, 198.0], 0.9073830246925354, -1), ([303.0, 227.5, 116.0, 189.0], 0.8707022666931152, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 3 chairs, 1 refrigerator, 236.0ms\n",
            "Speed: 3.5ms preprocess, 236.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      193.5         223         127         202]\n",
            " [      303.5         227         115         186]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89526     0.86993]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([193.5, 223.0, 127.0, 202.0], 0.8952611088752747, -1), ([303.5, 227.0, 115.0, 186.0], 0.8699305653572083, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 1 refrigerator, 311.0ms\n",
            "Speed: 3.5ms preprocess, 311.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        190         222         122         204]\n",
            " [        303       227.5         116         187]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89549     0.87104]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([190.0, 222.0, 122.0, 204.0], 0.8954854607582092, -1), ([303.0, 227.5, 116.0, 187.0], 0.8710384368896484, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 1 refrigerator, 324.1ms\n",
            "Speed: 6.3ms preprocess, 324.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        188         220         120         206]\n",
            " [      302.5       227.5         115         187]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.9023     0.88019]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([188.0, 220.0, 120.0, 206.0], 0.902302622795105, -1), ([302.5, 227.5, 115.0, 187.0], 0.880194365978241, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 1 refrigerator, 326.0ms\n",
            "Speed: 8.0ms preprocess, 326.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      187.5       217.5         117         211]\n",
            " [      302.5         228         115         188]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90374     0.88047]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([187.5, 217.5, 117.0, 211.0], 0.9037392735481262, -1), ([302.5, 228.0, 115.0, 188.0], 0.8804717063903809, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 1 refrigerator, 333.7ms\n",
            "Speed: 10.7ms preprocess, 333.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        187         216         116         214]\n",
            " [        302         228         116         188]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90535     0.87874]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([187.0, 216.0, 116.0, 214.0], 0.9053452014923096, -1), ([302.0, 228.0, 116.0, 188.0], 0.8787375688552856, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 1 refrigerator, 277.4ms\n",
            "Speed: 3.4ms preprocess, 277.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      186.5       213.5         117         217]\n",
            " [        302         228         116         188]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89216     0.86863]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([186.5, 213.5, 117.0, 217.0], 0.8921605944633484, -1), ([302.0, 228.0, 116.0, 188.0], 0.8686328530311584, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 1 refrigerator, 333.9ms\n",
            "Speed: 9.5ms preprocess, 333.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      186.5       212.5         115         221]\n",
            " [        302         228         116         188]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90272      0.8734]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([186.5, 212.5, 115.0, 221.0], 0.9027233123779297, -1), ([302.0, 228.0, 116.0, 188.0], 0.873400092124939, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 1 refrigerator, 337.9ms\n",
            "Speed: 3.5ms preprocess, 337.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      185.5         211         117         222]\n",
            " [      300.5         228         117         190]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89347     0.87713]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([185.5, 211.0, 117.0, 222.0], 0.8934749960899353, -1), ([300.5, 228.0, 117.0, 190.0], 0.8771273493766785, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 1 refrigerator, 328.4ms\n",
            "Speed: 8.7ms preprocess, 328.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      184.5       209.5         115         225]\n",
            " [        300         228         118         190]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.8996     0.88445]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([184.5, 209.5, 115.0, 225.0], 0.89959716796875, -1), ([300.0, 228.0, 118.0, 190.0], 0.8844513297080994, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 1 refrigerator, 1 book, 314.7ms\n",
            "Speed: 3.6ms preprocess, 314.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      183.5         209         115         226]\n",
            " [        299       228.5         120         191]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91018     0.88672]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([183.5, 209.0, 115.0, 226.0], 0.9101848006248474, -1), ([299.0, 228.5, 120.0, 191.0], 0.8867197036743164, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 1 refrigerator, 1 book, 331.6ms\n",
            "Speed: 4.4ms preprocess, 331.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      182.5       208.5         115         227]\n",
            " [      301.5       228.5         115         189]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90893     0.87573]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([182.5, 208.5, 115.0, 227.0], 0.9089305996894836, -1), ([301.5, 228.5, 115.0, 189.0], 0.8757280707359314, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 1 refrigerator, 311.9ms\n",
            "Speed: 12.6ms preprocess, 311.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      181.5         208         115         228]\n",
            " [        302       228.5         114         189]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.9077     0.87853]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([181.5, 208.0, 115.0, 228.0], 0.9076984524726868, -1), ([302.0, 228.5, 114.0, 189.0], 0.8785252571105957, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 1 refrigerator, 325.4ms\n",
            "Speed: 3.6ms preprocess, 325.4ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        180       207.5         114         229]\n",
            " [        300         229         116         190]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.8963     0.88234]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([180.0, 207.5, 114.0, 229.0], 0.8963039517402649, -1), ([300.0, 229.0, 116.0, 190.0], 0.8823372721672058, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 1 refrigerator, 235.9ms\n",
            "Speed: 3.6ms preprocess, 235.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      181.5         207         115         230]\n",
            " [      300.5       228.5         115         191]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90376     0.88532]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([181.5, 207.0, 115.0, 230.0], 0.9037560820579529, -1), ([300.5, 228.5, 115.0, 191.0], 0.8853210210800171, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 1 refrigerator, 234.8ms\n",
            "Speed: 14.1ms preprocess, 234.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        182       206.5         116         231]\n",
            " [      300.5       227.5         115         191]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90826     0.88556]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([182.0, 206.5, 116.0, 231.0], 0.9082573056221008, -1), ([300.5, 227.5, 115.0, 191.0], 0.8855587840080261, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 1 refrigerator, 234.1ms\n",
            "Speed: 6.5ms preprocess, 234.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      182.5         206         115         230]\n",
            " [      300.5       227.5         115         191]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90797     0.87942]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([182.5, 206.0, 115.0, 230.0], 0.907969057559967, -1), ([300.5, 227.5, 115.0, 191.0], 0.8794229626655579, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 1 refrigerator, 228.1ms\n",
            "Speed: 3.6ms preprocess, 228.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        183       206.5         116         231]\n",
            " [      300.5       227.5         115         191]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90867     0.87881]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([183.0, 206.5, 116.0, 231.0], 0.9086735248565674, -1), ([300.5, 227.5, 115.0, 191.0], 0.8788067102432251, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 1 refrigerator, 1 book, 220.9ms\n",
            "Speed: 3.8ms preprocess, 220.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        183       206.5         116         231]\n",
            " [      300.5       227.5         115         191]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90981     0.88003]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([183.0, 206.5, 116.0, 231.0], 0.9098094701766968, -1), ([300.5, 227.5, 115.0, 191.0], 0.8800334930419922, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 1 refrigerator, 244.3ms\n",
            "Speed: 3.5ms preprocess, 244.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        183         206         116         230]\n",
            " [        301         227         114         190]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90517     0.87668]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([183.0, 206.0, 116.0, 230.0], 0.9051727652549744, -1), ([301.0, 227.0, 114.0, 190.0], 0.8766784071922302, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 1 refrigerator, 218.7ms\n",
            "Speed: 3.4ms preprocess, 218.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        184       207.5         116         229]\n",
            " [      300.5       227.5         115         191]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90361     0.88649]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([184.0, 207.5, 116.0, 229.0], 0.9036099910736084, -1), ([300.5, 227.5, 115.0, 191.0], 0.8864912390708923, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 228.3ms\n",
            "Speed: 3.8ms preprocess, 228.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        184         208         118         228]\n",
            " [      299.5       227.5         117         191]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90147     0.88998]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([184.0, 208.0, 118.0, 228.0], 0.9014714360237122, -1), ([299.5, 227.5, 117.0, 191.0], 0.8899838924407959, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 238.9ms\n",
            "Speed: 6.8ms preprocess, 238.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      184.5         208         117         228]\n",
            " [      299.5         227         117         192]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90744     0.88533]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([184.5, 208.0, 117.0, 228.0], 0.9074446558952332, -1), ([299.5, 227.0, 117.0, 192.0], 0.8853264451026917, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 225.2ms\n",
            "Speed: 6.6ms preprocess, 225.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        185       208.5         116         227]\n",
            " [      299.5         227         117         192]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90969     0.88758]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([185.0, 208.5, 116.0, 227.0], 0.9096858501434326, -1), ([299.5, 227.0, 117.0, 192.0], 0.8875780701637268, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 218.7ms\n",
            "Speed: 3.4ms preprocess, 218.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      185.5         209         117         226]\n",
            " [        299         227         118         192]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91106      0.8882]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([185.5, 209.0, 117.0, 226.0], 0.9110645651817322, -1), ([299.0, 227.0, 118.0, 192.0], 0.8882040977478027, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 236.2ms\n",
            "Speed: 3.6ms preprocess, 236.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      185.5       208.5         117         225]\n",
            " [      298.5         227         117         192]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.9084     0.89104]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([185.5, 208.5, 117.0, 225.0], 0.908402144908905, -1), ([298.5, 227.0, 117.0, 192.0], 0.8910442590713501, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 224.1ms\n",
            "Speed: 8.9ms preprocess, 224.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        186       209.5         116         225]\n",
            " [        298       227.5         120         191]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89819     0.89434]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([186.0, 209.5, 116.0, 225.0], 0.8981907963752747, -1), ([298.0, 227.5, 120.0, 191.0], 0.8943417072296143, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 236.6ms\n",
            "Speed: 7.9ms preprocess, 236.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        299         227         118         192]\n",
            " [      185.5       209.5         115         225]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89453     0.89233]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([299.0, 227.0, 118.0, 192.0], 0.8945295214653015, -1), ([185.5, 209.5, 115.0, 225.0], 0.892328679561615, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 205.8ms\n",
            "Speed: 13.6ms preprocess, 205.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        299       227.5         118         193]\n",
            " [        185       209.5         116         225]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89373     0.89277]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([299.0, 227.5, 118.0, 193.0], 0.8937259316444397, -1), ([185.0, 209.5, 116.0, 225.0], 0.8927726745605469, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 240.2ms\n",
            "Speed: 12.7ms preprocess, 240.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      185.5         210         115         224]\n",
            " [      299.5       227.5         117         191]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89593     0.89342]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([185.5, 210.0, 115.0, 224.0], 0.8959294557571411, -1), ([299.5, 227.5, 117.0, 191.0], 0.8934221863746643, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 216.4ms\n",
            "Speed: 14.6ms preprocess, 216.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        185         210         116         224]\n",
            " [      299.5         228         117         192]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89952     0.89113]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([185.0, 210.0, 116.0, 224.0], 0.8995150923728943, -1), ([299.5, 228.0, 117.0, 192.0], 0.8911306262016296, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 235.4ms\n",
            "Speed: 7.7ms preprocess, 235.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        185         210         116         224]\n",
            " [        300         228         116         192]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90284     0.88919]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([185.0, 210.0, 116.0, 224.0], 0.9028394222259521, -1), ([300.0, 228.0, 116.0, 192.0], 0.889187216758728, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 236.3ms\n",
            "Speed: 3.4ms preprocess, 236.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      183.5         210         115         224]\n",
            " [        300       227.5         116         191]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90341     0.87116]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([183.5, 210.0, 115.0, 224.0], 0.9034104943275452, -1), ([300.0, 227.5, 116.0, 191.0], 0.8711622953414917, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 1 book, 208.8ms\n",
            "Speed: 3.5ms preprocess, 208.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      183.5         210         117         224]\n",
            " [        299         228         116         192]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91194     0.86935]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([183.5, 210.0, 117.0, 224.0], 0.9119393229484558, -1), ([299.0, 228.0, 116.0, 192.0], 0.869353711605072, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 1 book, 293.9ms\n",
            "Speed: 13.7ms preprocess, 293.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      182.5       209.5         117         225]\n",
            " [      298.5         228         117         192]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91289     0.87174]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([182.5, 209.5, 117.0, 225.0], 0.912889301776886, -1), ([298.5, 228.0, 117.0, 192.0], 0.8717438578605652, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 1 book, 220.1ms\n",
            "Speed: 3.9ms preprocess, 220.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      182.5       209.5         117         225]\n",
            " [        297         228         118         192]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90879     0.88432]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([182.5, 209.5, 117.0, 225.0], 0.9087863564491272, -1), ([297.0, 228.0, 118.0, 192.0], 0.8843246102333069, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 cars, 2 chairs, 1 book, 249.7ms\n",
            "Speed: 3.4ms preprocess, 249.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      181.5       209.5         117         225]\n",
            " [        296       228.5         118         193]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90402     0.89385]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([181.5, 209.5, 117.0, 225.0], 0.9040233492851257, -1), ([296.0, 228.5, 118.0, 193.0], 0.8938525915145874, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 cars, 1 chair, 1 book, 231.0ms\n",
            "Speed: 3.5ms preprocess, 231.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      181.5       209.5         117         225]\n",
            " [        295       228.5         118         193]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90704     0.88109]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([181.5, 209.5, 117.0, 225.0], 0.9070436358451843, -1), ([295.0, 228.5, 118.0, 193.0], 0.8810880184173584, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 cars, 1 chair, 224.9ms\n",
            "Speed: 3.7ms preprocess, 224.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        181       209.5         116         225]\n",
            " [        296       227.5         116         193]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90653     0.86422]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([181.0, 209.5, 116.0, 225.0], 0.9065321683883667, -1), ([296.0, 227.5, 116.0, 193.0], 0.8642165660858154, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 cars, 1 chair, 245.9ms\n",
            "Speed: 3.7ms preprocess, 245.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        181       209.5         116         225]\n",
            " [        296       227.5         116         193]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90725     0.87125]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([181.0, 209.5, 116.0, 225.0], 0.9072529077529907, -1), ([296.0, 227.5, 116.0, 193.0], 0.871250569820404, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 248.1ms\n",
            "Speed: 4.6ms preprocess, 248.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        181       209.5         116         225]\n",
            " [        295       227.5         118         193]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90973     0.86914]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([181.0, 209.5, 116.0, 225.0], 0.9097306132316589, -1), ([295.0, 227.5, 118.0, 193.0], 0.8691430687904358, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 232.1ms\n",
            "Speed: 6.1ms preprocess, 232.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        180       209.5         116         225]\n",
            " [        295         228         118         192]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90857     0.86953]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([180.0, 209.5, 116.0, 225.0], 0.9085723757743835, -1), ([295.0, 228.0, 118.0, 192.0], 0.8695259094238281, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 321.5ms\n",
            "Speed: 7.0ms preprocess, 321.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        180       209.5         116         225]\n",
            " [      294.5       227.5         117         193]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90711     0.87515]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([180.0, 209.5, 116.0, 225.0], 0.907110333442688, -1), ([294.5, 227.5, 117.0, 193.0], 0.8751452565193176, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 cars, 2 chairs, 339.5ms\n",
            "Speed: 3.4ms preprocess, 339.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        180       209.5         116         225]\n",
            " [        294       227.5         118         193]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90775     0.87907]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([180.0, 209.5, 116.0, 225.0], 0.9077498316764832, -1), ([294.0, 227.5, 118.0, 193.0], 0.8790736794471741, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 cars, 2 chairs, 320.2ms\n",
            "Speed: 9.6ms preprocess, 320.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        180       209.5         116         225]\n",
            " [      293.5         228         117         192]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90874     0.87372]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([180.0, 209.5, 116.0, 225.0], 0.9087376594543457, -1), ([293.5, 228.0, 117.0, 192.0], 0.8737189769744873, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 332.8ms\n",
            "Speed: 3.6ms preprocess, 332.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      180.5       209.5         117         225]\n",
            " [        294         228         118         192]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90945     0.88476]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([180.5, 209.5, 117.0, 225.0], 0.9094499349594116, -1), ([294.0, 228.0, 118.0, 192.0], 0.8847588300704956, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 336.4ms\n",
            "Speed: 9.3ms preprocess, 336.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      180.5       209.5         117         225]\n",
            " [        294         228         118         192]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90904      0.8786]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([180.5, 209.5, 117.0, 225.0], 0.9090428948402405, -1), ([294.0, 228.0, 118.0, 192.0], 0.8786004185676575, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 334.8ms\n",
            "Speed: 3.5ms preprocess, 334.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      180.5       209.5         117         225]\n",
            " [        293         228         118         192]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.9089     0.87975]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([180.5, 209.5, 117.0, 225.0], 0.9088964462280273, -1), ([293.0, 228.0, 118.0, 192.0], 0.879752516746521, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 321.0ms\n",
            "Speed: 9.2ms preprocess, 321.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      180.5       209.5         115         225]\n",
            " [        293         228         118         192]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90666     0.88238]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([180.5, 209.5, 115.0, 225.0], 0.9066593050956726, -1), ([293.0, 228.0, 118.0, 192.0], 0.8823838829994202, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 1 car, 2 chairs, 325.6ms\n",
            "Speed: 3.3ms preprocess, 325.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        180       209.5         116         225]\n",
            " [      293.5         228         117         192]\n",
            " [        217         156          26         110]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.90558     0.87502     0.32143]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([180.0, 209.5, 116.0, 225.0], 0.905580997467041, -1), ([293.5, 228.0, 117.0, 192.0], 0.8750171065330505, -1), ([217.0, 156.0, 26.0, 110.0], 0.3214285969734192, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 1 car, 2 chairs, 336.1ms\n",
            "Speed: 3.5ms preprocess, 336.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        180       209.5         116         225]\n",
            " [        293         228         118         192]\n",
            " [        217         157          26         110]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.90757     0.87557     0.26086]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([180.0, 209.5, 116.0, 225.0], 0.9075744152069092, -1), ([293.0, 228.0, 118.0, 192.0], 0.8755726218223572, -1), ([217.0, 157.0, 26.0, 110.0], 0.260864794254303, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 333.2ms\n",
            "Speed: 11.3ms preprocess, 333.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        178         210         116         224]\n",
            " [      293.5       228.5         117         191]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91176     0.88695]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([178.0, 210.0, 116.0, 224.0], 0.9117588400840759, -1), ([293.5, 228.5, 117.0, 191.0], 0.88694828748703, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 332.1ms\n",
            "Speed: 8.9ms preprocess, 332.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        178       210.5         116         223]\n",
            " [        294         228         116         192]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.9116     0.88736]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([178.0, 210.5, 116.0, 223.0], 0.9116017818450928, -1), ([294.0, 228.0, 116.0, 192.0], 0.8873555064201355, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 319.9ms\n",
            "Speed: 5.7ms preprocess, 319.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      176.5       211.5         115         221]\n",
            " [        294         228         116         192]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90395     0.87788]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([176.5, 211.5, 115.0, 221.0], 0.9039528369903564, -1), ([294.0, 228.0, 116.0, 192.0], 0.8778750896453857, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 chair, 268.7ms\n",
            "Speed: 3.5ms preprocess, 268.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        178       212.5         118         219]\n",
            " [      294.5         229         115         192]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91233     0.88195]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([178.0, 212.5, 118.0, 219.0], 0.9123255610466003, -1), ([294.5, 229.0, 115.0, 192.0], 0.881947934627533, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 218.6ms\n",
            "Speed: 8.7ms preprocess, 218.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      181.5         214         123         216]\n",
            " [      295.5       229.5         115         191]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91891     0.88131]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([181.5, 214.0, 123.0, 216.0], 0.9189125895500183, -1), ([295.5, 229.5, 115.0, 191.0], 0.8813090324401855, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 cars, 1 chair, 208.2ms\n",
            "Speed: 4.1ms preprocess, 208.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        185         216         130         214]\n",
            " [      294.5         230         115         190]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.92525     0.90596]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([185.0, 216.0, 130.0, 214.0], 0.9252479672431946, -1), ([294.5, 230.0, 115.0, 190.0], 0.9059635996818542, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 cars, 1 chair, 241.9ms\n",
            "Speed: 3.7ms preprocess, 241.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      188.5       217.5         135         213]\n",
            " [      294.5         230         115         190]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.92321     0.91179]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([188.5, 217.5, 135.0, 213.0], 0.9232086539268494, -1), ([294.5, 230.0, 115.0, 190.0], 0.911792516708374, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 231.6ms\n",
            "Speed: 3.8ms preprocess, 231.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        294         231         114         190]\n",
            " [      191.5         219         143         212]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91327     0.90922]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([294.0, 231.0, 114.0, 190.0], 0.9132654666900635, -1), ([191.5, 219.0, 143.0, 212.0], 0.9092177748680115, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 227.4ms\n",
            "Speed: 5.2ms preprocess, 227.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        295       231.5         114         187]\n",
            " [        195         219         148         210]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91656     0.90731]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([295.0, 231.5, 114.0, 187.0], 0.9165578484535217, -1), ([195.0, 219.0, 148.0, 210.0], 0.9073113799095154, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 1 book, 239.4ms\n",
            "Speed: 5.1ms preprocess, 239.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      197.5       219.5         155         211]\n",
            " [        295       232.5         114         187]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88326     0.87935]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([197.5, 219.5, 155.0, 211.0], 0.8832627534866333, -1), ([295.0, 232.5, 114.0, 187.0], 0.879349410533905, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 cars, 1 chair, 193.8ms\n",
            "Speed: 12.0ms preprocess, 193.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      204.5         218         153         212]\n",
            " [      295.5         232         113         184]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.84984     0.84567]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([204.5, 218.0, 153.0, 212.0], 0.8498355746269226, -1), ([295.5, 232.0, 113.0, 184.0], 0.8456718325614929, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 cars, 3 chairs, 231.7ms\n",
            "Speed: 3.6ms preprocess, 231.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        208         216         152         216]\n",
            " [        296       232.5         112         183]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89318      0.8506]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([208.0, 216.0, 152.0, 216.0], 0.8931816220283508, -1), ([296.0, 232.5, 112.0, 183.0], 0.8506028652191162, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 cars, 1 chair, 219.8ms\n",
            "Speed: 3.8ms preprocess, 219.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      211.5       213.5         155         221]\n",
            " [        297         233         110         182]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91174     0.81185]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([211.5, 213.5, 155.0, 221.0], 0.9117426872253418, -1), ([297.0, 233.0, 110.0, 182.0], 0.8118521571159363, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 cars, 2 chairs, 222.9ms\n",
            "Speed: 3.7ms preprocess, 222.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      214.5       210.5         155         227]\n",
            " [        296         234         110         182]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86745       0.864]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([214.5, 210.5, 155.0, 227.0], 0.8674479126930237, -1), ([296.0, 234.0, 110.0, 182.0], 0.8640040159225464, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 cars, 2 chairs, 214.8ms\n",
            "Speed: 10.9ms preprocess, 214.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        214       206.5         150         235]\n",
            " [      295.5       234.5         111         181]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85891     0.85458]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([214.0, 206.5, 150.0, 235.0], 0.8589106798171997, -1), ([295.5, 234.5, 111.0, 181.0], 0.8545828461647034, -1)]\n",
            "Processing frame 1600\n",
            "\n",
            "0: 480x640 2 persons, 2 cars, 254.4ms\n",
            "Speed: 3.4ms preprocess, 254.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        212         203         142         242]\n",
            " [        296       234.5         110         179]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85634     0.83966]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([212.0, 203.0, 142.0, 242.0], 0.856335461139679, -1), ([296.0, 234.5, 110.0, 179.0], 0.8396618962287903, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 235.0ms\n",
            "Speed: 3.6ms preprocess, 235.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        209         197         136         252]\n",
            " [      296.5       235.5         111         177]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.9066     0.84098]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([209.0, 197.0, 136.0, 252.0], 0.9065985679626465, -1), ([296.5, 235.5, 111.0, 177.0], 0.840981662273407, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 cars, 222.1ms\n",
            "Speed: 3.8ms preprocess, 222.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        206       193.5         128         261]\n",
            " [      297.5       235.5         111         175]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89243     0.83243]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([206.0, 193.5, 128.0, 261.0], 0.8924271464347839, -1), ([297.5, 235.5, 111.0, 175.0], 0.8324277997016907, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 233.7ms\n",
            "Speed: 14.4ms preprocess, 233.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        207         189         120         270]\n",
            " [        297         236         112         174]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89665     0.85561]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([207.0, 189.0, 120.0, 270.0], 0.8966465592384338, -1), ([297.0, 236.0, 112.0, 174.0], 0.8556086421012878, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 221.5ms\n",
            "Speed: 3.4ms preprocess, 221.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      209.5       183.5         121         279]\n",
            " [      297.5         236         111         172]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89556     0.83605]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([209.5, 183.5, 121.0, 279.0], 0.8955601453781128, -1), ([297.5, 236.0, 111.0, 172.0], 0.8360458612442017, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 239.7ms\n",
            "Speed: 4.5ms preprocess, 239.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        211         182         120         282]\n",
            " [        298         237         112         172]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88715      0.7068]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([211.0, 182.0, 120.0, 282.0], 0.8871511816978455, -1), ([298.0, 237.0, 112.0, 172.0], 0.7068037986755371, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 221.9ms\n",
            "Speed: 3.8ms preprocess, 221.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      210.5       179.5         117         287]\n",
            " [      297.5       237.5         113         169]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90356     0.70673]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([210.5, 179.5, 117.0, 287.0], 0.9035558700561523, -1), ([297.5, 237.5, 113.0, 169.0], 0.7067282795906067, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 225.1ms\n",
            "Speed: 3.4ms preprocess, 225.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      210.5       179.5         117         287]\n",
            " [      298.5         238         113         170]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90466     0.78403]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([210.5, 179.5, 117.0, 287.0], 0.904664158821106, -1), ([298.5, 238.0, 113.0, 170.0], 0.7840346097946167, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 227.7ms\n",
            "Speed: 3.6ms preprocess, 227.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      212.5         180         119         288]\n",
            " [      304.5         239          99         168]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89988     0.69286]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([212.5, 180.0, 119.0, 288.0], 0.8998806476593018, -1), ([304.5, 239.0, 99.0, 168.0], 0.6928640604019165, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 239.5ms\n",
            "Speed: 4.1ms preprocess, 239.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      299.5         240         109         168]\n",
            " [      212.5       180.5         119         287]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.81658     0.73462]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([299.5, 240.0, 109.0, 168.0], 0.8165807723999023, -1), ([212.5, 180.5, 119.0, 287.0], 0.7346150279045105, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 238.2ms\n",
            "Speed: 3.5ms preprocess, 238.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        241       179.5         174         287]\n",
            " [      301.5       240.5         105         167]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90711     0.81379]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([241.0, 179.5, 174.0, 287.0], 0.9071149230003357, -1), ([301.5, 240.5, 105.0, 167.0], 0.8137852549552917, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 243.1ms\n",
            "Speed: 5.5ms preprocess, 243.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        242       180.5         176         287]\n",
            " [        298         241         112         164]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90902     0.86971]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([242.0, 180.5, 176.0, 287.0], 0.9090163111686707, -1), ([298.0, 241.0, 112.0, 164.0], 0.8697099089622498, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 215.3ms\n",
            "Speed: 9.7ms preprocess, 215.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      243.5         180         173         286]\n",
            " [      298.5         241         113         162]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88782     0.87804]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([243.5, 180.0, 173.0, 286.0], 0.8878244161605835, -1), ([298.5, 241.0, 113.0, 162.0], 0.8780385255813599, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 chair, 224.1ms\n",
            "Speed: 3.4ms preprocess, 224.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        243       180.5         172         287]\n",
            " [        297         241         118         162]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85022     0.77878]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([243.0, 180.5, 172.0, 287.0], 0.8502241373062134, -1), ([297.0, 241.0, 118.0, 162.0], 0.7787752747535706, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 chair, 236.4ms\n",
            "Speed: 3.4ms preprocess, 236.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      297.5         242         117         162]\n",
            " [        239         180         164         288]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86681     0.73142]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([297.5, 242.0, 117.0, 162.0], 0.8668099641799927, -1), ([239.0, 180.0, 164.0, 288.0], 0.7314208149909973, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 chair, 216.4ms\n",
            "Speed: 3.5ms preprocess, 216.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      298.5         243         115         160]\n",
            " [      228.5         180         157         290]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88287     0.81456]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([298.5, 243.0, 115.0, 160.0], 0.8828749656677246, -1), ([228.5, 180.0, 157.0, 290.0], 0.8145608901977539, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 218.1ms\n",
            "Speed: 10.9ms preprocess, 218.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      237.5       180.5         145         289]\n",
            " [        299       243.5         114         159]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [      0.908      0.8956]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([237.5, 180.5, 145.0, 289.0], 0.9079999923706055, -1), ([299.0, 243.5, 114.0, 159.0], 0.8955950736999512, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 317.3ms\n",
            "Speed: 5.2ms preprocess, 317.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      299.5         245         117         158]\n",
            " [      228.5       180.5         125         289]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86852     0.82016]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([299.5, 245.0, 117.0, 158.0], 0.868521511554718, -1), ([228.5, 180.5, 125.0, 289.0], 0.8201563358306885, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 340.7ms\n",
            "Speed: 9.7ms preprocess, 340.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        300       245.5         116         157]\n",
            " [        216         181          98         288]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87283     0.70333]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([300.0, 245.5, 116.0, 157.0], 0.8728295564651489, -1), ([216.0, 181.0, 98.0, 288.0], 0.7033303380012512, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 315.2ms\n",
            "Speed: 8.6ms preprocess, 315.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      300.5       246.5         115         157]\n",
            " [        230         181         128         288]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87574     0.80305]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([300.5, 246.5, 115.0, 157.0], 0.8757393956184387, -1), ([230.0, 181.0, 128.0, 288.0], 0.8030520677566528, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 322.0ms\n",
            "Speed: 6.3ms preprocess, 322.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        301       246.5         116         157]\n",
            " [        222         181         134         290]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86987     0.81812]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([301.0, 246.5, 116.0, 157.0], 0.8698669672012329, -1), ([222.0, 181.0, 134.0, 290.0], 0.818118155002594, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 315.2ms\n",
            "Speed: 19.7ms preprocess, 315.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        301         247         114         156]\n",
            " [      214.5         181         129         288]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87472     0.86378]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([301.0, 247.0, 114.0, 156.0], 0.874722957611084, -1), ([214.5, 181.0, 129.0, 288.0], 0.8637797832489014, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 326.2ms\n",
            "Speed: 3.6ms preprocess, 326.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        301       247.5         116         155]\n",
            " [        228         183         156         290]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.8895      0.8258]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([301.0, 247.5, 116.0, 155.0], 0.8894977569580078, -1), ([228.0, 183.0, 156.0, 290.0], 0.8257977366447449, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 318.3ms\n",
            "Speed: 3.7ms preprocess, 318.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      235.5       181.5         157         281]\n",
            " [        301         246         120         152]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.9012     0.85321]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([235.5, 181.5, 157.0, 281.0], 0.9011967778205872, -1), ([301.0, 246.0, 120.0, 152.0], 0.8532087802886963, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 364.3ms\n",
            "Speed: 3.5ms preprocess, 364.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        237       182.5         172         279]\n",
            " [      301.5         246         119         152]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91512     0.85227]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([237.0, 182.5, 172.0, 279.0], 0.9151211380958557, -1), ([301.5, 246.0, 119.0, 152.0], 0.8522692322731018, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 312.6ms\n",
            "Speed: 10.8ms preprocess, 312.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      242.5       184.5         189         275]\n",
            " [      301.5       247.5         119         149]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91076     0.84413]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([242.5, 184.5, 189.0, 275.0], 0.9107624888420105, -1), ([301.5, 247.5, 119.0, 149.0], 0.844130277633667, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 refrigerator, 342.5ms\n",
            "Speed: 14.4ms preprocess, 342.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      250.5       184.5         203         275]\n",
            " [      301.5       247.5         119         151]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87894     0.84383]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([250.5, 184.5, 203.0, 275.0], 0.8789442777633667, -1), ([301.5, 247.5, 119.0, 151.0], 0.8438318967819214, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 chair, 1 refrigerator, 267.8ms\n",
            "Speed: 7.7ms preprocess, 267.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        261         185         224         274]\n",
            " [      301.5         247         121         150]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.9075     0.76981]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([261.0, 185.0, 224.0, 274.0], 0.9074971675872803, -1), ([301.5, 247.0, 121.0, 150.0], 0.7698125839233398, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 230.3ms\n",
            "Speed: 3.7ms preprocess, 230.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      257.5       190.5         209         265]\n",
            " [        302         248         122         150]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87971     0.80717]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([257.5, 190.5, 209.0, 265.0], 0.8797051310539246, -1), ([302.0, 248.0, 122.0, 150.0], 0.8071667551994324, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 refrigerator, 239.1ms\n",
            "Speed: 3.8ms preprocess, 239.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        244         194         190         258]\n",
            " [        301       248.5         122         149]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88891     0.80187]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([244.0, 194.0, 190.0, 258.0], 0.8889051675796509, -1), ([301.0, 248.5, 122.0, 149.0], 0.8018695712089539, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 228.7ms\n",
            "Speed: 5.9ms preprocess, 228.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        240       196.5         180         253]\n",
            " [        302         248         124         150]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.9073     0.82854]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([240.0, 196.5, 180.0, 253.0], 0.9072995781898499, -1), ([302.0, 248.0, 124.0, 150.0], 0.8285366296768188, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 229.7ms\n",
            "Speed: 4.2ms preprocess, 229.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      234.5         197         179         252]\n",
            " [        299       246.5         122         151]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90304     0.85291]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([234.5, 197.0, 179.0, 252.0], 0.9030401110649109, -1), ([299.0, 246.5, 122.0, 151.0], 0.8529141545295715, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 245.2ms\n",
            "Speed: 5.2ms preprocess, 245.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        234       197.5         176         249]\n",
            " [        300         247         122         150]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89161     0.88293]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([234.0, 197.5, 176.0, 249.0], 0.8916053175926208, -1), ([300.0, 247.0, 122.0, 150.0], 0.882928729057312, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 234.5ms\n",
            "Speed: 14.6ms preprocess, 234.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        300         247         122         150]\n",
            " [        232         198         174         250]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89787     0.81283]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([300.0, 247.0, 122.0, 150.0], 0.8978694081306458, -1), ([232.0, 198.0, 174.0, 250.0], 0.8128293752670288, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 241.2ms\n",
            "Speed: 3.5ms preprocess, 241.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        231         199         172         246]\n",
            " [        299         247         122         150]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90366     0.89725]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([231.0, 199.0, 172.0, 246.0], 0.9036587476730347, -1), ([299.0, 247.0, 122.0, 150.0], 0.8972465991973877, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 227.9ms\n",
            "Speed: 19.1ms preprocess, 227.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        230       199.5         166         247]\n",
            " [      298.5         247         121         150]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89242     0.89222]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([230.0, 199.5, 166.0, 247.0], 0.8924213647842407, -1), ([298.5, 247.0, 121.0, 150.0], 0.892223596572876, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 216.3ms\n",
            "Speed: 12.7ms preprocess, 216.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      229.5       200.5         165         245]\n",
            " [        298         247         120         150]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89393     0.88513]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([229.5, 200.5, 165.0, 245.0], 0.8939268589019775, -1), ([298.0, 247.0, 120.0, 150.0], 0.8851302862167358, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 238.5ms\n",
            "Speed: 4.9ms preprocess, 238.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      224.5       203.5         171         239]\n",
            " [        298       246.5         120         151]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90901     0.89191]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([224.5, 203.5, 171.0, 239.0], 0.9090127944946289, -1), ([298.0, 246.5, 120.0, 151.0], 0.8919140696525574, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 205.0ms\n",
            "Speed: 3.7ms preprocess, 205.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        223         205         176         236]\n",
            " [        298         247         120         150]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90547     0.89582]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([223.0, 205.0, 176.0, 236.0], 0.905470073223114, -1), ([298.0, 247.0, 120.0, 150.0], 0.8958163857460022, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 232.4ms\n",
            "Speed: 15.3ms preprocess, 232.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      221.5         204         179         238]\n",
            " [        297         247         120         150]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91081     0.88751]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([221.5, 204.0, 179.0, 238.0], 0.9108109474182129, -1), ([297.0, 247.0, 120.0, 150.0], 0.8875119686126709, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 refrigerator, 225.8ms\n",
            "Speed: 3.9ms preprocess, 225.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      297.5         247         121         152]\n",
            " [        221         204         180         238]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88982     0.85774]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([297.5, 247.0, 121.0, 152.0], 0.8898188471794128, -1), ([221.0, 204.0, 180.0, 238.0], 0.8577362895011902, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 refrigerator, 244.0ms\n",
            "Speed: 4.4ms preprocess, 244.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        220       203.5         180         239]\n",
            " [      297.5       247.5         121         151]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.9044     0.89151]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([220.0, 203.5, 180.0, 239.0], 0.9043964147567749, -1), ([297.5, 247.5, 121.0, 151.0], 0.8915094137191772, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 231.9ms\n",
            "Speed: 3.7ms preprocess, 231.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        220         202         182         242]\n",
            " [      297.5         248         119         150]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90773     0.89537]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([220.0, 202.0, 182.0, 242.0], 0.9077305197715759, -1), ([297.5, 248.0, 119.0, 150.0], 0.8953685760498047, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 228.7ms\n",
            "Speed: 9.7ms preprocess, 228.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      297.5       248.5         119         149]\n",
            " [      219.5         202         183         242]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90016     0.89571]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([297.5, 248.5, 119.0, 149.0], 0.9001584649085999, -1), ([219.5, 202.0, 183.0, 242.0], 0.89570552110672, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 245.2ms\n",
            "Speed: 3.5ms preprocess, 245.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      296.5       248.5         119         147]\n",
            " [        219       201.5         182         245]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89468     0.89262]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([296.5, 248.5, 119.0, 147.0], 0.8946820497512817, -1), ([219.0, 201.5, 182.0, 245.0], 0.8926244378089905, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 237.1ms\n",
            "Speed: 3.6ms preprocess, 237.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      295.5         248         117         148]\n",
            " [        219       200.5         182         245]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88298     0.78724]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([295.5, 248.0, 117.0, 148.0], 0.8829838633537292, -1), ([219.0, 200.5, 182.0, 245.0], 0.7872358560562134, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 suitcase, 239.3ms\n",
            "Speed: 3.6ms preprocess, 239.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        294       248.5         114         149]\n",
            " [        218       201.5         180         245]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89296     0.89142]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([294.0, 248.5, 114.0, 149.0], 0.8929648399353027, -1), ([218.0, 201.5, 180.0, 245.0], 0.8914226293563843, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 suitcase, 227.2ms\n",
            "Speed: 3.8ms preprocess, 227.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        217         201         176         244]\n",
            " [        294         248         112         150]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.92041     0.89845]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([217.0, 201.0, 176.0, 244.0], 0.920405387878418, -1), ([294.0, 248.0, 112.0, 150.0], 0.8984496593475342, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 229.3ms\n",
            "Speed: 3.8ms preprocess, 229.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      215.5         199         173         248]\n",
            " [        292         248         108         150]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91925     0.88918]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([215.5, 199.0, 173.0, 248.0], 0.9192476272583008, -1), ([292.0, 248.0, 108.0, 150.0], 0.8891792893409729, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 243.3ms\n",
            "Speed: 4.9ms preprocess, 243.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        214         200         170         246]\n",
            " [        291         248         106         150]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91643     0.89245]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([214.0, 200.0, 170.0, 246.0], 0.9164257049560547, -1), ([291.0, 248.0, 106.0, 150.0], 0.8924516439437866, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 223.1ms\n",
            "Speed: 3.5ms preprocess, 223.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      212.5         201         163         244]\n",
            " [        290       247.5         104         151]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.92529     0.87437]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([212.5, 201.0, 163.0, 244.0], 0.9252921342849731, -1), ([290.0, 247.5, 104.0, 151.0], 0.8743695616722107, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 229.1ms\n",
            "Speed: 3.5ms preprocess, 229.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      210.5       200.5         161         245]\n",
            " [      288.5         246         101         152]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.93131     0.86734]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([210.5, 200.5, 161.0, 245.0], 0.9313051104545593, -1), ([288.5, 246.0, 101.0, 152.0], 0.8673414587974548, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 236.1ms\n",
            "Speed: 11.5ms preprocess, 236.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        211         201         156         244]\n",
            " [        286       246.5          98         151]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.92258     0.88469]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([211.0, 201.0, 156.0, 244.0], 0.922578752040863, -1), ([286.0, 246.5, 98.0, 151.0], 0.8846943378448486, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 chair, 1 refrigerator, 233.5ms\n",
            "Speed: 3.6ms preprocess, 233.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        210       200.5         152         245]\n",
            " [        284         246          96         154]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.92571     0.88013]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([210.0, 200.5, 152.0, 245.0], 0.9257144927978516, -1), ([284.0, 246.0, 96.0, 154.0], 0.8801304697990417, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 1 refrigerator, 223.9ms\n",
            "Speed: 9.8ms preprocess, 223.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        210         201         150         244]\n",
            " [      281.5       244.5          97         157]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.92683     0.86204]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([210.0, 201.0, 150.0, 244.0], 0.9268276691436768, -1), ([281.5, 244.5, 97.0, 157.0], 0.8620443344116211, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 312.4ms\n",
            "Speed: 16.6ms preprocess, 312.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      209.5       200.5         147         245]\n",
            " [      278.5       245.5          95         155]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.92065     0.86743]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([209.5, 200.5, 147.0, 245.0], 0.920648455619812, -1), ([278.5, 245.5, 95.0, 155.0], 0.8674343228340149, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 chair, 320.2ms\n",
            "Speed: 3.9ms preprocess, 320.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        210         200         146         246]\n",
            " [        276         245          96         156]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91567     0.86885]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([210.0, 200.0, 146.0, 246.0], 0.9156728386878967, -1), ([276.0, 245.0, 96.0, 156.0], 0.8688534498214722, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 1 refrigerator, 313.0ms\n",
            "Speed: 11.8ms preprocess, 313.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        210       200.5         144         247]\n",
            " [        273       245.5          92         155]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91448     0.87813]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([210.0, 200.5, 144.0, 247.0], 0.9144821763038635, -1), ([273.0, 245.5, 92.0, 155.0], 0.8781329393386841, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 chair, 335.4ms\n",
            "Speed: 5.5ms preprocess, 335.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      209.5         199         141         248]\n",
            " [      270.5       244.5          91         155]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.92172     0.86713]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([209.5, 199.0, 141.0, 248.0], 0.9217153787612915, -1), ([270.5, 244.5, 91.0, 155.0], 0.8671300411224365, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 318.5ms\n",
            "Speed: 8.4ms preprocess, 318.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      208.5         199         137         250]\n",
            " [      272.5         245          89         156]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91839     0.84738]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([208.5, 199.0, 137.0, 250.0], 0.918388843536377, -1), ([272.5, 245.0, 89.0, 156.0], 0.8473796844482422, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 refrigerator, 323.1ms\n",
            "Speed: 7.3ms preprocess, 323.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      207.5         199         133         250]\n",
            " [        268         244          92         156]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [      0.919     0.84514]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([207.5, 199.0, 133.0, 250.0], 0.9189959764480591, -1), ([268.0, 244.0, 92.0, 156.0], 0.8451417088508606, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 329.1ms\n",
            "Speed: 13.4ms preprocess, 329.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      207.5       198.5         131         249]\n",
            " [        264         243          98         158]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91444     0.85323]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([207.5, 198.5, 131.0, 249.0], 0.9144368171691895, -1), ([264.0, 243.0, 98.0, 158.0], 0.8532266020774841, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 311.9ms\n",
            "Speed: 7.2ms preprocess, 311.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      209.5       197.5         127         251]\n",
            " [      262.5         244          99         158]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90362     0.82373]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([209.5, 197.5, 127.0, 251.0], 0.9036189317703247, -1), ([262.5, 244.0, 99.0, 158.0], 0.8237330317497253, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 346.4ms\n",
            "Speed: 7.8ms preprocess, 346.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        210       197.5         124         253]\n",
            " [      266.5       241.5          91         161]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90704     0.81086]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([210.0, 197.5, 124.0, 253.0], 0.9070379734039307, -1), ([266.5, 241.5, 91.0, 161.0], 0.8108623623847961, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 311.0ms\n",
            "Speed: 3.4ms preprocess, 311.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        210       196.5         122         253]\n",
            " [        271         241          82         162]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90262     0.83395]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([210.0, 196.5, 122.0, 253.0], 0.9026169776916504, -1), ([271.0, 241.0, 82.0, 162.0], 0.8339543342590332, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 337.7ms\n",
            "Speed: 13.3ms preprocess, 337.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        210         196         120         254]\n",
            " [      267.5         242          87         160]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90891     0.84918]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([210.0, 196.0, 120.0, 254.0], 0.9089058041572571, -1), ([267.5, 242.0, 87.0, 160.0], 0.8491761684417725, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 304.9ms\n",
            "Speed: 12.1ms preprocess, 304.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        210       195.5         120         255]\n",
            " [      265.5       241.5          87         161]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90664     0.79198]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([210.0, 195.5, 120.0, 255.0], 0.9066414833068848, -1), ([265.5, 241.5, 87.0, 161.0], 0.7919771671295166, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 207.6ms\n",
            "Speed: 3.6ms preprocess, 207.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        209         195         120         256]\n",
            " [        263       241.5          92         161]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90377     0.82494]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([209.0, 195.0, 120.0, 256.0], 0.9037660360336304, -1), ([263.0, 241.5, 92.0, 161.0], 0.8249399662017822, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 224.7ms\n",
            "Speed: 3.5ms preprocess, 224.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        208       194.5         122         257]\n",
            " [      260.5         242          97         162]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89804     0.83855]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([208.0, 194.5, 122.0, 257.0], 0.8980437517166138, -1), ([260.5, 242.0, 97.0, 162.0], 0.8385518789291382, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 refrigerator, 216.7ms\n",
            "Speed: 3.6ms preprocess, 216.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      207.5       194.5         123         257]\n",
            " [        267         241          82         162]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.8959     0.82345]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([207.5, 194.5, 123.0, 257.0], 0.8958969116210938, -1), ([267.0, 241.0, 82.0, 162.0], 0.8234463930130005, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 222.9ms\n",
            "Speed: 3.5ms preprocess, 222.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        206       194.5         122         259]\n",
            " [      262.5       240.5          85         163]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90898     0.78755]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([206.0, 194.5, 122.0, 259.0], 0.9089804887771606, -1), ([262.5, 240.5, 85.0, 163.0], 0.7875512838363647, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 234.9ms\n",
            "Speed: 7.1ms preprocess, 234.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      203.5         194         123         260]\n",
            " [      250.5         240         105         164]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91612     0.86552]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([203.5, 194.0, 123.0, 260.0], 0.9161180257797241, -1), ([250.5, 240.0, 105.0, 164.0], 0.8655161261558533, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 229.8ms\n",
            "Speed: 3.9ms preprocess, 229.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        203       193.5         122         263]\n",
            " [      249.5       238.5         103         167]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91765     0.74453]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([203.0, 193.5, 122.0, 263.0], 0.9176510572433472, -1), ([249.5, 238.5, 103.0, 167.0], 0.7445340156555176, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 227.3ms\n",
            "Speed: 8.0ms preprocess, 227.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        201         193         126         264]\n",
            " [        254         238          92         168]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91574     0.83458]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([201.0, 193.0, 126.0, 264.0], 0.915740430355072, -1), ([254.0, 238.0, 92.0, 168.0], 0.8345770835876465, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 truck, 214.2ms\n",
            "Speed: 18.9ms preprocess, 214.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        200         193         124         264]\n",
            " [      253.5       237.5          87         169]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90442     0.81746]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([200.0, 193.0, 124.0, 264.0], 0.9044154286384583, -1), ([253.5, 237.5, 87.0, 169.0], 0.8174643516540527, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 206.8ms\n",
            "Speed: 3.7ms preprocess, 206.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      199.5       192.5         125         263]\n",
            " [        253       236.5          90         171]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91508     0.80859]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([199.5, 192.5, 125.0, 263.0], 0.9150835275650024, -1), ([253.0, 236.5, 90.0, 171.0], 0.8085896372795105, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 212.1ms\n",
            "Speed: 3.7ms preprocess, 212.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      201.5       192.5         127         263]\n",
            " [        260         236          86         170]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91482     0.81163]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([201.5, 192.5, 127.0, 263.0], 0.9148219227790833, -1), ([260.0, 236.0, 86.0, 170.0], 0.8116283416748047, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 truck, 219.0ms\n",
            "Speed: 3.6ms preprocess, 219.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        201       192.5         130         263]\n",
            " [      262.5       234.5          95         175]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90398     0.81114]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([201.0, 192.5, 130.0, 263.0], 0.9039753079414368, -1), ([262.5, 234.5, 95.0, 175.0], 0.8111375570297241, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 219.0ms\n",
            "Speed: 9.0ms preprocess, 219.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        201       192.5         134         263]\n",
            " [        269         233          96         178]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87297     0.81017]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([201.0, 192.5, 134.0, 263.0], 0.8729701638221741, -1), ([269.0, 233.0, 96.0, 178.0], 0.8101652264595032, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 1 car, 1 truck, 229.9ms\n",
            "Speed: 3.5ms preprocess, 229.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      200.5       192.5         135         263]\n",
            " [        256       232.5          68         177]\n",
            " [        317         165          34          38]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.84195     0.79613     0.27368]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([200.5, 192.5, 135.0, 263.0], 0.8419508337974548, -1), ([256.0, 232.5, 68.0, 177.0], 0.7961298227310181, -1), ([317.0, 165.0, 34.0, 38.0], 0.2736756205558777, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 1 refrigerator, 230.9ms\n",
            "Speed: 3.6ms preprocess, 230.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        230         192         198         262]\n",
            " [      254.5         233          69         178]\n",
            " [        270         232         102         178]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.71591     0.54821     0.38596]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([230.0, 192.0, 198.0, 262.0], 0.715910792350769, -1), ([254.5, 233.0, 69.0, 178.0], 0.548213541507721, -1), ([270.0, 232.0, 102.0, 178.0], 0.385955274105072, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 1 truck, 218.6ms\n",
            "Speed: 18.1ms preprocess, 218.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      228.5       191.5         201         263]\n",
            " [      257.5         230          71         182]\n",
            " [        192       192.5         128         263]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.62995     0.47805      0.2748]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([228.5, 191.5, 201.0, 263.0], 0.6299496293067932, -1), ([257.5, 230.0, 71.0, 182.0], 0.47805026173591614, -1), ([192.0, 192.5, 128.0, 263.0], 0.2747975289821625, -1)]\n",
            "\n",
            "0: 480x640 4 persons, 1 truck, 233.9ms\n",
            "Speed: 3.5ms preprocess, 233.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      229.5       188.5         201         257]\n",
            " [        195       192.5         132         265]\n",
            " [      262.5         231          87         182]\n",
            " [        274       206.5         108         229]]\n",
            "Bounding box shape: (4, 4)\n",
            "Confidences: [    0.62789     0.54919     0.48145     0.26581]\n",
            "Confidences shape: (4,)\n",
            "Formatted detections: [([229.5, 188.5, 201.0, 257.0], 0.6278858184814453, -1), ([195.0, 192.5, 132.0, 265.0], 0.5491884350776672, -1), ([262.5, 231.0, 87.0, 182.0], 0.48145487904548645, -1), ([274.0, 206.5, 108.0, 229.0], 0.2658118009567261, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 truck, 214.8ms\n",
            "Speed: 3.6ms preprocess, 214.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      249.5       231.5          73         181]\n",
            " [      228.5       187.5         203         257]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.70158      0.6234]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([249.5, 231.5, 73.0, 181.0], 0.701577365398407, -1), ([228.5, 187.5, 203.0, 257.0], 0.6233987212181091, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 1 refrigerator, 227.5ms\n",
            "Speed: 8.4ms preprocess, 227.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        198       191.5         134         267]\n",
            " [        250         232          70         180]\n",
            " [        229         191         198         266]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.68341     0.66457     0.37718]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([198.0, 191.5, 134.0, 267.0], 0.6834068894386292, -1), ([250.0, 232.0, 70.0, 180.0], 0.6645707488059998, -1), ([229.0, 191.0, 198.0, 266.0], 0.3771812617778778, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 223.9ms\n",
            "Speed: 4.6ms preprocess, 223.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      200.5       191.5         135         267]\n",
            " [      270.5       232.5          89         179]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88679     0.73318]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([200.5, 191.5, 135.0, 267.0], 0.8867909908294678, -1), ([270.5, 232.5, 89.0, 179.0], 0.7331755757331848, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 refrigerator, 254.4ms\n",
            "Speed: 3.3ms preprocess, 254.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      199.5       191.5         133         265]\n",
            " [        265         232          90         178]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89526     0.77016]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([199.5, 191.5, 133.0, 265.0], 0.8952634930610657, -1), ([265.0, 232.0, 90.0, 178.0], 0.7701551914215088, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 229.4ms\n",
            "Speed: 3.8ms preprocess, 229.4ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        196       192.5         124         265]\n",
            " [        242       231.5         114         181]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88961     0.81871]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([196.0, 192.5, 124.0, 265.0], 0.889614999294281, -1), ([242.0, 231.5, 114.0, 181.0], 0.8187092542648315, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 1 refrigerator, 238.3ms\n",
            "Speed: 3.5ms preprocess, 238.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      197.5         192         117         264]\n",
            " [        241         232         110         180]\n",
            " [        228       211.5          96         223]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.86874     0.85758     0.46629]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([197.5, 192.0, 117.0, 264.0], 0.8687435984611511, -1), ([241.0, 232.0, 110.0, 180.0], 0.857581377029419, -1), ([228.0, 211.5, 96.0, 223.0], 0.46628695726394653, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 228.8ms\n",
            "Speed: 3.5ms preprocess, 228.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        197         192         120         262]\n",
            " [        244       231.5         104         179]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88752      0.7624]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([197.0, 192.0, 120.0, 262.0], 0.887517511844635, -1), ([244.0, 231.5, 104.0, 179.0], 0.7624019980430603, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 223.9ms\n",
            "Speed: 8.8ms preprocess, 223.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        199       193.5         114         263]\n",
            " [      248.5       232.5         103         179]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88914     0.76747]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([199.0, 193.5, 114.0, 263.0], 0.8891368508338928, -1), ([248.5, 232.5, 103.0, 179.0], 0.7674695253372192, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 223.0ms\n",
            "Speed: 3.7ms preprocess, 223.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        198         194         114         262]\n",
            " [      259.5         232          89         180]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89442     0.72474]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([198.0, 194.0, 114.0, 262.0], 0.894420325756073, -1), ([259.5, 232.0, 89.0, 180.0], 0.7247442007064819, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 refrigerator, 235.6ms\n",
            "Speed: 8.1ms preprocess, 235.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      199.5       194.5         115         261]\n",
            " [      247.5       231.5         119         181]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [      0.898     0.68904]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([199.5, 194.5, 115.0, 261.0], 0.8979957699775696, -1), ([247.5, 231.5, 119.0, 181.0], 0.6890398263931274, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 refrigerator, 210.6ms\n",
            "Speed: 4.9ms preprocess, 210.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      199.5       195.5         115         259]\n",
            " [      241.5       232.5         117         181]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88445     0.71514]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([199.5, 195.5, 115.0, 259.0], 0.8844478726387024, -1), ([241.5, 232.5, 117.0, 181.0], 0.7151420712471008, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 refrigerator, 278.9ms\n",
            "Speed: 5.0ms preprocess, 278.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        200       196.5         114         255]\n",
            " [      242.5         232         123         182]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88332     0.81597]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([200.0, 196.5, 114.0, 255.0], 0.8833245038986206, -1), ([242.5, 232.0, 123.0, 182.0], 0.8159705400466919, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 319.3ms\n",
            "Speed: 6.9ms preprocess, 319.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      198.5       197.5         113         253]\n",
            " [      238.5         232         119         182]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86962     0.84186]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([198.5, 197.5, 113.0, 253.0], 0.8696242570877075, -1), ([238.5, 232.0, 119.0, 182.0], 0.8418635725975037, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 refrigerator, 322.6ms\n",
            "Speed: 8.1ms preprocess, 322.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      198.5         198         115         250]\n",
            " [      231.5       231.5         109         181]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87866     0.84285]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([198.5, 198.0, 115.0, 250.0], 0.8786646723747253, -1), ([231.5, 231.5, 109.0, 181.0], 0.8428468704223633, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 refrigerator, 321.4ms\n",
            "Speed: 3.5ms preprocess, 321.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      229.5       231.5         103         181]\n",
            " [        198         199         114         248]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86201     0.85191]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([229.5, 231.5, 103.0, 181.0], 0.8620088696479797, -1), ([198.0, 199.0, 114.0, 248.0], 0.8519101738929749, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 refrigerator, 331.6ms\n",
            "Speed: 3.5ms preprocess, 331.6ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        195       200.5         114         245]\n",
            " [        229       231.5         100         181]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87598     0.86156]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([195.0, 200.5, 114.0, 245.0], 0.8759764432907104, -1), ([229.0, 231.5, 100.0, 181.0], 0.8615608811378479, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 refrigerator, 308.3ms\n",
            "Speed: 8.9ms preprocess, 308.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        230       231.5         100         181]\n",
            " [        192       202.5         118         241]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87191     0.85788]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([230.0, 231.5, 100.0, 181.0], 0.8719131350517273, -1), ([192.0, 202.5, 118.0, 241.0], 0.8578798174858093, -1)]\n",
            "Processing frame 1700\n",
            "\n",
            "0: 480x640 2 persons, 1 refrigerator, 303.4ms\n",
            "Speed: 8.5ms preprocess, 303.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      189.5         205         117         236]\n",
            " [      231.5         232          97         182]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87949     0.86101]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([189.5, 205.0, 117.0, 236.0], 0.8794932961463928, -1), ([231.5, 232.0, 97.0, 182.0], 0.8610067367553711, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 312.5ms\n",
            "Speed: 10.8ms preprocess, 312.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      187.5         207         113         232]\n",
            " [        232         232          90         182]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87959     0.86163]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([187.5, 207.0, 113.0, 232.0], 0.8795932531356812, -1), ([232.0, 232.0, 90.0, 182.0], 0.8616330623626709, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 319.2ms\n",
            "Speed: 8.1ms preprocess, 319.2ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        185         209         112         226]\n",
            " [        231         232          92         182]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86958     0.85779]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([185.0, 209.0, 112.0, 226.0], 0.8695799112319946, -1), ([231.0, 232.0, 92.0, 182.0], 0.8577936887741089, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 341.2ms\n",
            "Speed: 3.5ms preprocess, 341.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        233         231          88         182]\n",
            " [      182.5       212.5         107         219]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.84139     0.79667]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([233.0, 231.0, 88.0, 182.0], 0.8413875102996826, -1), ([182.5, 212.5, 107.0, 219.0], 0.7966663241386414, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 338.1ms\n",
            "Speed: 3.5ms preprocess, 338.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        237       230.5          78         185]\n",
            " [      178.5       216.5         109         211]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.84215      0.7787]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([237.0, 230.5, 78.0, 185.0], 0.842149555683136, -1), ([178.5, 216.5, 109.0, 211.0], 0.7787037491798401, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 1 bottle, 334.3ms\n",
            "Speed: 10.8ms preprocess, 334.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        178       219.5         106         207]\n",
            " [        235       230.5          80         185]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86597     0.85233]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([178.0, 219.5, 106.0, 207.0], 0.8659713268280029, -1), ([235.0, 230.5, 80.0, 185.0], 0.8523308038711548, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 bottle, 217.0ms\n",
            "Speed: 3.9ms preprocess, 217.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      233.5       229.5          81         187]\n",
            " [        176       224.5         102         197]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85099     0.77933]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([233.5, 229.5, 81.0, 187.0], 0.8509861826896667, -1), ([176.0, 224.5, 102.0, 197.0], 0.7793344259262085, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 bottle, 227.1ms\n",
            "Speed: 12.4ms preprocess, 227.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        175         229         100         188]\n",
            " [        234       229.5          78         187]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85748     0.85361]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([175.0, 229.0, 100.0, 188.0], 0.8574789762496948, -1), ([234.0, 229.5, 78.0, 187.0], 0.8536107540130615, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 233.6ms\n",
            "Speed: 4.8ms preprocess, 233.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        234         229          76         186]\n",
            " [      175.5         233         101         180]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.84876     0.70185]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([234.0, 229.0, 76.0, 186.0], 0.8487610220909119, -1), ([175.5, 233.0, 101.0, 180.0], 0.7018455266952515, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 231.1ms\n",
            "Speed: 15.3ms preprocess, 231.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        232       228.5          76         187]\n",
            " [        176         236         100         174]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.84334     0.54823]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([232.0, 228.5, 76.0, 187.0], 0.8433420062065125, -1), ([176.0, 236.0, 100.0, 174.0], 0.5482277870178223, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 1 car, 1 truck, 203.1ms\n",
            "Speed: 5.5ms preprocess, 203.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        231         228          78         188]\n",
            " [      160.5         242          65         162]\n",
            " [        175       241.5          92         163]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.81727     0.56778     0.49661]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([231.0, 228.0, 78.0, 188.0], 0.8172704577445984, -1), ([160.5, 242.0, 65.0, 162.0], 0.5677824020385742, -1), ([175.0, 241.5, 92.0, 163.0], 0.49661311507225037, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 1 car, 231.8ms\n",
            "Speed: 4.0ms preprocess, 231.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        229       228.5          80         187]\n",
            " [        176         241          98         164]\n",
            " [      159.5         245          67         162]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.85742     0.51462     0.30893]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([229.0, 228.5, 80.0, 187.0], 0.8574205040931702, -1), ([176.0, 241.0, 98.0, 164.0], 0.5146231651306152, -1), ([159.5, 245.0, 67.0, 162.0], 0.30892983078956604, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 1 car, 252.3ms\n",
            "Speed: 6.3ms preprocess, 252.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      229.5         229          81         188]\n",
            " [      176.5         242          99         160]\n",
            " [        158         247          66         152]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.85655     0.52175     0.30977]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([229.5, 229.0, 81.0, 188.0], 0.8565529584884644, -1), ([176.5, 242.0, 99.0, 160.0], 0.5217505097389221, -1), ([158.0, 247.0, 66.0, 152.0], 0.3097713589668274, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 240.9ms\n",
            "Speed: 3.4ms preprocess, 240.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        230         229          82         188]\n",
            " [        178       244.5         100         157]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.79629     0.61383]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([230.0, 229.0, 82.0, 188.0], 0.796285092830658, -1), ([178.0, 244.5, 100.0, 157.0], 0.6138290166854858, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 215.5ms\n",
            "Speed: 10.1ms preprocess, 215.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      235.5       228.5          73         189]\n",
            " [        179         246         102         154]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85279     0.61511]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([235.5, 228.5, 73.0, 189.0], 0.8527918457984924, -1), ([179.0, 246.0, 102.0, 154.0], 0.6151140332221985, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 1 car, 235.7ms\n",
            "Speed: 11.9ms preprocess, 235.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        237         229          74         188]\n",
            " [        178         248         100         150]\n",
            " [        159         251          66         144]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.86383     0.71081     0.26404]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([237.0, 229.0, 74.0, 188.0], 0.8638262152671814, -1), ([178.0, 248.0, 100.0, 150.0], 0.7108059525489807, -1), ([159.0, 251.0, 66.0, 144.0], 0.26404163241386414, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 238.3ms\n",
            "Speed: 3.5ms preprocess, 238.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      240.5       228.5          69         187]\n",
            " [      178.5         250         101         148]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85672     0.49728]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([240.5, 228.5, 69.0, 187.0], 0.8567212224006653, -1), ([178.5, 250.0, 101.0, 148.0], 0.49728232622146606, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 237.9ms\n",
            "Speed: 3.9ms preprocess, 237.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        242         228          66         188]\n",
            " [      178.5         251         101         146]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85343      0.4694]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([242.0, 228.0, 66.0, 188.0], 0.8534305691719055, -1), ([178.5, 251.0, 101.0, 146.0], 0.4693966507911682, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 1 car, 1 truck, 226.7ms\n",
            "Speed: 3.7ms preprocess, 226.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        240         228          72         188]\n",
            " [      175.5         252          93         142]\n",
            " [        161         253          68         142]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.84269     0.51173     0.46212]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([240.0, 228.0, 72.0, 188.0], 0.8426938652992249, -1), ([175.5, 252.0, 93.0, 142.0], 0.5117316246032715, -1), ([161.0, 253.0, 68.0, 142.0], 0.46212172508239746, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 237.1ms\n",
            "Speed: 8.4ms preprocess, 237.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        246         228          64         188]\n",
            " [        178         251         100         144]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87209     0.76599]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([246.0, 228.0, 64.0, 188.0], 0.8720906972885132, -1), ([178.0, 251.0, 100.0, 144.0], 0.7659900784492493, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 235.7ms\n",
            "Speed: 10.1ms preprocess, 235.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      246.5         228          63         188]\n",
            " [      177.5         250          99         146]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87436     0.76158]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([246.5, 228.0, 63.0, 188.0], 0.8743628263473511, -1), ([177.5, 250.0, 99.0, 146.0], 0.7615774273872375, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 225.6ms\n",
            "Speed: 8.9ms preprocess, 225.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      246.5         228          65         188]\n",
            " [      178.5       248.5          97         149]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87753     0.82482]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([246.5, 228.0, 65.0, 188.0], 0.8775274753570557, -1), ([178.5, 248.5, 97.0, 149.0], 0.8248238563537598, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 223.1ms\n",
            "Speed: 10.3ms preprocess, 223.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        247         227          64         188]\n",
            " [        178       246.5          98         153]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87712     0.83769]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([247.0, 227.0, 64.0, 188.0], 0.8771200776100159, -1), ([178.0, 246.5, 98.0, 153.0], 0.8376924991607666, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 203.2ms\n",
            "Speed: 3.8ms preprocess, 203.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      247.5         227          65         190]\n",
            " [      177.5         244          95         156]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87339     0.81716]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([247.5, 227.0, 65.0, 190.0], 0.8733928203582764, -1), ([177.5, 244.0, 95.0, 156.0], 0.8171591758728027, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 234.0ms\n",
            "Speed: 12.0ms preprocess, 234.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        248       226.5          64         189]\n",
            " [        180       242.5          88         159]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87674     0.81078]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([248.0, 226.5, 64.0, 189.0], 0.8767370581626892, -1), ([180.0, 242.5, 88.0, 159.0], 0.8107849359512329, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 228.0ms\n",
            "Speed: 4.1ms preprocess, 228.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        249       226.5          64         189]\n",
            " [        179       240.5          86         163]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86298      0.8122]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([249.0, 226.5, 64.0, 189.0], 0.862975537776947, -1), ([179.0, 240.5, 86.0, 163.0], 0.8122037649154663, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 233.5ms\n",
            "Speed: 3.4ms preprocess, 233.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      248.5         226          65         190]\n",
            " [        178       237.5          84         167]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86322     0.77523]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([248.5, 226.0, 65.0, 190.0], 0.8632166981697083, -1), ([178.0, 237.5, 84.0, 167.0], 0.7752344608306885, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 223.4ms\n",
            "Speed: 3.6ms preprocess, 223.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      248.5         226          67         190]\n",
            " [      176.5         236          85         172]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85225     0.80229]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([248.5, 226.0, 67.0, 190.0], 0.8522511124610901, -1), ([176.5, 236.0, 85.0, 172.0], 0.8022943139076233, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 214.2ms\n",
            "Speed: 7.3ms preprocess, 214.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        248       225.5          66         191]\n",
            " [      169.5       233.5          95         177]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.84881     0.81295]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([248.0, 225.5, 66.0, 191.0], 0.848813533782959, -1), ([169.5, 233.5, 95.0, 177.0], 0.8129487037658691, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 202.8ms\n",
            "Speed: 4.4ms preprocess, 202.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      248.5         225          67         192]\n",
            " [        173         232          88         180]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.84973     0.84211]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([248.5, 225.0, 67.0, 192.0], 0.8497284650802612, -1), ([173.0, 232.0, 88.0, 180.0], 0.8421139717102051, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 233.2ms\n",
            "Speed: 3.9ms preprocess, 233.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      249.5         225          67         194]\n",
            " [      170.5       230.5          95         185]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85705     0.81051]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([249.5, 225.0, 67.0, 194.0], 0.857054591178894, -1), ([170.5, 230.5, 95.0, 185.0], 0.8105095624923706, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 238.3ms\n",
            "Speed: 3.5ms preprocess, 238.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      168.5         228          87         188]\n",
            " [        247         225          72         194]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.84931     0.84086]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([168.5, 228.0, 87.0, 188.0], 0.8493121862411499, -1), ([247.0, 225.0, 72.0, 194.0], 0.8408612012863159, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 1 chair, 205.5ms\n",
            "Speed: 3.7ms preprocess, 205.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        168         227          90         192]\n",
            " [        247         225          72         194]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87312     0.84169]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([168.0, 227.0, 90.0, 192.0], 0.8731216788291931, -1), ([247.0, 225.0, 72.0, 194.0], 0.8416926860809326, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 227.3ms\n",
            "Speed: 3.7ms preprocess, 227.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        167       225.5          94         195]\n",
            " [      246.5       225.5          73         195]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85973     0.84565]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([167.0, 225.5, 94.0, 195.0], 0.8597293496131897, -1), ([246.5, 225.5, 73.0, 195.0], 0.845646858215332, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 1 chair, 331.5ms\n",
            "Speed: 3.6ms preprocess, 331.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      166.5         224          99         198]\n",
            " [      248.5       224.5          67         195]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.83669     0.83179]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([166.5, 224.0, 99.0, 198.0], 0.8366934061050415, -1), ([248.5, 224.5, 67.0, 195.0], 0.831786036491394, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 truck, 2 chairs, 322.7ms\n",
            "Speed: 15.4ms preprocess, 322.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      165.5       222.5          97         201]\n",
            " [        237       225.5          90         197]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.8643     0.81537]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([165.5, 222.5, 97.0, 201.0], 0.8643031120300293, -1), ([237.0, 225.5, 90.0, 197.0], 0.8153708577156067, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 2 chairs, 316.9ms\n",
            "Speed: 11.7ms preprocess, 316.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        165       222.5          94         203]\n",
            " [      248.5         225          69         196]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.84965     0.84501]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([165.0, 222.5, 94.0, 203.0], 0.8496543169021606, -1), ([248.5, 225.0, 69.0, 196.0], 0.8450062870979309, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 326.9ms\n",
            "Speed: 3.4ms preprocess, 326.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        247       224.5          68         197]\n",
            " [        171         222         102         204]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85082     0.83723]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([247.0, 224.5, 68.0, 197.0], 0.8508249521255493, -1), ([171.0, 222.0, 102.0, 204.0], 0.8372326493263245, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 317.9ms\n",
            "Speed: 6.6ms preprocess, 317.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      168.5         222          99         204]\n",
            " [        246         225          70         196]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86982     0.86347]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([168.5, 222.0, 99.0, 204.0], 0.869815468788147, -1), ([246.0, 225.0, 70.0, 196.0], 0.8634701371192932, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 312.5ms\n",
            "Speed: 4.4ms preprocess, 312.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      167.5       221.5          97         203]\n",
            " [      244.5       224.5          71         197]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88427     0.87076]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([167.5, 221.5, 97.0, 203.0], 0.8842729926109314, -1), ([244.5, 224.5, 71.0, 197.0], 0.8707556128501892, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 2 chairs, 348.9ms\n",
            "Speed: 11.8ms preprocess, 348.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        165       221.5          94         205]\n",
            " [      242.5         224          75         198]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87856     0.87707]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([165.0, 221.5, 94.0, 205.0], 0.8785640597343445, -1), ([242.5, 224.0, 75.0, 198.0], 0.8770749568939209, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 321.8ms\n",
            "Speed: 5.1ms preprocess, 321.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      240.5         224          77         200]\n",
            " [      165.5         221          91         206]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88569     0.87505]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([240.5, 224.0, 77.0, 200.0], 0.8856857419013977, -1), ([165.5, 221.0, 91.0, 206.0], 0.8750468492507935, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 342.9ms\n",
            "Speed: 3.4ms preprocess, 342.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      239.5         224          77         200]\n",
            " [      166.5       220.5          89         205]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87533      0.8742]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([239.5, 224.0, 77.0, 200.0], 0.8753295540809631, -1), ([166.5, 220.5, 89.0, 205.0], 0.8741994500160217, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 3 chairs, 328.3ms\n",
            "Speed: 7.3ms preprocess, 328.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        168       220.5          88         205]\n",
            " [      237.5         224          81         200]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89366     0.87954]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([168.0, 220.5, 88.0, 205.0], 0.8936636447906494, -1), ([237.5, 224.0, 81.0, 200.0], 0.8795368075370789, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 3 chairs, 284.8ms\n",
            "Speed: 8.1ms preprocess, 284.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        169       220.5          90         205]\n",
            " [        238       223.5          78         201]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90005     0.88518]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([169.0, 220.5, 90.0, 205.0], 0.9000502824783325, -1), ([238.0, 223.5, 78.0, 201.0], 0.8851795792579651, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 3 chairs, 228.3ms\n",
            "Speed: 3.5ms preprocess, 228.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        171         221          92         206]\n",
            " [        237       222.5          80         201]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89651     0.86724]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([171.0, 221.0, 92.0, 206.0], 0.8965078592300415, -1), ([237.0, 222.5, 80.0, 201.0], 0.8672405481338501, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 3 chairs, 224.0ms\n",
            "Speed: 6.5ms preprocess, 224.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        173         221          96         204]\n",
            " [      236.5       222.5          81         201]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90599     0.87668]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([173.0, 221.0, 96.0, 204.0], 0.9059928059577942, -1), ([236.5, 222.5, 81.0, 201.0], 0.8766849040985107, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 3 chairs, 212.1ms\n",
            "Speed: 3.6ms preprocess, 212.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      173.5       221.5          97         205]\n",
            " [      236.5       222.5          79         201]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90482     0.86185]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([173.5, 221.5, 97.0, 205.0], 0.9048176407814026, -1), ([236.5, 222.5, 79.0, 201.0], 0.8618510365486145, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 3 chairs, 1 refrigerator, 243.2ms\n",
            "Speed: 5.5ms preprocess, 243.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        175         221          98         204]\n",
            " [      236.5         222          77         202]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [       0.91     0.85614]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([175.0, 221.0, 98.0, 204.0], 0.9099953174591064, -1), ([236.5, 222.0, 77.0, 202.0], 0.8561398386955261, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 3 chairs, 223.5ms\n",
            "Speed: 3.4ms preprocess, 223.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        175       221.5          98         203]\n",
            " [      236.5         222          77         202]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90759     0.85834]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([175.0, 221.5, 98.0, 203.0], 0.9075939059257507, -1), ([236.5, 222.0, 77.0, 202.0], 0.8583351969718933, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 1 chair, 232.0ms\n",
            "Speed: 3.4ms preprocess, 232.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        175       221.5          98         203]\n",
            " [        237       221.5          76         203]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90494     0.85836]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([175.0, 221.5, 98.0, 203.0], 0.904940664768219, -1), ([237.0, 221.5, 76.0, 203.0], 0.8583554029464722, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 1 chair, 1 refrigerator, 233.1ms\n",
            "Speed: 3.7ms preprocess, 233.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        174         222          98         202]\n",
            " [      236.5       221.5          77         203]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90747     0.85391]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([174.0, 222.0, 98.0, 202.0], 0.9074745774269104, -1), ([236.5, 221.5, 77.0, 203.0], 0.8539149761199951, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 1 chair, 196.9ms\n",
            "Speed: 3.7ms preprocess, 196.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        174       222.5          98         201]\n",
            " [      236.5         221          77         202]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90661     0.85907]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([174.0, 222.5, 98.0, 201.0], 0.9066052436828613, -1), ([236.5, 221.0, 77.0, 202.0], 0.8590661883354187, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 1 chair, 222.9ms\n",
            "Speed: 9.7ms preprocess, 222.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      174.5         222          97         202]\n",
            " [      235.5       221.5          75         203]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.9057     0.86313]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([174.5, 222.0, 97.0, 202.0], 0.9057035446166992, -1), ([235.5, 221.5, 75.0, 203.0], 0.8631300330162048, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 1 chair, 233.4ms\n",
            "Speed: 3.7ms preprocess, 233.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      175.5         223          97         200]\n",
            " [        233         221          78         204]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91214     0.86124]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([175.5, 223.0, 97.0, 200.0], 0.9121363759040833, -1), ([233.0, 221.0, 78.0, 204.0], 0.861239492893219, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 2 chairs, 241.8ms\n",
            "Speed: 3.7ms preprocess, 241.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      175.5       222.5          97         201]\n",
            " [      231.5         221          81         204]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.92073     0.88414]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([175.5, 222.5, 97.0, 201.0], 0.9207331538200378, -1), ([231.5, 221.0, 81.0, 204.0], 0.8841431736946106, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 2 chairs, 264.4ms\n",
            "Speed: 4.2ms preprocess, 264.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      175.5         223          97         200]\n",
            " [      233.5       220.5          77         203]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.92178     0.90253]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([175.5, 223.0, 97.0, 200.0], 0.9217751026153564, -1), ([233.5, 220.5, 77.0, 203.0], 0.9025333523750305, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 1 chair, 216.9ms\n",
            "Speed: 3.5ms preprocess, 216.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        233         220          76         204]\n",
            " [        175         224          98         198]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90917     0.90579]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([233.0, 220.0, 76.0, 204.0], 0.9091700315475464, -1), ([175.0, 224.0, 98.0, 198.0], 0.9057921171188354, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 1 chair, 213.3ms\n",
            "Speed: 3.4ms preprocess, 213.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      233.5       220.5          75         203]\n",
            " [      175.5         225          99         194]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.9051     0.89445]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([233.5, 220.5, 75.0, 203.0], 0.905098021030426, -1), ([175.5, 225.0, 99.0, 194.0], 0.8944522738456726, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 1 chair, 1 book, 256.8ms\n",
            "Speed: 3.5ms preprocess, 256.8ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      232.5         220          75         204]\n",
            " [        176         226          98         194]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90144     0.89911]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([232.5, 220.0, 75.0, 204.0], 0.9014443159103394, -1), ([176.0, 226.0, 98.0, 194.0], 0.8991084098815918, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 199.9ms\n",
            "Speed: 5.5ms preprocess, 199.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      231.5         220          75         204]\n",
            " [        176       226.5          98         191]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89988     0.89871]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([231.5, 220.0, 75.0, 204.0], 0.8998773694038391, -1), ([176.0, 226.5, 98.0, 191.0], 0.898714542388916, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 227.9ms\n",
            "Speed: 10.2ms preprocess, 227.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      230.5       219.5          75         205]\n",
            " [        174         228         100         188]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90925     0.86961]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([230.5, 219.5, 75.0, 205.0], 0.9092530608177185, -1), ([174.0, 228.0, 100.0, 188.0], 0.8696095943450928, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 1 chair, 1 book, 236.7ms\n",
            "Speed: 9.8ms preprocess, 236.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        231         219          76         206]\n",
            " [        171         229         106         186]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90607     0.87717]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([231.0, 219.0, 76.0, 206.0], 0.9060711860656738, -1), ([171.0, 229.0, 106.0, 186.0], 0.8771703243255615, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 1 chair, 243.4ms\n",
            "Speed: 5.5ms preprocess, 243.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        230         219          76         208]\n",
            " [      169.5       229.5         107         185]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90328     0.87633]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([230.0, 219.0, 76.0, 208.0], 0.9032796025276184, -1), ([169.5, 229.5, 107.0, 185.0], 0.8763270974159241, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 1 chair, 239.0ms\n",
            "Speed: 4.1ms preprocess, 239.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        230       218.5          76         209]\n",
            " [        165       230.5         112         185]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91298     0.87541]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([230.0, 218.5, 76.0, 209.0], 0.9129787683486938, -1), ([165.0, 230.5, 112.0, 185.0], 0.8754082918167114, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 1 chair, 237.7ms\n",
            "Speed: 5.2ms preprocess, 237.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      229.5         219          77         210]\n",
            " [        161         231         120         182]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91223      0.8793]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([229.5, 219.0, 77.0, 210.0], 0.9122269153594971, -1), ([161.0, 231.0, 120.0, 182.0], 0.8792959451675415, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 1 chair, 235.1ms\n",
            "Speed: 3.4ms preprocess, 235.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      229.5         219          75         210]\n",
            " [        159       232.5         120         181]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90887     0.87796]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([229.5, 219.0, 75.0, 210.0], 0.9088700413703918, -1), ([159.0, 232.5, 120.0, 181.0], 0.8779628276824951, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 211.5ms\n",
            "Speed: 3.4ms preprocess, 211.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      230.5         219          75         210]\n",
            " [        159       233.5         118         179]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89346     0.86066]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([230.5, 219.0, 75.0, 210.0], 0.893458902835846, -1), ([159.0, 233.5, 118.0, 179.0], 0.8606564998626709, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 1 book, 240.5ms\n",
            "Speed: 3.5ms preprocess, 240.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      230.5         219          75         210]\n",
            " [        160       233.5         112         179]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89308     0.82897]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([230.5, 219.0, 75.0, 210.0], 0.8930842280387878, -1), ([160.0, 233.5, 112.0, 179.0], 0.8289721012115479, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 209.1ms\n",
            "Speed: 7.6ms preprocess, 209.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      231.5         219          73         210]\n",
            " [      161.5         234         107         178]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87669     0.81837]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([231.5, 219.0, 73.0, 210.0], 0.8766896724700928, -1), ([161.5, 234.0, 107.0, 178.0], 0.8183701038360596, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 231.0ms\n",
            "Speed: 11.2ms preprocess, 231.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        232       218.5          74         209]\n",
            " [        164         236         102         174]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87544     0.80245]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([232.0, 218.5, 74.0, 209.0], 0.8754361867904663, -1), ([164.0, 236.0, 102.0, 174.0], 0.8024455904960632, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 1 remote, 1 book, 243.6ms\n",
            "Speed: 10.6ms preprocess, 243.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        233       218.5          74         209]\n",
            " [        163       235.5          98         175]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87014     0.81904]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([233.0, 218.5, 74.0, 209.0], 0.8701407313346863, -1), ([163.0, 235.5, 98.0, 175.0], 0.8190375566482544, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 1 remote, 1 book, 229.6ms\n",
            "Speed: 3.8ms preprocess, 229.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        233         218          74         210]\n",
            " [      162.5         237          97         174]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86771     0.77198]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([233.0, 218.0, 74.0, 210.0], 0.8677146434783936, -1), ([162.5, 237.0, 97.0, 174.0], 0.7719762921333313, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 1 book, 330.4ms\n",
            "Speed: 4.1ms preprocess, 330.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      233.5       217.5          73         209]\n",
            " [      166.5       238.5          97         171]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85431     0.72895]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([233.5, 217.5, 73.0, 209.0], 0.8543126583099365, -1), ([166.5, 238.5, 97.0, 171.0], 0.7289509177207947, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 1 book, 320.1ms\n",
            "Speed: 9.6ms preprocess, 320.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      232.5         217          73         210]\n",
            " [      162.5         237          93         172]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86277     0.72216]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([232.5, 217.0, 73.0, 210.0], 0.8627668619155884, -1), ([162.5, 237.0, 93.0, 172.0], 0.7221585512161255, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 motorcycle, 1 chair, 1 book, 299.5ms\n",
            "Speed: 3.4ms preprocess, 299.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      230.5         216          77         210]\n",
            " [      160.5       236.5          91         173]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85098     0.55275]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([230.5, 216.0, 77.0, 210.0], 0.8509841561317444, -1), ([160.5, 236.5, 91.0, 173.0], 0.552754282951355, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 motorcycle, 1 cup, 1 book, 318.0ms\n",
            "Speed: 3.5ms preprocess, 318.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        230       215.5          78         211]\n",
            " [        165       237.5          88         171]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86034     0.66301]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([230.0, 215.5, 78.0, 211.0], 0.860342800617218, -1), ([165.0, 237.5, 88.0, 171.0], 0.6630140542984009, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 motorcycle, 1 chair, 1 book, 323.5ms\n",
            "Speed: 8.2ms preprocess, 323.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        233       215.5          74         211]\n",
            " [      159.5         237          89         172]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85921     0.63928]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([233.0, 215.5, 74.0, 211.0], 0.8592113256454468, -1), ([159.5, 237.0, 89.0, 172.0], 0.6392751336097717, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 motorcycle, 315.5ms\n",
            "Speed: 13.4ms preprocess, 315.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      234.5       214.5          73         211]\n",
            " [        160         236          98         174]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86322     0.78332]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([234.5, 214.5, 73.0, 211.0], 0.8632178902626038, -1), ([160.0, 236.0, 98.0, 174.0], 0.7833172082901001, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 motorcycle, 1 book, 312.0ms\n",
            "Speed: 3.6ms preprocess, 312.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      235.5       214.5          75         211]\n",
            " [        170       236.5          74         175]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86564     0.55234]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([235.5, 214.5, 75.0, 211.0], 0.8656350374221802, -1), ([170.0, 236.5, 74.0, 175.0], 0.5523396134376526, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 chair, 1 book, 338.0ms\n",
            "Speed: 4.0ms preprocess, 338.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      236.5       214.5          75         211]\n",
            " [      159.5       234.5          97         177]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87842     0.81679]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([236.5, 214.5, 75.0, 211.0], 0.8784182667732239, -1), ([159.5, 234.5, 97.0, 177.0], 0.8167949318885803, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 1 refrigerator, 309.9ms\n",
            "Speed: 14.6ms preprocess, 309.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        238         215          76         214]\n",
            " [      159.5       233.5          97         179]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88363     0.73033]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([238.0, 215.0, 76.0, 214.0], 0.8836304545402527, -1), ([159.5, 233.5, 97.0, 179.0], 0.7303324937820435, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 1 refrigerator, 346.6ms\n",
            "Speed: 13.5ms preprocess, 346.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        238       214.5          76         215]\n",
            " [        160         231          96         182]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.8847       0.777]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([238.0, 214.5, 76.0, 215.0], 0.8846989870071411, -1), ([160.0, 231.0, 96.0, 182.0], 0.7770015597343445, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 333.7ms\n",
            "Speed: 6.7ms preprocess, 333.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      237.5         214          77         216]\n",
            " [      160.5         230          97         184]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87636     0.82643]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([237.5, 214.0, 77.0, 216.0], 0.8763570785522461, -1), ([160.5, 230.0, 97.0, 184.0], 0.8264313340187073, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 245.8ms\n",
            "Speed: 7.1ms preprocess, 245.8ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        161       227.5          98         189]\n",
            " [        234         214          84         216]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86574     0.85145]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([161.0, 227.5, 98.0, 189.0], 0.8657423853874207, -1), ([234.0, 214.0, 84.0, 216.0], 0.8514534831047058, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 chair, 1 refrigerator, 226.4ms\n",
            "Speed: 3.6ms preprocess, 226.4ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        231       213.5          90         215]\n",
            " [        160         225          96         192]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86119     0.84482]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([231.0, 213.5, 90.0, 215.0], 0.8611907958984375, -1), ([160.0, 225.0, 96.0, 192.0], 0.8448200821876526, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 motorcycle, 1 chair, 1 refrigerator, 224.3ms\n",
            "Speed: 5.4ms preprocess, 224.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        233       213.5          86         215]\n",
            " [      158.5       223.5          93         195]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85277     0.83862]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([233.0, 213.5, 86.0, 215.0], 0.8527665138244629, -1), ([158.5, 223.5, 93.0, 195.0], 0.8386223912239075, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 1 refrigerator, 220.9ms\n",
            "Speed: 3.6ms preprocess, 220.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      159.5       221.5          97         201]\n",
            " [      229.5       213.5          93         217]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [      0.867      0.8613]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([159.5, 221.5, 97.0, 201.0], 0.8670012950897217, -1), ([229.5, 213.5, 93.0, 217.0], 0.861300528049469, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 229.0ms\n",
            "Speed: 7.4ms preprocess, 229.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        236       213.5          82         217]\n",
            " [      158.5       220.5         101         203]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85363     0.84305]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([236.0, 213.5, 82.0, 217.0], 0.8536312580108643, -1), ([158.5, 220.5, 101.0, 203.0], 0.8430467844009399, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 217.8ms\n",
            "Speed: 4.1ms preprocess, 217.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        236       213.5          80         217]\n",
            " [        159         220         102         206]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.8654     0.85994]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([236.0, 213.5, 80.0, 217.0], 0.8653958439826965, -1), ([159.0, 220.0, 102.0, 206.0], 0.8599374294281006, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 1 chair, 242.5ms\n",
            "Speed: 3.6ms preprocess, 242.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        228       213.5          96         219]\n",
            " [        158       218.5         100         209]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86257     0.85036]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([228.0, 213.5, 96.0, 219.0], 0.8625668883323669, -1), ([158.0, 218.5, 100.0, 209.0], 0.8503598570823669, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 1 chair, 233.0ms\n",
            "Speed: 3.6ms preprocess, 233.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        235         213          80         218]\n",
            " [        157         217         102         210]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85263     0.60652]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([235.0, 213.0, 80.0, 218.0], 0.8526256084442139, -1), ([157.0, 217.0, 102.0, 210.0], 0.6065232753753662, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 1 chair, 233.6ms\n",
            "Speed: 3.4ms preprocess, 233.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        232         213          84         218]\n",
            " [        158       214.5         100         209]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85101     0.82016]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([232.0, 213.0, 84.0, 218.0], 0.8510134220123291, -1), ([158.0, 214.5, 100.0, 209.0], 0.8201640248298645, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 1 chair, 249.9ms\n",
            "Speed: 5.6ms preprocess, 249.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      226.5       213.5          95         219]\n",
            " [        159       214.5          98         211]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85655     0.78561]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([226.5, 213.5, 95.0, 219.0], 0.8565459251403809, -1), ([159.0, 214.5, 98.0, 211.0], 0.7856077551841736, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 241.6ms\n",
            "Speed: 3.5ms preprocess, 241.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      230.5         213          87         220]\n",
            " [      159.5         212          95         208]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85526      0.7491]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([230.5, 213.0, 87.0, 220.0], 0.8552587032318115, -1), ([159.5, 212.0, 95.0, 208.0], 0.7491026520729065, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 1 remote, 239.6ms\n",
            "Speed: 6.0ms preprocess, 239.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        225         213          98         220]\n",
            " [      159.5       214.5          91         213]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.8556     0.84322]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([225.0, 213.0, 98.0, 220.0], 0.855595588684082, -1), ([159.5, 214.5, 91.0, 213.0], 0.8432196378707886, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 251.3ms\n",
            "Speed: 4.3ms preprocess, 251.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        223       212.5         102         221]\n",
            " [      156.5       213.5          91         211]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87406     0.74125]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([223.0, 212.5, 102.0, 221.0], 0.8740615248680115, -1), ([156.5, 213.5, 91.0, 211.0], 0.7412475347518921, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 231.0ms\n",
            "Speed: 14.8ms preprocess, 231.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      223.5         213         105         220]\n",
            " [        157         214          96         212]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85351     0.79502]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([223.5, 213.0, 105.0, 220.0], 0.8535060882568359, -1), ([157.0, 214.0, 96.0, 212.0], 0.7950214147567749, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 1 chair, 239.7ms\n",
            "Speed: 3.5ms preprocess, 239.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      223.5       212.5         105         221]\n",
            " [        157         214         100         212]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85798     0.63023]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([223.5, 212.5, 105.0, 221.0], 0.8579781651496887, -1), ([157.0, 214.0, 100.0, 212.0], 0.6302251219749451, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 1 chair, 229.9ms\n",
            "Speed: 9.1ms preprocess, 229.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        225       212.5         104         221]\n",
            " [      156.5       213.5         103         207]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85854     0.65778]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([225.0, 212.5, 104.0, 221.0], 0.8585360646247864, -1), ([156.5, 213.5, 103.0, 207.0], 0.6577849984169006, -1)]\n",
            "Processing frame 1800\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 1 chair, 200.6ms\n",
            "Speed: 7.1ms preprocess, 200.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        223         212         106         220]\n",
            " [        154         215         104         206]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86841     0.73082]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([223.0, 212.0, 106.0, 220.0], 0.8684088587760925, -1), ([154.0, 215.0, 104.0, 206.0], 0.7308232188224792, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 1 chair, 239.8ms\n",
            "Speed: 10.0ms preprocess, 239.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      221.5         212         107         220]\n",
            " [      149.5       215.5          99         207]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88325     0.81415]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([221.5, 212.0, 107.0, 220.0], 0.8832492232322693, -1), ([149.5, 215.5, 99.0, 207.0], 0.8141541481018066, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 1 chair, 243.2ms\n",
            "Speed: 3.4ms preprocess, 243.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      220.5       210.5         107         219]\n",
            " [        149         216         100         204]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88761     0.80705]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([220.5, 210.5, 107.0, 219.0], 0.8876106142997742, -1), ([149.0, 216.0, 100.0, 204.0], 0.8070475459098816, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 238.1ms\n",
            "Speed: 8.6ms preprocess, 238.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        220         211         106         220]\n",
            " [        148         217         100         204]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.8748     0.71375]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([220.0, 211.0, 106.0, 220.0], 0.874796450138092, -1), ([148.0, 217.0, 100.0, 204.0], 0.7137547731399536, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 1 chair, 236.2ms\n",
            "Speed: 6.6ms preprocess, 236.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      218.5         211         107         220]\n",
            " [      146.5       218.5          99         203]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88563     0.84298]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([218.5, 211.0, 107.0, 220.0], 0.8856250643730164, -1), ([146.5, 218.5, 99.0, 203.0], 0.8429788947105408, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 truck, 1 chair, 226.7ms\n",
            "Speed: 7.0ms preprocess, 226.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        218       211.5         106         221]\n",
            " [      145.5         219          99         204]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86457     0.85862]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([218.0, 211.5, 106.0, 221.0], 0.8645721673965454, -1), ([145.5, 219.0, 99.0, 204.0], 0.8586179614067078, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 1 refrigerator, 209.7ms\n",
            "Speed: 3.5ms preprocess, 209.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        220         212         100         222]\n",
            " [      143.5         219          99         200]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85706     0.85596]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([220.0, 212.0, 100.0, 222.0], 0.857057511806488, -1), ([143.5, 219.0, 99.0, 200.0], 0.855960488319397, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 244.7ms\n",
            "Speed: 3.7ms preprocess, 244.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      215.5       211.5         105         223]\n",
            " [      142.5         220          97         200]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86188     0.81292]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([215.5, 211.5, 105.0, 223.0], 0.8618841171264648, -1), ([142.5, 220.0, 97.0, 200.0], 0.8129227757453918, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 241.8ms\n",
            "Speed: 7.3ms preprocess, 241.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        216         213         100         220]\n",
            " [        142       216.5          96         193]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.8676     0.74074]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([216.0, 213.0, 100.0, 220.0], 0.8675951361656189, -1), ([142.0, 216.5, 96.0, 193.0], 0.7407383322715759, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 1 book, 203.6ms\n",
            "Speed: 5.2ms preprocess, 203.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      214.5       212.5         101         221]\n",
            " [        141         215          92         192]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88574     0.66409]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([214.5, 212.5, 101.0, 221.0], 0.8857405781745911, -1), ([141.0, 215.0, 92.0, 192.0], 0.6640920639038086, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 223.4ms\n",
            "Speed: 3.6ms preprocess, 223.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        212       212.5         106         221]\n",
            " [      141.5       217.5          87         199]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.9034     0.64428]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([212.0, 212.5, 106.0, 221.0], 0.903399646282196, -1), ([141.5, 217.5, 87.0, 199.0], 0.6442824602127075, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 1 book, 222.5ms\n",
            "Speed: 4.4ms preprocess, 222.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      212.5       211.5         105         223]\n",
            " [        141         217          80         190]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89138     0.59954]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([212.5, 211.5, 105.0, 223.0], 0.8913788795471191, -1), ([141.0, 217.0, 80.0, 190.0], 0.5995405316352844, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 1 book, 325.9ms\n",
            "Speed: 4.3ms preprocess, 325.9ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      209.5         210         113         224]\n",
            " [        142       219.5          80         185]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90212     0.67297]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([209.5, 210.0, 113.0, 224.0], 0.902115523815155, -1), ([142.0, 219.5, 80.0, 185.0], 0.6729726791381836, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 chair, 2 books, 336.8ms\n",
            "Speed: 3.7ms preprocess, 336.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        209       209.5         116         225]\n",
            " [      142.5         222          75         172]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.76269     0.47337]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([209.0, 209.5, 116.0, 225.0], 0.7626945972442627, -1), ([142.5, 222.0, 75.0, 172.0], 0.4733704924583435, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 2 books, 308.0ms\n",
            "Speed: 4.8ms preprocess, 308.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      209.5       209.5         115         225]\n",
            " [      144.5       215.5          71         145]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.75043     0.47566]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([209.5, 209.5, 115.0, 225.0], 0.7504289150238037, -1), ([144.5, 215.5, 71.0, 145.0], 0.47566160559654236, -1)]\n",
            "\n",
            "0: 480x640 1 person, 1 chair, 1 book, 314.0ms\n",
            "Speed: 15.4ms preprocess, 314.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        191       209.5         154         225]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.90164]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([191.0, 209.5, 154.0, 225.0], 0.9016413688659668, -1)]\n",
            "\n",
            "0: 480x640 1 person, 1 chair, 1 book, 314.9ms\n",
            "Speed: 13.1ms preprocess, 314.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      193.5         210         151         226]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.90922]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([193.5, 210.0, 151.0, 226.0], 0.9092226028442383, -1)]\n",
            "\n",
            "0: 480x640 1 person, 1 chair, 269.4ms\n",
            "Speed: 3.7ms preprocess, 269.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        195         210         148         226]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.91285]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([195.0, 210.0, 148.0, 226.0], 0.9128468632698059, -1)]\n",
            "\n",
            "0: 480x640 1 person, 1 car, 1 chair, 1 book, 303.8ms\n",
            "Speed: 6.7ms preprocess, 303.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        198         210         144         224]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.90013]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([198.0, 210.0, 144.0, 224.0], 0.9001302123069763, -1)]\n",
            "\n",
            "0: 480x640 1 person, 1 car, 1 chair, 2 books, 325.3ms\n",
            "Speed: 5.8ms preprocess, 325.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        203         210         134         224]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.89843]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([203.0, 210.0, 134.0, 224.0], 0.8984314799308777, -1)]\n",
            "\n",
            "0: 480x640 1 person, 1 car, 1 chair, 1 book, 313.2ms\n",
            "Speed: 3.5ms preprocess, 313.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        200       210.5         138         225]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.88398]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([200.0, 210.5, 138.0, 225.0], 0.8839834928512573, -1)]\n",
            "\n",
            "0: 480x640 1 person, 1 car, 1 chair, 1 book, 322.0ms\n",
            "Speed: 5.4ms preprocess, 322.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      197.5         211         143         226]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.88217]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([197.5, 211.0, 143.0, 226.0], 0.8821706771850586, -1)]\n",
            "\n",
            "0: 480x640 1 person, 1 car, 1 truck, 1 chair, 1 book, 326.1ms\n",
            "Speed: 7.2ms preprocess, 326.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        197         211         142         224]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [     0.8835]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([197.0, 211.0, 142.0, 224.0], 0.8835047483444214, -1)]\n",
            "\n",
            "0: 480x640 1 person, 1 car, 1 truck, 3 chairs, 1 book, 321.6ms\n",
            "Speed: 8.5ms preprocess, 321.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        196         212         138         224]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.89916]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([196.0, 212.0, 138.0, 224.0], 0.8991602063179016, -1)]\n",
            "\n",
            "0: 480x640 1 person, 1 car, 1 truck, 3 chairs, 1 book, 283.5ms\n",
            "Speed: 7.7ms preprocess, 283.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      195.5         213         137         222]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.88151]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([195.5, 213.0, 137.0, 222.0], 0.8815112113952637, -1)]\n",
            "\n",
            "0: 480x640 1 person, 1 car, 1 truck, 1 chair, 2 books, 210.9ms\n",
            "Speed: 4.2ms preprocess, 210.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      196.5       213.5         137         221]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.90299]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([196.5, 213.5, 137.0, 221.0], 0.9029881954193115, -1)]\n",
            "\n",
            "0: 480x640 1 person, 1 car, 1 truck, 1 chair, 218.3ms\n",
            "Speed: 3.8ms preprocess, 218.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        193       213.5         140         221]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.89284]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([193.0, 213.5, 140.0, 221.0], 0.8928379416465759, -1)]\n",
            "\n",
            "0: 480x640 1 person, 1 car, 1 truck, 1 chair, 2 books, 208.8ms\n",
            "Speed: 15.5ms preprocess, 208.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      192.5       213.5         141         219]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.88642]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([192.5, 213.5, 141.0, 219.0], 0.8864179849624634, -1)]\n",
            "\n",
            "0: 480x640 1 person, 1 chair, 204.3ms\n",
            "Speed: 3.8ms preprocess, 204.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      195.5       213.5         153         221]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.90847]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([195.5, 213.5, 153.0, 221.0], 0.9084728956222534, -1)]\n",
            "\n",
            "0: 480x640 1 person, 1 chair, 212.4ms\n",
            "Speed: 3.5ms preprocess, 212.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        194       213.5         154         221]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.89878]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([194.0, 213.5, 154.0, 221.0], 0.8987780213356018, -1)]\n",
            "\n",
            "0: 480x640 1 person, 1 chair, 206.7ms\n",
            "Speed: 3.5ms preprocess, 206.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        195       213.5         158         221]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.88533]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([195.0, 213.5, 158.0, 221.0], 0.8853324055671692, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 chair, 1 book, 216.2ms\n",
            "Speed: 8.9ms preprocess, 216.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        193         214         160         220]\n",
            " [        156       211.5          86         217]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.71582     0.25608]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([193.0, 214.0, 160.0, 220.0], 0.7158190011978149, -1), ([156.0, 211.5, 86.0, 217.0], 0.25607502460479736, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 chair, 1 book, 215.3ms\n",
            "Speed: 10.4ms preprocess, 215.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      216.5       215.5         115         219]\n",
            " [      193.5       213.5         163         221]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.57704     0.47042]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([216.5, 215.5, 115.0, 219.0], 0.5770360827445984, -1), ([193.5, 213.5, 163.0, 221.0], 0.4704166054725647, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 1 chair, 241.8ms\n",
            "Speed: 3.6ms preprocess, 241.8ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      213.5       213.5         113         219]\n",
            " [      188.5       212.5         163         219]\n",
            " [      151.5         212          93         218]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.61139     0.34114     0.28572]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([213.5, 213.5, 113.0, 219.0], 0.6113929748535156, -1), ([188.5, 212.5, 163.0, 219.0], 0.34113800525665283, -1), ([151.5, 212.0, 93.0, 218.0], 0.2857229709625244, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 chair, 1 book, 242.8ms\n",
            "Speed: 3.7ms preprocess, 242.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      213.5       212.5         123         221]\n",
            " [        152       210.5          90         217]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.68923     0.52012]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([213.5, 212.5, 123.0, 221.0], 0.6892337203025818, -1), ([152.0, 210.5, 90.0, 217.0], 0.5201175212860107, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 231.9ms\n",
            "Speed: 3.3ms preprocess, 231.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        216         211         122         224]\n",
            " [      146.5       209.5          79         217]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.71488     0.60074]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([216.0, 211.0, 122.0, 224.0], 0.7148820757865906, -1), ([146.5, 209.5, 79.0, 217.0], 0.6007373332977295, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 208.9ms\n",
            "Speed: 3.7ms preprocess, 208.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      219.5       209.5         115         225]\n",
            " [        147       208.5          80         219]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.68687     0.44115]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([219.5, 209.5, 115.0, 225.0], 0.6868740916252136, -1), ([147.0, 208.5, 80.0, 219.0], 0.4411473274230957, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 1 car, 1 motorcycle, 233.5ms\n",
            "Speed: 4.1ms preprocess, 233.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      212.5         210          99         226]\n",
            " [      145.5         208          81         218]\n",
            " [      258.5       252.5          43         129]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.81454     0.51219     0.29047]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([212.5, 210.0, 99.0, 226.0], 0.8145444393157959, -1), ([145.5, 208.0, 81.0, 218.0], 0.5121946930885315, -1), ([258.5, 252.5, 43.0, 129.0], 0.29047104716300964, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 motorcycle, 1 book, 237.4ms\n",
            "Speed: 3.6ms preprocess, 237.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      212.5       207.5         101         227]\n",
            " [      143.5         208          79         220]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.84192     0.40738]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([212.5, 207.5, 101.0, 227.0], 0.8419245481491089, -1), ([143.5, 208.0, 79.0, 220.0], 0.4073842763900757, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 motorcycle, 1 book, 234.2ms\n",
            "Speed: 3.6ms preprocess, 234.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        214       207.5         100         227]\n",
            " [        147         207          80         222]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.78625     0.32337]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([214.0, 207.5, 100.0, 227.0], 0.7862510681152344, -1), ([147.0, 207.0, 80.0, 222.0], 0.323373943567276, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 motorcycle, 1 book, 231.5ms\n",
            "Speed: 3.4ms preprocess, 231.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        214         207         100         230]\n",
            " [      141.5       199.5          89         207]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.82283     0.41079]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([214.0, 207.0, 100.0, 230.0], 0.8228275179862976, -1), ([141.5, 199.5, 89.0, 207.0], 0.4107940196990967, -1)]\n",
            "\n",
            "0: 480x640 1 person, 1 book, 1 teddy bear, 237.1ms\n",
            "Speed: 3.6ms preprocess, 237.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        213       204.5         100         233]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.73734]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([213.0, 204.5, 100.0, 233.0], 0.7373403906822205, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 motorcycle, 1 book, 211.7ms\n",
            "Speed: 4.0ms preprocess, 211.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      215.5       206.5          99         231]\n",
            " [      154.5         207         121         224]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.71147     0.27334]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([215.5, 206.5, 99.0, 231.0], 0.711468517780304, -1), ([154.5, 207.0, 121.0, 224.0], 0.27333977818489075, -1)]\n",
            "\n",
            "0: 480x640 1 person, 225.1ms\n",
            "Speed: 15.6ms preprocess, 225.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      190.5       203.5         137         235]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.47188]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([190.5, 203.5, 137.0, 235.0], 0.4718792736530304, -1)]\n",
            "\n",
            "0: 480x640 1 person, 1 book, 205.1ms\n",
            "Speed: 8.4ms preprocess, 205.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      222.5         204          89         234]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [     0.4107]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([222.5, 204.0, 89.0, 234.0], 0.4107045829296112, -1)]\n",
            "\n",
            "0: 480x640 1 person, 2 books, 222.0ms\n",
            "Speed: 5.4ms preprocess, 222.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      237.5       202.5         123         235]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.45809]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([237.5, 202.5, 123.0, 235.0], 0.45808908343315125, -1)]\n",
            "\n",
            "0: 480x640 1 person, 1 book, 202.3ms\n",
            "Speed: 8.6ms preprocess, 202.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        259       213.5          96         219]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.58185]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([259.0, 213.5, 96.0, 219.0], 0.5818514823913574, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 book, 205.0ms\n",
            "Speed: 3.9ms preprocess, 205.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        257         213         102         220]\n",
            " [        161         192         142         258]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.76939     0.34065]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([257.0, 213.0, 102.0, 220.0], 0.769385039806366, -1), ([161.0, 192.0, 142.0, 258.0], 0.34065118432044983, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 book, 241.0ms\n",
            "Speed: 3.8ms preprocess, 241.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      255.5         216         103         214]\n",
            " [        151       179.5         144         285]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.7932     0.59318]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([255.5, 216.0, 103.0, 214.0], 0.7931989431381226, -1), ([151.0, 179.5, 144.0, 285.0], 0.5931830406188965, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 book, 198.7ms\n",
            "Speed: 3.3ms preprocess, 198.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        255       217.5         106         211]\n",
            " [      159.5         182         159         280]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.79914     0.46545]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([255.0, 217.5, 106.0, 211.0], 0.7991420030593872, -1), ([159.5, 182.0, 159.0, 280.0], 0.4654536545276642, -1)]\n",
            "\n",
            "0: 480x640 1 person, 1 chair, 2 books, 223.5ms\n",
            "Speed: 3.5ms preprocess, 223.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        244       218.5         128         207]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.65059]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([244.0, 218.5, 128.0, 207.0], 0.6505944132804871, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 1 book, 225.0ms\n",
            "Speed: 3.7ms preprocess, 225.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        156       177.5         146         283]\n",
            " [        220       214.5         188         203]\n",
            " [        242       217.5         134         209]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [     0.5285     0.46295     0.33597]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([156.0, 177.5, 146.0, 283.0], 0.5285008549690247, -1), ([220.0, 214.5, 188.0, 203.0], 0.46295079588890076, -1), ([242.0, 217.5, 134.0, 209.0], 0.3359723389148712, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 1 banana, 205.4ms\n",
            "Speed: 3.7ms preprocess, 205.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      155.5         179         145         286]\n",
            " [        222       216.5         178         205]\n",
            " [        260         218         100         208]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.82492     0.61479     0.43958]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([155.5, 179.0, 145.0, 286.0], 0.8249216675758362, -1), ([222.0, 216.5, 178.0, 205.0], 0.6147884130477905, -1), ([260.0, 218.0, 100.0, 208.0], 0.439578652381897, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 banana, 213.8ms\n",
            "Speed: 12.5ms preprocess, 213.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        169       179.5         172         287]\n",
            " [        262       219.5          96         207]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88556      0.8238]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([169.0, 179.5, 172.0, 287.0], 0.8855558037757874, -1), ([262.0, 219.5, 96.0, 207.0], 0.8237955570220947, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 banana, 1 chair, 243.1ms\n",
            "Speed: 3.4ms preprocess, 243.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      170.5       179.5         173         285]\n",
            " [      260.5         219          99         206]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89885     0.83902]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([170.5, 179.5, 173.0, 285.0], 0.898848295211792, -1), ([260.5, 219.0, 99.0, 206.0], 0.8390173316001892, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 chair, 321.5ms\n",
            "Speed: 3.1ms preprocess, 321.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        170         179         174         284]\n",
            " [      259.5         220         101         204]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88909      0.8567]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([170.0, 179.0, 174.0, 284.0], 0.889085590839386, -1), ([259.5, 220.0, 101.0, 204.0], 0.8566997051239014, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 324.3ms\n",
            "Speed: 15.6ms preprocess, 324.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      172.5         178         181         288]\n",
            " [      259.5         221         101         202]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91663     0.85937]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([172.5, 178.0, 181.0, 288.0], 0.9166269898414612, -1), ([259.5, 221.0, 101.0, 202.0], 0.859366238117218, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 1 dining table, 302.5ms\n",
            "Speed: 8.4ms preprocess, 302.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      172.5         179         183         288]\n",
            " [        259       222.5         102         199]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89283     0.87557]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([172.5, 179.0, 183.0, 288.0], 0.892827033996582, -1), ([259.0, 222.5, 102.0, 199.0], 0.8755675554275513, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 321.2ms\n",
            "Speed: 15.4ms preprocess, 321.2ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      171.5         183         183         280]\n",
            " [        259       223.5         108         195]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90696     0.84966]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([171.5, 183.0, 183.0, 280.0], 0.9069556593894958, -1), ([259.0, 223.5, 108.0, 195.0], 0.849656343460083, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 323.7ms\n",
            "Speed: 3.4ms preprocess, 323.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      173.5         186         187         270]\n",
            " [      257.5         224         111         194]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87736     0.86375]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([173.5, 186.0, 187.0, 270.0], 0.8773590326309204, -1), ([257.5, 224.0, 111.0, 194.0], 0.8637490272521973, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 309.5ms\n",
            "Speed: 7.1ms preprocess, 309.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        173       191.5         188         263]\n",
            " [        256         225         110         194]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89814     0.89129]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([173.0, 191.5, 188.0, 263.0], 0.8981429934501648, -1), ([256.0, 225.0, 110.0, 194.0], 0.8912929892539978, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 298.4ms\n",
            "Speed: 3.7ms preprocess, 298.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        173       196.5         186         249]\n",
            " [        248         224         122         196]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89217     0.85658]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([173.0, 196.5, 186.0, 249.0], 0.8921706676483154, -1), ([248.0, 224.0, 122.0, 196.0], 0.856583833694458, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 316.9ms\n",
            "Speed: 5.9ms preprocess, 316.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        247       224.5         124         195]\n",
            " [      172.5         201         183         242]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85214     0.80393]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([247.0, 224.5, 124.0, 195.0], 0.8521436452865601, -1), ([172.5, 201.0, 183.0, 242.0], 0.8039329051971436, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 339.5ms\n",
            "Speed: 10.2ms preprocess, 339.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      249.5       225.5         119         195]\n",
            " [        172         213         180         220]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.84866     0.84373]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([249.5, 225.5, 119.0, 195.0], 0.8486571907997131, -1), ([172.0, 213.0, 180.0, 220.0], 0.8437303304672241, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 cup, 3 chairs, 342.4ms\n",
            "Speed: 5.5ms preprocess, 342.4ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        247       224.5         128         195]\n",
            " [      167.5       215.5         169         213]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.83347      0.8165]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([247.0, 224.5, 128.0, 195.0], 0.8334715962409973, -1), ([167.5, 215.5, 169.0, 213.0], 0.8164975643157959, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 dog, 1 cup, 3 chairs, 1 refrigerator, 340.3ms\n",
            "Speed: 4.8ms preprocess, 340.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        233         225         158         196]\n",
            " [      163.5         223         157         200]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.8188      0.3321]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([233.0, 225.0, 158.0, 196.0], 0.8188045620918274, -1), ([163.5, 223.0, 157.0, 200.0], 0.3320969343185425, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 280.5ms\n",
            "Speed: 4.3ms preprocess, 280.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      252.5         225         117         194]\n",
            " [      163.5         230         153         184]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85243     0.63498]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([252.5, 225.0, 117.0, 194.0], 0.8524332642555237, -1), ([163.5, 230.0, 153.0, 184.0], 0.6349819898605347, -1)]\n",
            "\n",
            "0: 480x640 1 person, 1 dog, 4 chairs, 1 refrigerator, 238.9ms\n",
            "Speed: 3.4ms preprocess, 238.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      235.5         225         149         194]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.81763]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([235.5, 225.0, 149.0, 194.0], 0.8176279067993164, -1)]\n",
            "\n",
            "0: 480x640 1 person, 1 dog, 4 chairs, 1 refrigerator, 197.3ms\n",
            "Speed: 4.4ms preprocess, 197.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        237       224.5         144         193]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.80476]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([237.0, 224.5, 144.0, 193.0], 0.8047596216201782, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 1 refrigerator, 202.3ms\n",
            "Speed: 3.7ms preprocess, 202.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      249.5       224.5         119         193]\n",
            " [        162         243         152         162]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.81847     0.66012]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([249.5, 224.5, 119.0, 193.0], 0.8184676170349121, -1), ([162.0, 243.0, 152.0, 162.0], 0.6601179838180542, -1)]\n",
            "\n",
            "0: 480x640 1 person, 1 dog, 4 chairs, 1 refrigerator, 225.7ms\n",
            "Speed: 3.8ms preprocess, 225.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        250         225         118         194]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.82957]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([250.0, 225.0, 118.0, 194.0], 0.8295668959617615, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 dog, 1 cup, 4 chairs, 1 refrigerator, 212.0ms\n",
            "Speed: 6.2ms preprocess, 212.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        241         225         136         194]\n",
            " [        157         248         150         150]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.82451     0.43617]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([241.0, 225.0, 136.0, 194.0], 0.8245078325271606, -1), ([157.0, 248.0, 150.0, 150.0], 0.4361657202243805, -1)]\n",
            "\n",
            "0: 480x640 1 person, 1 dog, 4 chairs, 1 refrigerator, 234.3ms\n",
            "Speed: 7.5ms preprocess, 234.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        248       225.5         124         193]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.85608]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([248.0, 225.5, 124.0, 193.0], 0.8560831546783447, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 1 refrigerator, 213.9ms\n",
            "Speed: 3.7ms preprocess, 213.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        252       225.5         122         193]\n",
            " [      151.5         252         143         142]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86651      0.3323]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([252.0, 225.5, 122.0, 193.0], 0.8665142059326172, -1), ([151.5, 252.0, 143.0, 142.0], 0.3323010802268982, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 cup, 5 chairs, 1 refrigerator, 219.8ms\n",
            "Speed: 4.4ms preprocess, 219.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        260       224.5         114         195]\n",
            " [        150         251         138         142]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.81858     0.49809]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([260.0, 224.5, 114.0, 195.0], 0.8185818195343018, -1), ([150.0, 251.0, 138.0, 142.0], 0.4980893135070801, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 cup, 4 chairs, 1 refrigerator, 220.5ms\n",
            "Speed: 3.6ms preprocess, 220.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        262       224.5         116         195]\n",
            " [      148.5       249.5         141         147]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85615      0.6856]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([262.0, 224.5, 116.0, 195.0], 0.8561539053916931, -1), ([148.5, 249.5, 141.0, 147.0], 0.6855995059013367, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 cup, 5 chairs, 1 refrigerator, 227.3ms\n",
            "Speed: 3.7ms preprocess, 227.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        261         225         122         194]\n",
            " [        146       247.5         138         151]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.8695      0.3873]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([261.0, 225.0, 122.0, 194.0], 0.8695003390312195, -1), ([146.0, 247.5, 138.0, 151.0], 0.38730406761169434, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 cup, 4 chairs, 1 refrigerator, 233.3ms\n",
            "Speed: 3.4ms preprocess, 233.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        264         225         130         194]\n",
            " [        143         244         140         156]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90847      0.4947]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([264.0, 225.0, 130.0, 194.0], 0.9084701538085938, -1), ([143.0, 244.0, 140.0, 156.0], 0.49469730257987976, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 dog, 1 cup, 4 chairs, 1 refrigerator, 253.0ms\n",
            "Speed: 5.9ms preprocess, 253.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        264         225         126         194]\n",
            " [      140.5       241.5         135         161]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89719     0.37258]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([264.0, 225.0, 126.0, 194.0], 0.8971869349479675, -1), ([140.5, 241.5, 135.0, 161.0], 0.3725751042366028, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 355.9ms\n",
            "Speed: 3.6ms preprocess, 355.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      263.5         225         123         196]\n",
            " [      135.5       239.5         137         169]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90327     0.47541]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([263.5, 225.0, 123.0, 196.0], 0.9032673835754395, -1), ([135.5, 239.5, 137.0, 169.0], 0.47540754079818726, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 1 refrigerator, 314.6ms\n",
            "Speed: 4.7ms preprocess, 314.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      264.5         224         125         198]\n",
            " [        132       235.5         144         175]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90034     0.57202]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([264.5, 224.0, 125.0, 198.0], 0.9003443121910095, -1), ([132.0, 235.5, 144.0, 175.0], 0.572021484375, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 cake, 4 chairs, 1 refrigerator, 327.1ms\n",
            "Speed: 4.9ms preprocess, 327.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        265       222.5         124         201]\n",
            " [      134.5       232.5         133         181]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [      0.879     0.55165]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([265.0, 222.5, 124.0, 201.0], 0.8789987564086914, -1), ([134.5, 232.5, 133.0, 181.0], 0.551654040813446, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 335.1ms\n",
            "Speed: 8.3ms preprocess, 335.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      264.5         221         119         204]\n",
            " [      133.5         231         135         184]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87184     0.67312]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([264.5, 221.0, 119.0, 204.0], 0.8718380928039551, -1), ([133.5, 231.0, 135.0, 184.0], 0.673119068145752, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 cake, 4 chairs, 334.9ms\n",
            "Speed: 3.7ms preprocess, 334.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      267.5         220         123         206]\n",
            " [      133.5         230         127         188]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88649     0.83172]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([267.5, 220.0, 123.0, 206.0], 0.8864911794662476, -1), ([133.5, 230.0, 127.0, 188.0], 0.8317239284515381, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 cup, 3 chairs, 1 tv, 309.6ms\n",
            "Speed: 3.7ms preprocess, 309.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        269         219         122         208]\n",
            " [      131.5         229         131         188]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89472     0.81453]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([269.0, 219.0, 122.0, 208.0], 0.894717276096344, -1), ([131.5, 229.0, 131.0, 188.0], 0.8145343065261841, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 cup, 4 chairs, 336.7ms\n",
            "Speed: 11.4ms preprocess, 336.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      269.5       218.5         121         211]\n",
            " [      136.5       228.5         129         189]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89426     0.77929]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([269.5, 218.5, 121.0, 211.0], 0.894261360168457, -1), ([136.5, 228.5, 129.0, 189.0], 0.7792853713035583, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 cup, 4 chairs, 332.1ms\n",
            "Speed: 7.8ms preprocess, 332.1ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        270       217.5         120         211]\n",
            " [        143       228.5         132         189]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90418      0.7804]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([270.0, 217.5, 120.0, 211.0], 0.9041789770126343, -1), ([143.0, 228.5, 132.0, 189.0], 0.7803989052772522, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 cup, 4 chairs, 1 refrigerator, 342.8ms\n",
            "Speed: 8.5ms preprocess, 342.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      270.5         218         119         210]\n",
            " [      142.5         229         133         190]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91649      0.7624]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([270.5, 218.0, 119.0, 210.0], 0.91648930311203, -1), ([142.5, 229.0, 133.0, 190.0], 0.7624032497406006, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 cup, 4 chairs, 1 refrigerator, 342.2ms\n",
            "Speed: 7.1ms preprocess, 342.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        271       217.5         120         211]\n",
            " [      144.5         229         141         188]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91715     0.65438]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([271.0, 217.5, 120.0, 211.0], 0.917149007320404, -1), ([144.5, 229.0, 141.0, 188.0], 0.6543822884559631, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 305.2ms\n",
            "Speed: 9.1ms preprocess, 305.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      271.5         218         119         210]\n",
            " [      139.5         230         151         186]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91449     0.64172]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([271.5, 218.0, 119.0, 210.0], 0.9144865274429321, -1), ([139.5, 230.0, 151.0, 186.0], 0.6417247653007507, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 318.1ms\n",
            "Speed: 4.3ms preprocess, 318.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        272       218.5         120         209]\n",
            " [        138       231.5         160         185]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90099     0.65166]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([272.0, 218.5, 120.0, 209.0], 0.9009890556335449, -1), ([138.0, 231.5, 160.0, 185.0], 0.6516566872596741, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 4 chairs, 305.1ms\n",
            "Speed: 3.5ms preprocess, 305.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      271.5       218.5         123         209]\n",
            " [        152         233         134         184]\n",
            " [        192       274.5         104          97]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [     0.8936     0.64607     0.35232]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([271.5, 218.5, 123.0, 209.0], 0.8936011791229248, -1), ([152.0, 233.0, 134.0, 184.0], 0.6460676789283752, -1), ([192.0, 274.5, 104.0, 97.0], 0.3523174524307251, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 341.3ms\n",
            "Speed: 7.2ms preprocess, 341.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      273.5       218.5         119         209]\n",
            " [        165       233.5         156         181]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87718     0.57071]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([273.5, 218.5, 119.0, 209.0], 0.8771828413009644, -1), ([165.0, 233.5, 156.0, 181.0], 0.5707091093063354, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 324.4ms\n",
            "Speed: 3.6ms preprocess, 324.4ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      281.5       218.5         107         209]\n",
            " [      167.5         234         157         180]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88749     0.54303]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([281.5, 218.5, 107.0, 209.0], 0.8874941468238831, -1), ([167.5, 234.0, 157.0, 180.0], 0.5430262088775635, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 344.8ms\n",
            "Speed: 3.5ms preprocess, 344.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        278         219         114         210]\n",
            " [        169       235.5         160         177]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87891      0.7978]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([278.0, 219.0, 114.0, 210.0], 0.8789145946502686, -1), ([169.0, 235.5, 160.0, 177.0], 0.7978024482727051, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 4 chairs, 313.6ms\n",
            "Speed: 4.8ms preprocess, 313.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        278         218         116         210]\n",
            " [        168       236.5         158         175]\n",
            " [        193         236         112         174]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.88155      0.6042     0.27187]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([278.0, 218.0, 116.0, 210.0], 0.8815501928329468, -1), ([168.0, 236.5, 158.0, 175.0], 0.6042006611824036, -1), ([193.0, 236.0, 112.0, 174.0], 0.2718675136566162, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 337.7ms\n",
            "Speed: 8.4ms preprocess, 337.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        276         218         124         210]\n",
            " [      168.5         237         159         174]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87542     0.66667]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([276.0, 218.0, 124.0, 210.0], 0.8754192590713501, -1), ([168.5, 237.0, 159.0, 174.0], 0.6666661500930786, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 4 chairs, 325.4ms\n",
            "Speed: 5.1ms preprocess, 325.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        278       218.5         122         211]\n",
            " [      140.5         237         203         174]\n",
            " [      199.5         237          95         174]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.86985     0.49939     0.27775]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([278.0, 218.5, 122.0, 211.0], 0.869847297668457, -1), ([140.5, 237.0, 203.0, 174.0], 0.49938836693763733, -1), ([199.5, 237.0, 95.0, 174.0], 0.27775460481643677, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 337.5ms\n",
            "Speed: 10.1ms preprocess, 337.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      282.5         219         115         212]\n",
            " [      142.5         237         205         174]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87078     0.71984]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([282.5, 219.0, 115.0, 212.0], 0.870782732963562, -1), ([142.5, 237.0, 205.0, 174.0], 0.7198412418365479, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 341.0ms\n",
            "Speed: 3.5ms preprocess, 341.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        284       218.5         116         211]\n",
            " [      144.5         236         209         174]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88193     0.66768]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([284.0, 218.5, 116.0, 211.0], 0.8819319605827332, -1), ([144.5, 236.0, 209.0, 174.0], 0.6676766276359558, -1)]\n",
            "Processing frame 1900\n",
            "\n",
            "0: 480x640 3 persons, 3 chairs, 346.0ms\n",
            "Speed: 8.7ms preprocess, 346.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      283.5         218         119         210]\n",
            " [      132.5         237         195         176]\n",
            " [        220         243          94         164]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.87057     0.61234     0.44536]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([283.5, 218.0, 119.0, 210.0], 0.8705739974975586, -1), ([132.5, 237.0, 195.0, 176.0], 0.6123438477516174, -1), ([220.0, 243.0, 94.0, 164.0], 0.44535520672798157, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 206.6ms\n",
            "Speed: 4.3ms preprocess, 206.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        283         218         120         210]\n",
            " [      179.5         236         201         176]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85306     0.72162]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([283.0, 218.0, 120.0, 210.0], 0.8530550599098206, -1), ([179.5, 236.0, 201.0, 176.0], 0.7216242551803589, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 214.6ms\n",
            "Speed: 4.3ms preprocess, 214.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        285       217.5         118         209]\n",
            " [      181.5       235.5         207         177]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.85733     0.83561]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([285.0, 217.5, 118.0, 209.0], 0.8573285937309265, -1), ([181.5, 235.5, 207.0, 177.0], 0.8356134295463562, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 230.5ms\n",
            "Speed: 5.0ms preprocess, 230.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      285.5       216.5         121         211]\n",
            " [      181.5         234         201         180]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87567     0.86282]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([285.5, 216.5, 121.0, 211.0], 0.8756721019744873, -1), ([181.5, 234.0, 201.0, 180.0], 0.8628189563751221, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 214.1ms\n",
            "Speed: 4.5ms preprocess, 214.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      288.5       215.5         125         213]\n",
            " [        182         233         202         182]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.8695     0.86108]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([288.5, 215.5, 125.0, 213.0], 0.8695002794265747, -1), ([182.0, 233.0, 202.0, 182.0], 0.8610824346542358, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 230.8ms\n",
            "Speed: 13.2ms preprocess, 230.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        187         231         210         184]\n",
            " [        284       214.5         140         215]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88733     0.86409]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([187.0, 231.0, 210.0, 184.0], 0.8873284459114075, -1), ([284.0, 214.5, 140.0, 215.0], 0.8640905022621155, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 229.2ms\n",
            "Speed: 3.6ms preprocess, 229.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        188         230         212         186]\n",
            " [        291         214         142         216]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91772     0.88146]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([188.0, 230.0, 212.0, 186.0], 0.9177203178405762, -1), ([291.0, 214.0, 142.0, 216.0], 0.8814625144004822, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 1 remote, 195.4ms\n",
            "Speed: 13.1ms preprocess, 195.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      185.5       229.5         207         189]\n",
            " [      291.5       213.5         145         217]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90581     0.88435]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([185.5, 229.5, 207.0, 189.0], 0.905810534954071, -1), ([291.5, 213.5, 145.0, 217.0], 0.8843482136726379, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 1 remote, 239.7ms\n",
            "Speed: 8.4ms preprocess, 239.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      292.5       213.5         145         217]\n",
            " [        182         229         202         190]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89351     0.89322]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([292.5, 213.5, 145.0, 217.0], 0.8935105204582214, -1), ([182.0, 229.0, 202.0, 190.0], 0.8932244777679443, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 cup, 3 chairs, 1 cell phone, 236.5ms\n",
            "Speed: 5.5ms preprocess, 236.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        292       213.5         144         217]\n",
            " [        179       227.5         196         193]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.8818     0.87857]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([292.0, 213.5, 144.0, 217.0], 0.8817957043647766, -1), ([179.0, 227.5, 196.0, 193.0], 0.8785655498504639, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 cup, 3 chairs, 229.0ms\n",
            "Speed: 9.1ms preprocess, 229.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        293         213         144         218]\n",
            " [        176       226.5         190         193]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88124     0.87091]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([293.0, 213.0, 144.0, 218.0], 0.88124018907547, -1), ([176.0, 226.5, 190.0, 193.0], 0.8709074258804321, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 1 cell phone, 230.3ms\n",
            "Speed: 3.5ms preprocess, 230.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        175         226         188         194]\n",
            " [      296.5         212         137         218]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87565     0.87546]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([175.0, 226.0, 188.0, 194.0], 0.87564617395401, -1), ([296.5, 212.0, 137.0, 218.0], 0.8754638433456421, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 1 cell phone, 239.3ms\n",
            "Speed: 3.7ms preprocess, 239.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        291       212.5         144         219]\n",
            " [        173       225.5         184         195]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88674     0.76736]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([291.0, 212.5, 144.0, 219.0], 0.8867350816726685, -1), ([173.0, 225.5, 184.0, 195.0], 0.7673643231391907, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 1 cell phone, 224.8ms\n",
            "Speed: 3.7ms preprocess, 224.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      290.5       211.5         133         219]\n",
            " [        171         225         180         196]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88611     0.84998]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([290.5, 211.5, 133.0, 219.0], 0.8861125707626343, -1), ([171.0, 225.0, 180.0, 196.0], 0.849979043006897, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 235.4ms\n",
            "Speed: 3.5ms preprocess, 235.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      292.5       211.5         123         221]\n",
            " [      170.5       224.5         179         195]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88724     0.87316]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([292.5, 211.5, 123.0, 221.0], 0.8872438669204712, -1), ([170.5, 224.5, 179.0, 195.0], 0.8731634616851807, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 cake, 3 chairs, 238.1ms\n",
            "Speed: 5.6ms preprocess, 238.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      289.5         212         123         220]\n",
            " [      171.5       224.5         181         197]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88433     0.88178]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([289.5, 212.0, 123.0, 220.0], 0.8843316435813904, -1), ([171.5, 224.5, 181.0, 197.0], 0.8817753791809082, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 cake, 4 chairs, 239.9ms\n",
            "Speed: 4.2ms preprocess, 239.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        174       223.5         186         197]\n",
            " [      288.5         212         121         220]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88488     0.87925]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([174.0, 223.5, 186.0, 197.0], 0.8848837018013, -1), ([288.5, 212.0, 121.0, 220.0], 0.8792470693588257, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 cake, 4 chairs, 1 cell phone, 216.0ms\n",
            "Speed: 3.5ms preprocess, 216.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      173.5         224         185         198]\n",
            " [      285.5         212         119         222]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88091     0.87817]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([173.5, 224.0, 185.0, 198.0], 0.8809149861335754, -1), ([285.5, 212.0, 119.0, 222.0], 0.8781733512878418, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 cake, 3 chairs, 221.3ms\n",
            "Speed: 6.2ms preprocess, 221.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        283         212         118         220]\n",
            " [      169.5         223         181         198]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88554     0.85534]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([283.0, 212.0, 118.0, 220.0], 0.8855393528938293, -1), ([169.5, 223.0, 181.0, 198.0], 0.8553403615951538, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 cake, 3 chairs, 224.2ms\n",
            "Speed: 8.4ms preprocess, 224.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        282       212.5         118         221]\n",
            " [        171         223         180         198]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88879     0.86858]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([282.0, 212.5, 118.0, 221.0], 0.8887869715690613, -1), ([171.0, 223.0, 180.0, 198.0], 0.8685819506645203, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 cake, 3 chairs, 216.1ms\n",
            "Speed: 3.5ms preprocess, 216.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        281       212.5         120         221]\n",
            " [      171.5         223         179         198]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89017     0.84603]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([281.0, 212.5, 120.0, 221.0], 0.8901721835136414, -1), ([171.5, 223.0, 179.0, 198.0], 0.8460314273834229, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 cake, 3 chairs, 227.2ms\n",
            "Speed: 7.0ms preprocess, 227.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      279.5       212.5         121         223]\n",
            " [        172       222.5         178         197]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88649     0.85027]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([279.5, 212.5, 121.0, 223.0], 0.8864879012107849, -1), ([172.0, 222.5, 178.0, 197.0], 0.8502730131149292, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 cake, 3 chairs, 222.6ms\n",
            "Speed: 14.6ms preprocess, 222.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      279.5       212.5         121         223]\n",
            " [      171.5       222.5         179         197]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88338     0.86724]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([279.5, 212.5, 121.0, 223.0], 0.8833793997764587, -1), ([171.5, 222.5, 179.0, 197.0], 0.8672369718551636, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 cake, 3 chairs, 250.7ms\n",
            "Speed: 3.7ms preprocess, 250.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      279.5       212.5         121         223]\n",
            " [        172         223         180         198]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87815      0.8507]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([279.5, 212.5, 121.0, 223.0], 0.8781495690345764, -1), ([172.0, 223.0, 180.0, 198.0], 0.8507000207901001, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 fire hydrant, 1 cake, 3 chairs, 237.6ms\n",
            "Speed: 19.0ms preprocess, 237.6ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      279.5       212.5         121         223]\n",
            " [      171.5         223         183         198]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88036     0.77569]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([279.5, 212.5, 121.0, 223.0], 0.8803642392158508, -1), ([171.5, 223.0, 183.0, 198.0], 0.7756931781768799, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 fire hydrant, 1 cake, 3 chairs, 226.8ms\n",
            "Speed: 6.3ms preprocess, 226.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      280.5         213         121         222]\n",
            " [        172       223.5         184         199]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88057     0.83497]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([280.5, 213.0, 121.0, 222.0], 0.8805660009384155, -1), ([172.0, 223.5, 184.0, 199.0], 0.8349699378013611, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 cake, 3 chairs, 230.2ms\n",
            "Speed: 10.1ms preprocess, 230.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      282.5         212         123         222]\n",
            " [        176       223.5         190         199]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86055     0.85579]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([282.5, 212.0, 123.0, 222.0], 0.8605525493621826, -1), ([176.0, 223.5, 190.0, 199.0], 0.855785608291626, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 238.2ms\n",
            "Speed: 6.8ms preprocess, 238.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      284.5         213         123         222]\n",
            " [        176       223.5         192         199]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87702     0.81554]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([284.5, 213.0, 123.0, 222.0], 0.8770223259925842, -1), ([176.0, 223.5, 192.0, 199.0], 0.8155360817909241, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 237.9ms\n",
            "Speed: 11.7ms preprocess, 237.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        286         213         124         224]\n",
            " [      175.5       223.5         193         199]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86616     0.80436]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([286.0, 213.0, 124.0, 224.0], 0.8661563992500305, -1), ([175.5, 223.5, 193.0, 199.0], 0.8043590188026428, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 320.1ms\n",
            "Speed: 3.6ms preprocess, 320.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      290.5         212         121         224]\n",
            " [      176.5       223.5         197         199]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86908     0.81789]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([290.5, 212.0, 121.0, 224.0], 0.8690784573554993, -1), ([176.5, 223.5, 197.0, 199.0], 0.8178926706314087, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 315.2ms\n",
            "Speed: 3.6ms preprocess, 315.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        295         212         122         224]\n",
            " [        180         223         200         200]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87575     0.80515]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([295.0, 212.0, 122.0, 224.0], 0.8757548928260803, -1), ([180.0, 223.0, 200.0, 200.0], 0.8051478862762451, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 303.5ms\n",
            "Speed: 5.2ms preprocess, 303.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      298.5       212.5         125         221]\n",
            " [      179.5         222         205         200]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88093     0.78455]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([298.5, 212.5, 125.0, 221.0], 0.8809345960617065, -1), ([179.5, 222.0, 205.0, 200.0], 0.7845534086227417, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 326.2ms\n",
            "Speed: 14.8ms preprocess, 326.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      299.5         212         127         224]\n",
            " [      181.5       221.5         207         201]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.8668     0.83213]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([299.5, 212.0, 127.0, 224.0], 0.866803765296936, -1), ([181.5, 221.5, 207.0, 201.0], 0.8321263790130615, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 bottle, 1 cake, 6 chairs, 317.6ms\n",
            "Speed: 16.0ms preprocess, 317.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        304         211         124         224]\n",
            " [        180         221         218         202]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89698     0.82238]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([304.0, 211.0, 124.0, 224.0], 0.8969752192497253, -1), ([180.0, 221.0, 218.0, 202.0], 0.8223799467086792, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 bottle, 4 chairs, 341.3ms\n",
            "Speed: 3.6ms preprocess, 341.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      305.5         211         123         224]\n",
            " [        181       221.5         226         203]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87015     0.84255]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([305.5, 211.0, 123.0, 224.0], 0.8701491951942444, -1), ([181.0, 221.5, 226.0, 203.0], 0.8425525426864624, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 bottle, 4 chairs, 313.7ms\n",
            "Speed: 3.6ms preprocess, 313.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        188         221         226         204]\n",
            " [      307.5         209         127         226]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.8359      0.8279]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([188.0, 221.0, 226.0, 204.0], 0.835895299911499, -1), ([307.5, 209.0, 127.0, 226.0], 0.8278964161872864, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 cake, 4 chairs, 329.2ms\n",
            "Speed: 3.7ms preprocess, 329.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        312         208         124         226]\n",
            " [        193         221         232         204]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.84012     0.78967]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([312.0, 208.0, 124.0, 226.0], 0.8401219844818115, -1), ([193.0, 221.0, 232.0, 204.0], 0.7896706461906433, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 knife, 1 cake, 3 chairs, 1 tv, 325.1ms\n",
            "Speed: 7.6ms preprocess, 325.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      314.5       208.5         125         227]\n",
            " [        197         221         238         206]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.86965     0.78516]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([314.5, 208.5, 125.0, 227.0], 0.8696500658988953, -1), ([197.0, 221.0, 238.0, 206.0], 0.785158634185791, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 343.9ms\n",
            "Speed: 7.9ms preprocess, 343.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        317       208.5         126         229]\n",
            " [      198.5       220.5         237         205]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88746     0.83445]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([317.0, 208.5, 126.0, 229.0], 0.8874630928039551, -1), ([198.5, 220.5, 237.0, 205.0], 0.8344494104385376, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 325.1ms\n",
            "Speed: 10.2ms preprocess, 325.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        320         208         128         230]\n",
            " [        195         219         234         206]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.8845     0.81887]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([320.0, 208.0, 128.0, 230.0], 0.8844988346099854, -1), ([195.0, 219.0, 234.0, 206.0], 0.8188723921775818, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 chair, 202.6ms\n",
            "Speed: 9.6ms preprocess, 202.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        322       208.5         130         231]\n",
            " [      193.5       218.5         227         207]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.8968     0.81304]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([322.0, 208.5, 130.0, 231.0], 0.8967950344085693, -1), ([193.5, 218.5, 227.0, 207.0], 0.8130391836166382, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 cake, 3 chairs, 238.3ms\n",
            "Speed: 5.8ms preprocess, 238.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      322.5         208         129         232]\n",
            " [      191.5         219         223         208]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90499     0.81876]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([322.5, 208.0, 129.0, 232.0], 0.904987633228302, -1), ([191.5, 219.0, 223.0, 208.0], 0.818763017654419, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 225.6ms\n",
            "Speed: 3.5ms preprocess, 225.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      322.5         208         129         232]\n",
            " [      193.5       218.5         221         209]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90726     0.86582]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([322.5, 208.0, 129.0, 232.0], 0.907257080078125, -1), ([193.5, 218.5, 221.0, 209.0], 0.8658165335655212, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 1 tv, 229.9ms\n",
            "Speed: 5.9ms preprocess, 229.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        323       207.5         130         231]\n",
            " [        195       218.5         228         209]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90274     0.83802]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([323.0, 207.5, 130.0, 231.0], 0.9027419090270996, -1), ([195.0, 218.5, 228.0, 209.0], 0.8380208611488342, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 209.4ms\n",
            "Speed: 3.5ms preprocess, 209.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        323       207.5         130         231]\n",
            " [        199       217.5         232         211]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90159     0.89961]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([323.0, 207.5, 130.0, 231.0], 0.9015941023826599, -1), ([199.0, 217.5, 232.0, 211.0], 0.8996149301528931, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 cake, 4 chairs, 229.5ms\n",
            "Speed: 3.3ms preprocess, 229.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        200       217.5         234         211]\n",
            " [      323.5         207         133         232]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88676     0.88554]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([200.0, 217.5, 234.0, 211.0], 0.8867560029029846, -1), ([323.5, 207.0, 133.0, 232.0], 0.8855372667312622, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 4 chairs, 1 tv, 237.0ms\n",
            "Speed: 9.6ms preprocess, 237.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        321       207.5         132         233]\n",
            " [        198       217.5         230         211]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88375     0.87441]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([321.0, 207.5, 132.0, 233.0], 0.8837528824806213, -1), ([198.0, 217.5, 230.0, 211.0], 0.8744062781333923, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 3 chairs, 224.9ms\n",
            "Speed: 9.8ms preprocess, 224.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        320         207         130         234]\n",
            " [        196       217.5         224         211]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88446     0.84965]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([320.0, 207.0, 130.0, 234.0], 0.8844584226608276, -1), ([196.0, 217.5, 224.0, 211.0], 0.8496516346931458, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 chair, 253.8ms\n",
            "Speed: 19.6ms preprocess, 253.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        320       206.5         132         235]\n",
            " [      189.5         217         219         210]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88424     0.76033]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([320.0, 206.5, 132.0, 235.0], 0.8842399716377258, -1), ([189.5, 217.0, 219.0, 210.0], 0.7603254914283752, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 230.8ms\n",
            "Speed: 3.9ms preprocess, 230.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      321.5       206.5         135         237]\n",
            " [      189.5       218.5         215         209]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88457     0.75146]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([321.5, 206.5, 135.0, 237.0], 0.8845669031143188, -1), ([189.5, 218.5, 215.0, 209.0], 0.7514572739601135, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 211.1ms\n",
            "Speed: 3.9ms preprocess, 211.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        321       205.5         134         237]\n",
            " [        190       218.5         212         209]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.8843      0.6675]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([321.0, 205.5, 134.0, 237.0], 0.8842968344688416, -1), ([190.0, 218.5, 212.0, 209.0], 0.6674955487251282, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 247.9ms\n",
            "Speed: 3.8ms preprocess, 247.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      320.5         205         133         238]\n",
            " [        162         218         270         208]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88648     0.69851]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([320.5, 205.0, 133.0, 238.0], 0.8864825367927551, -1), ([162.0, 218.0, 270.0, 208.0], 0.6985113620758057, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 214.9ms\n",
            "Speed: 6.2ms preprocess, 214.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        321       203.5         134         239]\n",
            " [        192         217         218         208]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88409     0.75648]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([321.0, 203.5, 134.0, 239.0], 0.8840860724449158, -1), ([192.0, 217.0, 218.0, 208.0], 0.756479024887085, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 cake, 2 chairs, 222.6ms\n",
            "Speed: 4.0ms preprocess, 222.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      321.5         203         133         240]\n",
            " [      193.5         216         217         208]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.88096     0.80085]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([321.5, 203.0, 133.0, 240.0], 0.8809563517570496, -1), ([193.5, 216.0, 217.0, 208.0], 0.8008488416671753, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 cake, 2 chairs, 240.8ms\n",
            "Speed: 9.7ms preprocess, 240.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      322.5       202.5         135         241]\n",
            " [      193.5       216.5         219         209]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.91186     0.82711]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([322.5, 202.5, 135.0, 241.0], 0.9118630290031433, -1), ([193.5, 216.5, 219.0, 209.0], 0.8271117806434631, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 2 chairs, 231.9ms\n",
            "Speed: 3.5ms preprocess, 231.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        325       201.5         138         241]\n",
            " [        195         216         220         210]\n",
            " [        225         183          86         142]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.90391     0.78938     0.35141]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([325.0, 201.5, 138.0, 241.0], 0.9039052724838257, -1), ([195.0, 216.0, 220.0, 210.0], 0.7893827557563782, -1), ([225.0, 183.0, 86.0, 142.0], 0.35141050815582275, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 chair, 237.4ms\n",
            "Speed: 3.5ms preprocess, 237.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        328         202         140         242]\n",
            " [        191         215         214         210]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90918      0.8026]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([328.0, 202.0, 140.0, 242.0], 0.9091801643371582, -1), ([191.0, 215.0, 214.0, 210.0], 0.802596926689148, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 1 chair, 248.7ms\n",
            "Speed: 3.5ms preprocess, 248.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        330         202         140         242]\n",
            " [        196       214.5         222         211]\n",
            " [        230         184          92         146]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.90854     0.81942     0.31158]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([330.0, 202.0, 140.0, 242.0], 0.9085366725921631, -1), ([196.0, 214.5, 222.0, 211.0], 0.8194155097007751, -1), ([230.0, 184.0, 92.0, 146.0], 0.3115801215171814, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 1 cake, 1 chair, 234.0ms\n",
            "Speed: 3.5ms preprocess, 234.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      330.5         201         137         242]\n",
            " [      197.5         214         225         212]\n",
            " [        228         177          86         136]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.91211     0.76731     0.27997]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([330.5, 201.0, 137.0, 242.0], 0.9121086001396179, -1), ([197.5, 214.0, 225.0, 212.0], 0.7673062682151794, -1), ([228.0, 177.0, 86.0, 136.0], 0.27997270226478577, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 1 cake, 1 chair, 224.1ms\n",
            "Speed: 8.5ms preprocess, 224.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      333.5       200.5         137         241]\n",
            " [        198       212.5         224         211]\n",
            " [        233         179          96         132]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.91195     0.82323     0.30923]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([333.5, 200.5, 137.0, 241.0], 0.9119512438774109, -1), ([198.0, 212.5, 224.0, 211.0], 0.8232324719429016, -1), ([233.0, 179.0, 96.0, 132.0], 0.30923283100128174, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 1 cake, 1 chair, 226.7ms\n",
            "Speed: 3.6ms preprocess, 226.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        337       201.5         136         241]\n",
            " [        196       210.5         222         211]\n",
            " [        238       179.5         106         139]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.91723     0.80172     0.25081]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([337.0, 201.5, 136.0, 241.0], 0.9172335267066956, -1), ([196.0, 210.5, 222.0, 211.0], 0.8017212748527527, -1), ([238.0, 179.5, 106.0, 139.0], 0.2508067488670349, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 cake, 2 chairs, 238.3ms\n",
            "Speed: 17.1ms preprocess, 238.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        341       201.5         138         243]\n",
            " [        197       209.5         222         211]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.90595     0.81313]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([341.0, 201.5, 138.0, 243.0], 0.9059544205665588, -1), ([197.0, 209.5, 222.0, 211.0], 0.8131261467933655, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 1 potted plant, 236.7ms\n",
            "Speed: 3.9ms preprocess, 236.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        346         201         140         240]\n",
            " [      199.5       210.5         227         213]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.89633     0.85151]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([346.0, 201.0, 140.0, 240.0], 0.8963264226913452, -1), ([199.5, 210.5, 227.0, 213.0], 0.8515068888664246, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 1 chair, 235.2ms\n",
            "Speed: 7.0ms preprocess, 235.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      349.5         200         139         240]\n",
            " [        196       211.5         222         217]\n",
            " [        284         130          82          82]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.90725     0.83187     0.31825]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([349.5, 200.0, 139.0, 240.0], 0.9072473645210266, -1), ([196.0, 211.5, 222.0, 217.0], 0.8318692445755005, -1), ([284.0, 130.0, 82.0, 82.0], 0.3182470500469208, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 chair, 228.4ms\n",
            "Speed: 10.3ms preprocess, 228.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        352         201         140         238]\n",
            " [        199       210.5         228         219]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [     0.9104     0.81418]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([352.0, 201.0, 140.0, 238.0], 0.9104004502296448, -1), ([199.0, 210.5, 228.0, 219.0], 0.814180850982666, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 230.5ms\n",
            "Speed: 3.9ms preprocess, 230.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      353.5       201.5         143         235]\n",
            " [        206       210.5         244         221]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.82562     0.82356]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([353.5, 201.5, 143.0, 235.0], 0.8256198167800903, -1), ([206.0, 210.5, 244.0, 221.0], 0.823557436466217, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 2 chairs, 225.0ms\n",
            "Speed: 3.9ms preprocess, 225.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      207.5         210         251         222]\n",
            " [        357       203.5         140         235]\n",
            " [        287       128.5          84          83]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.80823     0.65821     0.25412]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([207.5, 210.0, 251.0, 222.0], 0.8082309365272522, -1), ([357.0, 203.5, 140.0, 235.0], 0.65821373462677, -1), ([287.0, 128.5, 84.0, 83.0], 0.2541181445121765, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 2 chairs, 325.4ms\n",
            "Speed: 4.2ms preprocess, 325.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        358       205.5         142         233]\n",
            " [      209.5         210         253         222]\n",
            " [        287         126          84          88]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.81079     0.72665     0.31545]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([358.0, 205.5, 142.0, 233.0], 0.8107882142066956, -1), ([209.5, 210.0, 253.0, 222.0], 0.7266525030136108, -1), ([287.0, 126.0, 84.0, 88.0], 0.31545212864875793, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 315.3ms\n",
            "Speed: 10.3ms preprocess, 315.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      360.5         208         139         230]\n",
            " [      210.5         209         257         222]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.87214     0.76461]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([360.5, 208.0, 139.0, 230.0], 0.872140109539032, -1), ([210.5, 209.0, 257.0, 222.0], 0.7646138668060303, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 2 chairs, 303.4ms\n",
            "Speed: 3.8ms preprocess, 303.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        211       208.5         262         223]\n",
            " [      362.5         209         139         228]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.77331     0.65349]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([211.0, 208.5, 262.0, 223.0], 0.7733147740364075, -1), ([362.5, 209.0, 139.0, 228.0], 0.6534860134124756, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 2 chairs, 323.5ms\n",
            "Speed: 3.5ms preprocess, 323.5ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        210       207.5         266         221]\n",
            " [      314.5         211         237         226]\n",
            " [        366       210.5         132         225]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.78048     0.44283     0.39903]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([210.0, 207.5, 266.0, 221.0], 0.7804766297340393, -1), ([314.5, 211.0, 237.0, 226.0], 0.4428298771381378, -1), ([366.0, 210.5, 132.0, 225.0], 0.3990314304828644, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 1 chair, 322.0ms\n",
            "Speed: 4.6ms preprocess, 322.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      205.5       208.5         271         223]\n",
            " [      366.5         212         131         222]\n",
            " [      322.5         212         219         222]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.73959     0.60207     0.35664]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([205.5, 208.5, 271.0, 223.0], 0.7395853400230408, -1), ([366.5, 212.0, 131.0, 222.0], 0.6020731329917908, -1), ([322.5, 212.0, 219.0, 222.0], 0.3566385507583618, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 323.8ms\n",
            "Speed: 11.1ms preprocess, 323.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      187.5       209.5         331         225]\n",
            " [        366         213         132         220]\n",
            " [        314         213         238         222]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.61037       0.517     0.30746]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([187.5, 209.5, 331.0, 225.0], 0.6103703379631042, -1), ([366.0, 213.0, 132.0, 220.0], 0.516995906829834, -1), ([314.0, 213.0, 238.0, 222.0], 0.30745649337768555, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 343.1ms\n",
            "Speed: 13.3ms preprocess, 343.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        199       208.5         282         227]\n",
            " [      364.5       213.5         133         217]\n",
            " [      312.5         212         231         222]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.65661     0.32344     0.26982]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([199.0, 208.5, 282.0, 227.0], 0.6566120982170105, -1), ([364.5, 213.5, 133.0, 217.0], 0.32344040274620056, -1), ([312.5, 212.0, 231.0, 222.0], 0.26981791853904724, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 321.3ms\n",
            "Speed: 3.9ms preprocess, 321.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        208       208.5         258         227]\n",
            " [        364         215         132         216]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.74544     0.26272]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([208.0, 208.5, 258.0, 227.0], 0.7454418540000916, -1), ([364.0, 215.0, 132.0, 216.0], 0.26271796226501465, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 350.0ms\n",
            "Speed: 6.4ms preprocess, 350.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      201.5       207.5         273         227]\n",
            " [        333       214.5         194         217]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.62809      0.4382]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([201.5, 207.5, 273.0, 227.0], 0.6280943155288696, -1), ([333.0, 214.5, 194.0, 217.0], 0.43819934129714966, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 292.7ms\n",
            "Speed: 5.2ms preprocess, 292.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      207.5         207         267         226]\n",
            " [        335       214.5         192         215]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.70786     0.56649]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([207.5, 207.0, 267.0, 226.0], 0.7078605890274048, -1), ([335.0, 214.5, 192.0, 215.0], 0.5664944052696228, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 229.7ms\n",
            "Speed: 3.7ms preprocess, 229.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        208         205         266         226]\n",
            " [        361         213         134         214]\n",
            " [        329         213         202         218]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.71483     0.38641       0.303]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([208.0, 205.0, 266.0, 226.0], 0.7148333787918091, -1), ([361.0, 213.0, 134.0, 214.0], 0.38640522956848145, -1), ([329.0, 213.0, 202.0, 218.0], 0.30300140380859375, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 bottle, 246.4ms\n",
            "Speed: 3.6ms preprocess, 246.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      360.5       213.5         139         217]\n",
            " [        205       203.5         266         225]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.72576     0.72568]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([360.5, 213.5, 139.0, 217.0], 0.7257556915283203, -1), ([205.0, 203.5, 266.0, 225.0], 0.7256794571876526, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 226.7ms\n",
            "Speed: 3.5ms preprocess, 226.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        356         213         136         216]\n",
            " [      206.5         203         255         226]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.54489     0.53577]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([356.0, 213.0, 136.0, 216.0], 0.5448886752128601, -1), ([206.5, 203.0, 255.0, 226.0], 0.535772979259491, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 237.8ms\n",
            "Speed: 3.4ms preprocess, 237.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        332       210.5         176         219]\n",
            " [        165       179.5         186         185]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.66253     0.26968]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([332.0, 210.5, 176.0, 219.0], 0.6625330448150635, -1), ([165.0, 179.5, 186.0, 185.0], 0.2696811556816101, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 book, 236.9ms\n",
            "Speed: 3.7ms preprocess, 236.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        350         211         128         220]\n",
            " [      194.5       176.5         237         183]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.63682     0.35198]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([350.0, 211.0, 128.0, 220.0], 0.6368241310119629, -1), ([194.5, 176.5, 237.0, 183.0], 0.35197845101356506, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 1 book, 193.6ms\n",
            "Speed: 11.3ms preprocess, 193.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        192       165.5         230         161]\n",
            " [      349.5         204         129         218]\n",
            " [      249.5       163.5         121         153]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.40955     0.36405     0.26313]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([192.0, 165.5, 230.0, 161.0], 0.40955063700675964, -1), ([349.5, 204.0, 129.0, 218.0], 0.3640517294406891, -1), ([249.5, 163.5, 121.0, 153.0], 0.26312944293022156, -1)]\n",
            "\n",
            "0: 480x640 1 person, 1 cup, 1 potted plant, 229.7ms\n",
            "Speed: 3.7ms preprocess, 229.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        245         163         118         146]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.42684]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([245.0, 163.0, 118.0, 146.0], 0.4268408715724945, -1)]\n",
            "\n",
            "0: 480x640 1 person, 1 cup, 216.1ms\n",
            "Speed: 3.8ms preprocess, 216.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      253.5         185         133         186]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.45878]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([253.5, 185.0, 133.0, 186.0], 0.4587774872779846, -1)]\n",
            "\n",
            "0: 480x640 1 person, 202.2ms\n",
            "Speed: 3.8ms preprocess, 202.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        261         189         134         196]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.28153]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([261.0, 189.0, 134.0, 196.0], 0.28152740001678467, -1)]\n",
            "\n",
            "0: 480x640 1 person, 173.6ms\n",
            "Speed: 3.9ms preprocess, 173.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        261         202         138         224]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.50103]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([261.0, 202.0, 138.0, 224.0], 0.5010347366333008, -1)]\n",
            "\n",
            "0: 480x640 (no detections), 178.3ms\n",
            "Speed: 5.4ms preprocess, 178.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: []\n",
            "Bounding box shape: (0,)\n",
            "Confidences: []\n",
            "Confidences shape: (0,)\n",
            "Formatted detections: []\n",
            "\n",
            "0: 480x640 2 persons, 191.8ms\n",
            "Speed: 5.1ms preprocess, 191.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        281       214.5          96         213]\n",
            " [      221.5       176.5          71         177]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.51413     0.27137]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([281.0, 214.5, 96.0, 213.0], 0.5141261219978333, -1), ([221.5, 176.5, 71.0, 177.0], 0.2713650166988373, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 233.7ms\n",
            "Speed: 4.4ms preprocess, 233.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        281       202.5          96         235]\n",
            " [        209       143.5          82         115]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.68236     0.33194]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([281.0, 202.5, 96.0, 235.0], 0.6823573708534241, -1), ([209.0, 143.5, 82.0, 115.0], 0.3319362998008728, -1)]\n",
            "\n",
            "0: 480x640 3 persons, 241.1ms\n",
            "Speed: 9.7ms preprocess, 241.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        280         201         102         238]\n",
            " [      219.5       142.5          59         115]\n",
            " [        227       204.5          60         109]]\n",
            "Bounding box shape: (3, 4)\n",
            "Confidences: [    0.58941     0.39647     0.34386]\n",
            "Confidences shape: (3,)\n",
            "Formatted detections: [([280.0, 201.0, 102.0, 238.0], 0.5894108414649963, -1), ([219.5, 142.5, 59.0, 115.0], 0.3964691162109375, -1), ([227.0, 204.5, 60.0, 109.0], 0.34385696053504944, -1)]\n",
            "\n",
            "0: 480x640 1 person, 1 car, 1 motorcycle, 1 book, 204.1ms\n",
            "Speed: 5.4ms preprocess, 204.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        283         201         108         242]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.74391]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([283.0, 201.0, 108.0, 242.0], 0.7439119815826416, -1)]\n",
            "\n",
            "0: 480x640 1 person, 1 car, 1 book, 206.0ms\n",
            "Speed: 10.8ms preprocess, 206.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      282.5         201         119         242]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.70906]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([282.5, 201.0, 119.0, 242.0], 0.7090590596199036, -1)]\n",
            "\n",
            "0: 480x640 2 persons, 1 car, 1 tv, 1 book, 202.8ms\n",
            "Speed: 3.7ms preprocess, 202.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        278         202         112         240]\n",
            " [        224         167          62         170]]\n",
            "Bounding box shape: (2, 4)\n",
            "Confidences: [    0.79075     0.30776]\n",
            "Confidences shape: (2,)\n",
            "Formatted detections: [([278.0, 202.0, 112.0, 240.0], 0.7907471060752869, -1), ([224.0, 167.0, 62.0, 170.0], 0.30775824189186096, -1)]\n",
            "\n",
            "0: 480x640 1 person, 1 car, 1 chair, 1 tv, 230.1ms\n",
            "Speed: 5.2ms preprocess, 230.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        273         201         122         242]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.67222]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([273.0, 201.0, 122.0, 242.0], 0.672215461730957, -1)]\n",
            "\n",
            "0: 480x640 1 person, 1 car, 1 chair, 1 tv, 1 book, 198.4ms\n",
            "Speed: 3.5ms preprocess, 198.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        273         201         120         242]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.70861]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([273.0, 201.0, 120.0, 242.0], 0.7086133360862732, -1)]\n",
            "\n",
            "0: 480x640 1 person, 1 car, 1 chair, 1 tv, 2 books, 207.8ms\n",
            "Speed: 7.7ms preprocess, 207.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      269.5       201.5         127         241]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.79983]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([269.5, 201.5, 127.0, 241.0], 0.7998296022415161, -1)]\n",
            "\n",
            "0: 480x640 1 person, 1 chair, 1 tv, 2 books, 230.3ms\n",
            "Speed: 3.7ms preprocess, 230.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      268.5         204         129         238]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.83335]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([268.5, 204.0, 129.0, 238.0], 0.8333544731140137, -1)]\n",
            "\n",
            "0: 480x640 1 person, 2 chairs, 1 book, 208.1ms\n",
            "Speed: 9.0ms preprocess, 208.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        269       203.5         138         239]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.82905]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([269.0, 203.5, 138.0, 239.0], 0.8290472626686096, -1)]\n",
            "\n",
            "0: 480x640 1 person, 2 chairs, 1 book, 215.2ms\n",
            "Speed: 14.7ms preprocess, 215.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[        267         203         134         236]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.85841]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([267.0, 203.0, 134.0, 236.0], 0.8584116697311401, -1)]\n",
            "Processing frame 2000\n",
            "\n",
            "0: 480x640 1 person, 2 chairs, 1 tv, 1 book, 204.4ms\n",
            "Speed: 3.3ms preprocess, 204.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Bounding boxes: [[      267.5       203.5         135         237]]\n",
            "Bounding box shape: (1, 4)\n",
            "Confidences: [    0.85869]\n",
            "Confidences shape: (1,)\n",
            "Formatted detections: [([267.5, 203.5, 135.0, 237.0], 0.858692467212677, -1)]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gvjvK2wGeDoL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}